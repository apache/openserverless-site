[{"body":"Quick Start This is a quick start guide to the installation process, targeting experienced users in a hurry.\nIt provides a high-level overview of the installation process, omitting advanced of details. The missing pieces are covered in the rest of the documentation.\nOf course, if this guide is not enough and things fail, you can always apply the rule: “if everything fails, read the manual”.\nPrerequisites Start ensuring the prerequsites are satisfied:\nDownload and install ops, the OpenServerless CLI, picking version suitable for your environment. We support 64-bit versions of recent Windows, MacOS and major Linux distributions.\nCheck that ops is correctly installed: open the terminal and write:\nops -info\nConfigure the services you want to enable. By default, OpenServerless will install only the serverless engine, accessible in http with no services enabled.\nIf you want to enable all the services, use:\nops config enable --all otherwise pick the services you want, among --redis, --mongodb, --minio, --cron, --postgres. Note that --mongodb is actually FerretDB and requires Postgres which is implicitly also enabled. More details here.\nNow, choose where to install OpenServerless.\nYour options are:\nlocally in your workstation;\nin a Linux server in your intranet\nin a Linux server available on Internet\nin a Kubernetes cluster in your intranet\nin cloud, where you can provision a Kubernetes cluster\nLocal Installation If you have a decent workstation (with at least 16GB of memory) running a recent 64-bit operating system, you can install Docker Desktop and then install OpenServerless in it. Once you have:\ninstalled the CLI\nconfigured the services\ninstalled Docker Desktop\nMake sure Docker Desktop its running before the next operation. Install OpenServerless and its services in Docker with just this command:\nops setup devcluster Once it is installed, you can proceed to read the tutorial to learn how to code with it.\nNOTE: At least 16GB of memory is ideal, but if you know what you’re doing and can tolerate inefficiency, you can install with less using:\nexport PREFL_NO_MEM_CHECK=1 export PLEFL_NO_CPU_CHECK=1 Internet Server Configuration If you have access to a server on the Internet, you will know its IP address.\nMany cloud providers also give you a DNS name usually derived by the IP and very hard to remember such as ec2-12-34-56-78.us-west-2.compute.amazonaws.com.\nOnce you got the IP address and the DNS name, you can give to your server a bettername using a domain name provider. We cannot give here precise instructions as there are many DNS providers and each has different rules to do the setup. Check with your chosen domain name provider.\nIf you have this name, configure it and enable DNS with:\nops config apihost \u003cdns-name\u003e --tls=\u003cemail-address\u003e ❗ IMPORTANT\nReplace the \u003cdns-name\u003e with the actual DNS name, without using prefixes like http:// or suffixes like :443. Also, replace ` with your actual email address.\nthen proceed with the server installation.\nServer Installation Once you got access to a Linux server with:\nAn IP address or DNS name, referred to as \u003cserver\u003e\nPasswordless access with ssh to a Linux user \u003cuser\u003e\nAt least 8GB of memory and 50GB of disk space available\nThe user \u003cuser\u003e has passwordless sudo rights\nThe firewall that allows traffic to ports 80, 443 and 6443\nWithout any Docker or Kubernetes installed\nWithout any Web server or Web application installed\nthen you can install OpenServerless in it.\nThe server can be physical or virtual. We need Kubernetes in it but the installer takes care of installing also a flavor of Kubernetes, K3S, courtesy of K3Sup.\nTo install OpenServerless, first check you have access to the server with:\nssh \u003cuser\u003e@\u003cserver\u003e sudo hostname You should see no errors and read the internal hostname of your server.\nIf you do not receive errors, you can proceed to install OpenServerless with this command:\nops setup server \u003cserver\u003e \u003cuser\u003e ❗ IMPORTANT\nReplace in the commands \u003cserver\u003e with the address of your server, and \u003cuser\u003e with the actual user to use in your server. The \u003cserver\u003e can be the same as \u003cdns-name\u003e you have configured in the previous paragraph, if you did so, or simply the IP address of a server on your intranet.\nNow wait until the installation completes. Once it is installed, you can proceed to read the tutorial to learn how to code with it.\nCloud Cluster Provisioning If you have access to a cloud provider, you can set up a Kubernetes cluster in it. The Kubernetes cluster needs to satisfy certain prerequisites to be able to install OpenServerless with no issues.\nWe provide the support to easily configure and install a compliant Kubernetes cluster for the following clouds:\nAmazon AWS\nMicrosoft Azure\nGoogle Cloud\nAt the end of the installation you will have available and accessible a Kubernetes Cluster able to install OpenServerless, so proceed with a cluster installation.\nAmazon AWS Configure and install an Amazon EKS cluster on Amazon AWS with:\nops config eks ops cloud eks create then install the cluster.\nAzure AKS Configure and install an Azure AKS cluster on Microsoft Azure with:\nops config aks ops cloud aks create then install the cluster.\nGoogle Cloud GKE Configure and install a Google Cloud GKE with:\nops config gke ops cloud gke create then install the cluster.\nCluster Install In short, if you have access to kubernetes cluster, you can install OpenServerless with:\nops setup cluster For a slightly longer discussion, checking prerequisites before installing, read on.\nPrerequisites to install If you have access to a Kubernetes cluster with:\nAccess to the cluster-admin role\nBlock storage configured as the default storage class\nThe nginx-ingress installed\nKnowledge of the IP address of your nginx-ingress controller\nyou can install OpenServerless in it. You can read more details here.\nYou can get this access either by provisioning a Kubernetes cluster in cloud or getting access to it from your system administrator.\nWhatever the way you get access to your Kubernetes cluster, you will end up with a configuration file which is usually stored in a file named .kube/config in your home directory. This file will give access to the Kubernetes cluster to install OpenServerless.\nPerforming the installation To install, first, verify you have actually access to the Kubernetes cluster, by running this command:\nops debug kube info You should get information about your cluster, something like this:\nKubernetes control plane is running at \\https://api.nuvolaris.osh.n9s.cc:6443\nNow you can finally install OpenServerless with the command:\nops setup cluster Wait until the process is complete and if there are no errors, OpenServerless is installed and ready to go.\nOnce it is installed, you can proceed to read the Tutorial to learn how to code with it.\n","categories":"","description":"Fast path to install a self-hosted OpenServerless","excerpt":"Fast path to install a self-hosted OpenServerless","ref":"/docs/installation/quickstart/","tags":"","title":"Quick Start"},{"body":"Actions Actions are stateless functions that run on the OpenWhisk and OpenServerless platform. For example, an action can be used to detect the faces in an image, respond to a database change, respond to an API call, or post a Tweet. In general, an action is invoked in response to an event and produces some observable output.\nAn action may be created from a function programmed using a number of supported languages and runtimes, or from a binary-compatible executable.\nThe OpenServerless CLI makes it easy to create and invoke actions. Instructions for configuring and using the CLI are available here.\nYou can also use the REST API.\nWhile the actual function code will be specific to a language and runtime, the operations to create, invoke and manage an action are the same regardless of the implementation choice.\nWe recommend that you review the cli and read the tutorial before moving on to advanced topics.\nWhat you need to know about actions Functions should be stateless, or idempotent. While the system does not enforce this property, there is no guarantee that any state maintained by an action will be available across invocations. In some cases, deliberately leaking state across invocations may be advantageous for performance, but also exposes some risks.\nAn action executes in a sandboxed environment, namely a container. At any given time, a single activation will execute inside the container. Subsequent invocations of the same action may reuse a previous container, and there may exist more than one container at any given time, each having its own state.\nInvocations of an action are not ordered. If the user invokes an action twice from the command line or the REST API, the second invocation might run before the first. If the actions have side effects, they might be observed in any order.\nThere is no guarantee that actions will execute atomically. Two actions can run concurrently and their side effects can be interleaved. OpenWhisk and OpenServerless does not ensure any particular concurrent consistency model for side effects. Any concurrency side effects will be implementation-dependent.\nActions have two phases: an initialization phase, and a run phase. During initialization, the function is loaded and prepared for execution. The run phase receives the action parameters provided at invocation time. Initialization is skipped if an action is dispatched to a previously initialized container — this is referred to as a warm start. You can tell if an invocation was a warm activation or a cold one requiring initialization by inspecting the activation record.\nAn action runs for a bounded amount of time. This limit can be configured per action, and applies to both the initialization and the execution separately. If the action time limit is exceeded during the initialization or run phase, the activation’s response status is action developer error.\nAccessing action metadata within the action body The action environment contains several properties that are specific to the running action. These allow the action to programmatically work with OpenWhisk and OpenServerless assets via the REST API, or set an internal alarm when the action is about to use up its allotted time budget. The properties are accessible via the system environment for all supported runtimes: Node.js, Python, Swift, Java and Docker actions when using the OpenWhisk and OpenServerless Docker skeleton.\n__OW_API_HOST the API host for the OpenWhisk and OpenServerless deployment running this action.\n__OW_API_KEY the API key for the subject invoking the action, this key may be a restricted API key. This property is absent unless requested with the annotation explicitly provide-api-key\n__OW_NAMESPACE the namespace for the activation (this may not be the same as the namespace for the action).\n__OW_ACTION_NAME the fully qualified name of the running action.\n__OW_ACTION_VERSION the internal version number of the running action.\n__OW_ACTIVATION_ID the activation id for this running action instance.\n__OW_DEADLINE the approximate time when this action will have consumed its entire duration quota (measured in epoch milliseconds).\n","categories":"","description":"What Actions are and how to create and execute them","excerpt":"What Actions are and how to create and execute them","ref":"/docs/reference/entities/actions/","tags":"","title":"Actions"},{"body":"OpenServerless Cli OpenServerless offers a powerful command line interface named ops which extends and embeds the OpenWhisk wsk.\nDownload instructions are available here.\nLet’s see some advanced uses of ops.\nOpenServerless access is usually configured logging into the platform with the ops -login command.\nYou can also configure access directly using the ops -wsk command.\nThere are two required properties to configure:\nAPI host (name or IP address) for the OpenWhisk and OpenServerless deployment you want to use.\nAuthorization key (username and password) which grants you access to the OpenWhisk and OpenServerless API.\nThe API host is the installation host, the one you configure in installation with ops config apihost\nops -wsk property set --apihost \u003copenwhisk_baseurl\u003e If you know your authorization key, you can configure the CLI to use it. Otherwise, you will need to obtain an authorization key for most CLI operations. The API key is visible in the file ~/.wskprops after you perform a ops -login. This file can be sourced to be read as environment variables.\nsource ~/.wskprops ops -wsk property set --auth $AUTH Tip: The OpenWhisk and OpenServerless CLI stores properties in the ~/.wskprops configuration file by default. The location of this file can be altered by setting the WSK_CONFIG_FILE environment variable.\nThe required properties described above have the following keys in the .wskprops file:\nAPIHOST - Required key for the API host value.\nAUTH - Required key for the Authorization key.\nTo verify your CLI setup, try ops action list.\nConfigure the CLI to use an HTTPS proxy The CLI can be setup to use an HTTPS proxy. To setup an HTTPS proxy, an environment variable called HTTPS_PROXY must be created. The variable must be set to the address of the HTTPS proxy, and its port using the following format: {PROXY IP}:{PROXY PORT}.\nConfigure the CLI to use client certificate The CLI has an extra level of security from client to apihost, system provides default client certificate configuration which deployment process generated, then you can refer to below steps to use client certificate:\nops -wsk property set --cert \u003cclient_cert_path\u003e --key \u003cclient_key_path\u003e ","categories":"","description":"How to use the advanced features of ops command line","excerpt":"How to use the advanced features of ops command line","ref":"/docs/reference/references/advanced-cli/","tags":"","title":"Advanced CLI"},{"body":"Contribution Guidelines Subscribe our mailing list sending an email to dev-subscribe@openserverless.apache.org Discuss your contribution and get a ticket assigned in our Issue Tracker setup your virtual machine as described here . Learn about git submodules (we use them), and use the script update-tree.sh to update your source tree to the latest version of all the branches. Fork the subrepo you want to contribute and code your contribution. Download and sign the ICLA and send to secretary@apache.org before submitting any Pull Request Send a pull request to the relevant subrepo. ","categories":"","description":"How to contribute to the Apache OpenServerless Project","excerpt":"How to contribute to the Apache OpenServerless Project","ref":"/contribution-guidelines/","tags":"","title":"Contribution Guidelines"},{"body":"Local Docker installation This page describes how to install OpenServerless on your local machine. The services are limited and not accessible from the outside so it is an installation useful only for development purposes.\nPrerequisites Before installing, you need to:\ninstall Docker.\ninstall ops.\nFurthermore you will need a decent PC / Mac.\nDocker will need 4 Gb Ram and almost 40Gb of free space to run the cluster locally.\n💡 NOTE\nWe introduced a special domain called miniops.me: this domain will always resolve to 127.0.0.1. This way the static service for the default namespace nuvolaris will be linking the http://miniops.me to the nuvolaris web bucket.\nAdding new users will add an ingress with host set to http://\u003cnamespace\u003e.miniops.me.\n⚠ WARNING\nYou cannot have https in a local installation. If you enable it, the configuration will be ignored.\nInstallation The following command will perform a full local installation:\nops setup mini Behind the scene, this command will write a cluster configuration file called ~/.ops/config.json activating these services: static, redis, postgres, ferretdb, minio, cron, milvus constituting the common baseline for development tasks.\nWait until the command terminates. It will take minutes to complete, so be patient.\nThe installation will ends showing these informations:\n*** Configuring Access to OpenServerless *** apihost=http://miniops.me username=devel Logging in http://miniops.me as devel Successfully logged in as devel. ok: whisk auth set. Run 'wsk property get --auth' to see the new value. ok: whisk API host set to http://miniops.me OpenServerless host and auth set successfully. You are now ready to use ops! ==================| UPLOAD RESULTS |================== | FILES : 4 | COMPLETED : 4 | ERRORS : 0 | SKIPPED : 0 | EXEC. TIME : 46.70 ms ====================================================== Login with: ops ide login devel https://miniops.me Password is saved in: /Users/openserverless/.ops/devel.password Web URL is: http://devel.miniops.me Try your devel user At the end of the setup, you’ll have a local OpenServerless installation with a devel user.\nOpen a browser to http://devel.miniops.me. You will see a page like this:\nTake a minute to share on Linkedin your experience with the setup and to join us on Discord.\nTroubleshooting Usually the setup completes without errors.\nHowever, if ops is unable to complete the setup, you may see this message at the end:\nops: Failed to run task \"create\": exit status 1 task execution error: ops: Failed to run task \"create\": exit status 1 ops: Failed to run task \"devcluster\": exit status 1 task execution error: ops: Failed to run task \"devcluster\": exit status 1 If this is your case, try to perform a uninstall / reinstall:\nops setup devcluster --uninstall ops config reset If this will not solve, please contact the community.\nPost install Check the tutorial to learn how to use it.\nUninstall and remove devcluster This will actually remove the ops namespace and all the services from kind. Useful to re-try an installation when something gone wrong.\nops setup devcluster --uninstall ops config reset ","categories":"","description":"Install OpenServerless on a local machine","excerpt":"Install OpenServerless on a local machine","ref":"/docs/installation/install/docker/","tags":"","title":"Docker"},{"body":"Download and Install ops What is ops? As you can guess it helps with operations: ops is the OPenServerless CLI.\nIt is a task executor on steroids.\nit embeds task, wsk and a lot of other utility commands (check with ops -help) automatically download and update command line tools, prerequisites and tasks taskfiles are organized in commands and subcommands, hierarchically and are powered by docopt it supports plugins The predefined set of tasks are all you need to install and manage an OpenServerless cluster.\nDownload links You can install OpenServerless using its Command Line Interface, ops.\n⚠ WARNING\nSince we are in a preview phase, this is not an official link approved by the Apache Software Foundation.\nQuick install in Linux, MacOS and Windows with WSL or GitBash:\ncurl -sL bit.ly/get-ops | bash Quick install in Windows with PowerShell\nOpen a powershell. Then give these commands:\nSet-ExecutionPolicy Bypass -Scope Process -Force irm bit.ly/get-ops-exe | iex After the installation Once installed, in the first run ops will tell to update the tasks executing:\nops -update\nThis command updates the OpenServerless “tasks” (its internal logic) to the latest version. This command should be also executed frequently, as the tasks are continuously evolving and expanding.\nops will suggest when to update them (at least once a day).\nYou normally just need to update the tasks but sometimes you also need to update ops itself. The system will detect when it is the case and tell you what to do.\nWhere to find more details: For more details, please visit the Github page of Openserverless Cli\n","categories":"","description":"Download OpenServerless with ops CLI","excerpt":"Download OpenServerless with ops CLI","ref":"/docs/installation/download/","tags":"","title":"Download"},{"body":"Entities OpenServerless applications are composed by some “entities” that you can manipulate either using a command line interface or programmatically with code.\nThe command line interface is the ops command line tools, that can be used directly on the command line or automated through scripts. You can also a REST API crafted explicitly for OpenServerless.\nThe entities available in OpenServerless are:\nPackages: They serve as a means of grouping actions together, facilitating the sharing of parameters, annotations, etc. Additionally, they offer a base URL that can be utilized by web applications.\nActions: These are the fundamental components of a OpenServerless application, capable of being written in any programming language. Actions accept input and produce output, both formatted in JSON.\nActivations: Each action invocations produces an activation id that can be listed. Action output and results logged and are associated to activations and can be retrieved providing an activativation id.\nSequences: Actions can be interconnected, where the output of one action serves as the input for another, effectively forming a sequence.\nTriggers: Serving as entry points with distinct names, triggers are instrumental in activating multiple actions.\nRules: Rules establish an association between a trigger and an action. Consequently, when a trigger is fired, all associated actions are invoked accordingly.\nThe ops command Let’s now provide an overview of OpenServerless’ command line interface, focusing on the ops command.\nThe command can be dowloaded in precompile binary format for many platform following the Download button on https://www.nuvolaris.io/\nThe ops command is composed of many commands, each one with many subcommands. The general format is:\nops \u003centity\u003e \u003ccommand\u003e \u003cparameters\u003e \u003cflags\u003e Note that \u003cparameters\u003e and \u003cflags\u003e are different for each \u003ccommand\u003e, and for each \u003centity\u003e there are many subcommands.\nThe CLI shows documention in the form of help output if you do not provide enough parameters to it. Start with ops to get the list of the main commands. If you type the ops \u003centity\u003e get the help for that entity, and so on.\nFor example, let’s see ops output (showing the command) and the more frequently used command, action, also showing the more common subcommands, shared with many others:\n$ ops Welcome to Ops, the all-mighty OpenServerless Build Tool The top level commands all have subcommands. Just type ops \u003ccommand\u003e to see its subcommands. Commands: action work with actions activation work with activations invoke shorthand for action invoke (-r is the default) logs shorthand for activation logs package work with packages result shorthand for activation result rule work with rules trigger work with triggers url get the url of a web action$ wsk action There are many more sub commands used for aministrative purposes. In this documentation we only focus on the subcommands used to manage the main entities of OpenServerless.\nKeep in mind that commands represent entities, and their subcommands follow the CRUD model (Create, Retrieve via get/list, Update, Delete). This serves as a helpful mnemonic to understand the ops command’s functionality. While there are exceptions, these will be addressed throughout the chapter’s discussion. Note however that some subcommand may have some specific flags.\nNaming Entities Let’s see how entities are named.\nEach user also has a namespace, and everything a user creates, belongs to it.\nThe namespace is usually created by a system administrator.\nUnder a namespace you can create triggers, rules, actions and packages.\nThose entities will have a name like this:\n/mirella/demo-triggger\n/mirella/demo-rule\n/mirella/demo-package\n/mirella/demo-action\nWhen you create a package, you can put under it actions and feeds. Those entities are named\n/mirella/demo-package/demo-action\n/mirella/demo-package/demo-feed\n💡 NOTE\nIn the commands you do not require to specify a namespace. If your user is mirella, your namespace is /mirella, and You type demo-package to mean /mirella/demo-package, and demo-package/demo-action to mean /mirella/demo-package/demo-action.\n","categories":"","description":"The parts that OpenServerless applications are made of","excerpt":"The parts that OpenServerless applications are made of","ref":"/docs/cli/entities/","tags":"","title":"Entities"},{"body":"In this section you can find more informations about OpenServerless and OpenWhisk entities.\n","categories":"","description":"","excerpt":"In this section you can find more informations about OpenServerless …","ref":"/docs/reference/entities/","tags":"","title":"Entities"},{"body":"Getting started Build a sample Application Imagine we have a static website and need server logic to store contacts and validate data. This would require a server, a database and some code to glue it all together. With a serverless approach, we can just sprinkle little functions (that we call actions) on top of our static website and let OpenServerless take care of the rest. No more setting up VMs, backend web servers, databases, etc.\nIn this tutorial, we will see how you can take advantage of several services which are already part of a OpenServerless deployment and develop a contact form page for users to fill it with their emails and messages, which are then sent via email to us and stored in a database.\nFinally, we’ll see how to activate external services using Web hooks.\nOpenserverless CLI: Ops Serverless development is mostly performed on the CLI, and OpenServerless has its tool called ops. It’s a command line tool that allows you to deploy (and interact with) the platform seamlessly to the cloud, locally and in custom environments.\nOps is cross-platform and can be installed on Windows, Linux and MacOS. You can find the project and the sources on Apache OpenServerless Cli Github page\nDeploy OpenServerless To start using OpenServerless you can refer to the Installation Guide. You can follow the local installation to quickly get started with OpenServerless deployed on your machine, or if you want to follow the tutorial on a deployment on cloud you can pick one of the many supported cloud provider. Once installed come back here!\nEnabling Services After installing OpenServerless on a local machine with Docker or on a supported cloud, you can enable or disable the services offered by the platform. As we will use Postgres database, the Static content with the Minio S3 compatible storage, let’s run in the terminal:\nops config enable --postgres --static --minio --cron This is the default set of services.\nSince you should already have a deployment running, we have to update it with the new services so they get deployed. Simply run:\nops update apply And with just that (when it finishes), we have everything we need ready to use!\n💡 NOTE\nIf you’ve installed the local development environment using the instructions from the Docker installation page you’ve already the base services enabled by default.\nYou can check what services are enabled with the command:\nops config status This should be the output:\nOPERATOR_COMPONENT_MINIO=true OPERATOR_COMPONENT_MONGODB=true OPERATOR_COMPONENT_POSTGRES=true OPERATOR_COMPONENT_STATIC=true OPERATOR_COMPONENT_CRON=true OPERATOR_COMPONENT_REDIS=true Create a user If you don’t have a user, it’s the time to create one. We we’ll use it to work on this tutorial.\n⚠ WARNING\nTo create a user, we need to be the administrator, like described in this section.\nops admin adduser opstutorial \u003cyouremail\u003e SimplePassword --all The output will be:\nGenerated OPSTUTORIAL user secrets. Creating user opstutorial... whiskuser.nuvolaris.org/opstutorial created Login as user After user creation, it’s time to perform ops login.\n💡 NOTE\nThe ops ide login command will log you in on the server and dump the proper configuration of active services for your user. The configuration is automatically used by ops for all the tasks. You only need to run ops ide login once (unless you need to log in to another OpenServerless server or with another OpenServerless user).\nChange your APIHOST accordly, if you’ve specified a custom one during the system setup\nops ide login opstutorial http://localhost:80 *** Configuring Access to OpenServerless *** apihost=http://localhost:80 username=opstutorial Logging in http://localhost:80 as opstutorial Enter Password: Successfully logged in as opstutorial. ok: whisk auth set. Run 'wsk property get --auth' to see the new value. ok: whisk API host set to http://localhost:80 OpenServerless host and auth set successfully. You are now ready to use ops! Cleaning Up Once you are done and want to clean the services configuration, just run:\nops config disable --postgres --static --minio --cron ","categories":"","description":"Let's start building a sample application","excerpt":"Let's start building a sample application","ref":"/docs/tutorial/getting-started/","tags":"","title":"Getting started"},{"body":"Prerequisites to install OpenServerless with Docker You can install OpenServerless on your local machine using Docker. This page lists the prerequisits.\nFirst and before all you need a computer with at least 16 GB of memory and 30GB of available space.\n❗ IMPORTANT\n8GB are definitely not enough to run OpenServerless on your local machine.\nFurthermore, you need to install Docker. Let’s see the which one to install and configure if you have:\nWindows MacOS Linux Windows You require the 64 bit edition in Intel Architecture of a recent version of Windows (at least version 10). The installer ops does not run on 32 bit versions nor in the ARM architecture.\nDownload and install Docker Desktop for Windows.\nOnce installed, you can proceed configuring OpenServerless for the installation.\nMacOS You require a recent version of MacOS (at least version 11.xb BigSur). The installer ops is available both for Intel and ARM.\nDownload and install Docker Desktop for MacOS.\nSince MacOS uses a virtual machine for Docker with a constrained memory. you also need also to reserve at least 8GB.\n❗ IMPORTANT\nOn MacOS, Docker defaults to 2GB memoery and they are definitely not enough to run OpenServerless on your local machine.\nInstructions to increase the memory reserved to Docker Desktopo on MacOS:\nclick on the Docker Desktop icon in the menu\nselect Preferences\nclick on Resources\nincrease the reserved memory up to (at least) 8GB\nclick on Apply \u0026 Restart\nOnce installed, you can proceed configuring OpenServerless for the installation.\nLinux Docker Desktop is available also on Linux, however we advice to install instead the Server Docker Engine\nOn Linux, the Docker Engine for the server does not run in a virtual machine, so it is faster and uses less memory.\nOnce installed, you can proceed configuring OpenServerless for the installation.\n","categories":"","description":"Install OpenServerless with Docker locally","excerpt":"Install OpenServerless with Docker locally","ref":"/docs/installation/prereq/docker/","tags":"","title":"Local Docker"},{"body":"Packages OpenServerless groups actions and feeds in packages under a namespace. It is conceptually similar to a folder containing a group of related files.\nA package allows you to:\nGroup related actions together.\nShare parameters and annotations (each action sees the parameters assigned to the package).\nProvide web actions with a common prefix in the URL to invoke them.\nFor example, we can create a package demo-package and assign a parameter:\n$ ops package create demo-package -p email no-reply@nuvolaris.io ok: created package demo-package This command creates a new package with the specified name.\nPackage Creation, Update, and Deletion Let’s proceed with the commands to list, get information, update, and finally delete a package:\nFirst, let’s list our packages:\n$ ops package list packages /openserverless/demo-package/ private If you want to update a package by adding a parameter:\n$ ops package update demo-package -p email info@nuvolaris.io ok: updated package demo-package Let’s retrieve some package information:\n$ ops package get demo-package -s package /openserverless/demo-package/sample: (parameters: *email) Note the final -s, which means “summarize.”\nFinally, let’s delete a package:\n$ ops package delete demo-package ok: deleted package demo-package Adding Actions to the Package Actions can be added to a package using this command:\nops action create \u003cpackage-name\u003e/\u003caction-name\u003e This associates an existing action with the specified package.\nUsing Packages Once a package is created, actions within it can be invoked using their full path, with this schema: \u003cpackage-name\u003e/\u003caction-name\u003e. This allows organizing actions hierarchically and avoiding naming conflicts.\nConclusion Packages in OpenServerless provide a flexible and organized way to manage actions and their dependencies. Using the Ops CLI, you can efficiently create, add actions, and manage package dependencies, simplifying the development and management of serverless applications.\n","categories":"","description":"How to group actions and their related files","excerpt":"How to group actions and their related files","ref":"/docs/cli/entities/packages/","tags":"","title":"Packages"},{"body":"Configure a generic Linux server to install OpenServerless If you have access to a generic Linux server, to be able to install OpenServerless it needs to:\nbe accessible without a password with ssh\nbe able to run root commands without a password with sudo\nopen the ports 80, 443 and 6443 or 16443\nIf your server does not already satisfy those requirements, read below for information how to create a sshkey, configure sudo and open the firewall\nInstalling a public SSH key To connect to a server without a password using openssh (used by the installer), you need a couple of files called ssh keys.\nYou can generate them on the command line using this command:\nssh-keygen It will create a couple of files, typically called:\n~/.ssh/id_rsa\n~/.ssh/id_rsa.pub\nwhere ~ is your home directory.\nYou have to keep secret the id_rsa file because it is the private key and contains the information to identify you uniquely. Think to is as your password.\nYou can copy the id_rsa.pub in the server or even share it publicly, as it is the public key. Think to it as your login name, and adding this file to the server adds you to the users who can login into it.\nOnce you have generated the public key, access your server, then edit the file ~/.ssh/authorized_keys adding the public key to it.\nIt is just one line, contained in the id_rsa.pub file.\nCreate the file if it does not exist. Append the line to the file (as a single line) if it already exists. Do not remove other lines if you do not want to remove access to other users.\nConfigure Sudo You normally access Linux servers using a user that is not root (the system administrator with unlimited power on the system).\nDepending on the system, the user to use to access be ubuntu, ec2-user, admin or something else entirely. However if you have access to the server, the information of which user to use should have been provided, including a way to access to the root user.\nYou need to give this user the right to execute commands as root without a password, and you do this by configuring the command sudo.\nYou usually have either access to root with the su command, or you can execute sudo with a password.\nType either su or sudo bash to become root and edit the file /etc/sudoers adding the following line:\n\u003cuser\u003e ALL=(ALL) NOPASSWD:ALL where \u003cuser\u003e is the user you use to log into the system.\nOpen the firewall You need to open the following ports in the firewall of the server:\n443 for HTTPS\n80 for HTTP and provisioning certificates\n6443 (K3S) or 16443 (MicroK8S) for Kubernetes\nFor information on how to open the firewall, please consult the documentation of your cloud provider or contact your system administrator, as there are no common procedures and they depends on the cloud provider.\n","categories":"","description":"General prerequisites to install OpenServerless","excerpt":"General prerequisites to install OpenServerless","ref":"/docs/installation/prereq/server/generic/","tags":"","title":"SSH and Sudo"},{"body":"Tutorial This tutorial walks you through developing a simple OpenServerless application using the Command Line Interface (CLI) and Javascript (but any supported language will do).\nIts purpose is to showcase serverless development in action by creating a contact form for a website. We will see the development process from start to finish, including the deployment of the platform and running the application.\n","categories":"","description":"Showcase serverless development in action","excerpt":"Showcase serverless development in action","ref":"/docs/tutorial/","tags":"","title":"Tutorial"},{"body":"Actions An action can generally be considered as a function, a snippet of code, or generally a method.\nThe ops action command is designed for managing actions, featuring frequently utilized CRUD operations such as list, create, update, and delete. We will illustrate these operations through examples using a basic hello action. Let’s assume we have the following file in the current directory:\nThe hello.js script with the following content:\nfunction main(args) { return { body: \"Hello\" } } Simple Action Deployment If we want to deploy this simple action in the package demo, let’s execute:\n$ ops package update demo ok: updated package demo $ ops action update demo/hello hello.js ok: update action demo/hello Note that we ensured the package exists before creating the action.\nWe can actually omit the package name. In this case, the package name is default, which always exists in a namespace. However, we advise always placing actions in some named package.\n💡 NOTE\nWe used update, but we could have used create if the action does not exist because update also creates the action if it does not exist and updates it if it is already there. Update here is similar to the patch concept in REST API. However, create generates an error if an action does not exist, while update does not, so it is practical to always use update instead of create (unless we really want an error for an existing action for some reason).\nHow to Invoke Actions Let’s try to run the action:\n$ ops invoke demo/hello { \"body\": \"Hello\" } Actually, the invoke command does not exist, or better, it’s just a handy shortcut for ops action invoke -r.\nIf you try to run ops action invoke demo/hello, you get:\n$ ops action invoke demo/hello ok: invoked /_/demo/hello with id fec047bc81ff40bc8047bc81ff10bc85 You may wonder where the result is. In reality, in OpenServerless, all actions are by default asynchronous, so what you usually get is the activation id to retrieve the result once the action is completed.\nTo block the execution until the action is completed and get the result, you can either use the flag -r or --result, or use ops invoke.\nNote, however, that we are using ops to invoke an action, which means all the requests are authenticated. You cannot invoke actions directly without logging into the system first.\nHowever, you can mark an action to be public by creating it with --web true (see below).\nPublic Actions If you want an action to be public, you can do:\n$ ops action update demo/hello hello.js --web true ok: updated action demo/hello $ ops url demo/hello https://nuvolaris.dev/api/v1/web/mirella/demo/hello and you can invoke it with:\n$ curl -sL https://nuvolaris.dev/api/v1/web/dashboard/demo/hello Hello Note that the output is only showing the value of the body field. This is because the web actions must follow a pattern to produce an output suitable for web output, so the output should be under the key body, and so on. Check the section on Web Actions for more information.\n💡 NOTE\nActually, ops url is a shortcut for ops action get --url. You can use ops action get to retrieve a more detailed description of an action in JSON format.\nAfter action create, action update, and action get (and the shortcuts invoke and url), we should mention action list and action delete.\nThe action list command obviously lists actions and allows us to delete them:\n$ ops action list /mirella/demo/hello private nodejs:18 $ ops action delete demo/hello ok: deleted action demo/hello Conclusion Actions are a core part of our entities. A ops action is a self-contained and executable unit of code deployed on the ops serverless computing platform.\n","categories":"","description":"Functions, the core of OpenServerless","excerpt":"Functions, the core of OpenServerless","ref":"/docs/cli/entities/actions/","tags":"","title":"Actions"},{"body":"Administration If you are the administrator and you have access to the Kubernetes cluster where OpenServerless is installed you can administer the system.\nYou have access to the ops admin subcommand with the following synopsis:\nSubcommand: ops admin\nUsage: admin adduser \u003cusername\u003e \u003cemail\u003e \u003cpassword\u003e [--all] [--redis] [--mongodb] [--minio] [--postgres] [--storagequota=\u003cquota\u003e|auto] admin deleteuser \u003cusername\u003e Commands: admin adduser create a new user in OpenServerless with the username, email and password provided admin deleteuser delete a user from the OpenServerless installation via the username provided Options: --all enable all services --redis enable redis --mongodb enable mongodb --minio enable minio --postgres enable postgres --storagequota=\u003cquota\u003e ","categories":"","description":"System administration","excerpt":"System administration","ref":"/docs/cli/admin/","tags":"","title":"Administration"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/articles/","tags":"","title":"Articles"},{"body":"About Apache OpenServerless Apache OpenServerless is an Open Source project, released under the Apache License 2.0 providing a portable and complete Serverless environment, allowing to build quickly and easily cloud-native applications.\nOur goal is to make OpenServerless ubitiquous, allowing it to easily run a complete and portable environment that runs in every Kubernetes.\nOpenServerless is based on Apache OpenWhisk, which provides a powerful, production-ready serverless engine.\nHowever, the serverless engine is just the beginning, because a serverless environment requires a set of integrated services.\nOpenServerless provides integrated with OpenWhisk several additional services such as databases, object storage, and a cron scheduler.\nFurthermore, we test it on many public cloud Kubernetes services and on-premises Kubernetes vendors.\nThe platform is paired with a powerful CLI tool, ops, which lets you deploy OpenServerless quickly and easily everywhere, and perform a lot of development tasks.\nOur goal is to build a complete distribution of a serverless environment with the following features:\nIt is easy to install and manage.\nIntegrates all the key services to build applications.\nIt is as portable as possible to run potentially in every Kubernetes.\nIt is however tested regularly against a set of supported Kubernetes environments.\nIf you want to know more about our goals, check our roadmap document.\n","categories":"","description":"","excerpt":"About Apache OpenServerless Apache OpenServerless is an Open Source …","ref":"/docs/","tags":"","title":"Docs"},{"body":"First steps Starting at the Front Right now, after a fresh installation, and after added the opstutorial user, if we visit the \u003capihost\u003e you will see a very simple page with:\nWelcome to Nuvolaris static content distributor landing page!!!\nThat’s because we’ve activated the static content, and by default it starts with this simple index.html page. We will instead have our own index page that shows the users a contact form powered by OpenServerless actions. Let’s write it now.\nLet’s create a folder that will contain all of our app code: contact_us_app.\n💡 NOTE\nYou can find the full source code of the tutorial at this GitHub Repository: Contact Us App.\nThe repository has a tag for each step. So after cloning it in your local directory, follow the istruction on it’s README page.\nInside that create two new folders called web, which will store our static frontend, and packages, which will store our backend actions. Inside the web folder an index.html file.\nThe directory structure should look like:\ncontact_us_app ├── packages └── web └── index.html Paste the following markup inside the index.html file:\n\u003c!DOCTYPE html\u003e \u003chtml lang=\"it\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1\"\u003e \u003ctitle\u003eGet In Touch\u003c/title\u003e \u003clink href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\"\u003e \u003c/head\u003e \u003cbody\u003e \u003cnav class=\"navbar navbar-dark bg-dark\"\u003e \u003cdiv class=\"container\"\u003e \u003ca class=\"navbar-brand\" href=\"#\"\u003eApache OpenServerless™ Tutorial\u003c/a\u003e \u003c/div\u003e \u003c/nav\u003e \u003cdiv class=\"container d-flex justify-content-center align-items-center\" style=\"min-height: 80vh;\"\u003e \u003cdiv class=\"w-50 p-4 border rounded bg-light shadow\"\u003e \u003ch2 class=\"text-center mb-4\"\u003eGet In Touch\u003c/h2\u003e \u003cform\u003e \u003cdiv class=\"mb-3\"\u003e \u003clabel for=\"name\" class=\"form-label\"\u003eName\u003c/label\u003e \u003cinput type=\"text\" class=\"form-control\" id=\"name\" name=\"name\" placeholder=\"Insert your name\"\u003e \u003c/div\u003e \u003cdiv class=\"mb-3\"\u003e \u003clabel for=\"email\" class=\"form-label\"\u003eEmail\u003c/label\u003e \u003cinput type=\"email\" class=\"form-control\" id=\"email\" name=\"email\" placeholder=\"Insert your email\"\u003e \u003c/div\u003e \u003cdiv class=\"mb-3\"\u003e \u003clabel for=\"phone\" class=\"form-label\"\u003ePhone Number\u003c/label\u003e \u003cinput type=\"tel\" class=\"form-control\" id=\"phone\" name=\"phone\" placeholder=\"Insert you phone number\"\u003e \u003c/div\u003e \u003cdiv class=\"mb-3\"\u003e \u003clabel for=\"message\" class=\"form-label\"\u003eMessage\u003c/label\u003e \u003ctextarea class=\"form-control\" id=\"message\" name=\"message\" rows=\"4\" placeholder=\"Type here your message\"\u003e\u003c/textarea\u003e \u003c/div\u003e \u003cbutton type=\"submit\" class=\"btn btn-primary w-100\"\u003eSend !\u003c/button\u003e \u003c/form\u003e \u003c/div\u003e \u003c/div\u003e \u003cscript src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js\"\u003e\u003c/script\u003e \u003c/body\u003e \u003c/html\u003e ⚠ WARNING\nBefore move on, be sure to have completed once the login as indicated here\nNow we just have to upload it to our OpenServerless deployment. You could upload it using something like curl with a PUT to where your platform is deployed at, but there is an handy command that does it automatically for all files in a folder:\nops ide deploy The output will be:\n\u003e Scan: \u003e Deploying: build process exited with code 0 UPLOAD ASSETS FROM web ==================| UPLOAD RESULTS |================== | FILES : 1 | COMPLETED : 1 | ERRORS : 0 | SKIPPED : 0 | EXEC. TIME : 37.83 ms ====================================================== URL: http://opstutorial.localhost:80 The command will scan both packages and web directories and will upload the index.html to the web bucket. Finally it will show the URL where the frontend have been published. If you visit the URL within your browser, you should see the new index page:\nDevelopment Tools Apache OpenServerless has a set of development tools, inside the ops ide command, details of which are available in this section of the guide.\nAs shown before, we will be using ops ide for publishing, as this make the process quicker and easier.\nThe command ops ide login will enable the development tools.\n","categories":"","description":"Move your first steps on Apache Openserverless","excerpt":"Move your first steps on Apache Openserverless","ref":"/docs/tutorial/first-steps/","tags":"","title":"First steps"},{"body":"Server Installation This page describes how to install OpenServerless on a Linux server accessible with SSH.\nThis is a single node installation, so it is advisable only for development purposes.\nPrerequisites Before installing, you need to:\ninstall the OpenServerless CLI ops;\nprovision a server running a Linux operating system, either a virtual machine or a physical server, and you know its IP address or DNS name;\nconfigure it to have passwordless ssh access and sudo rights;\nopen the firewall to have access to ports 80, 443 and 6443 or 16443 from your client machine;\nconfigure the DNS name for the server and choose the services you want to enable;\nInstallation If the prerequisites are satisfied, execute the dommand:\nops setup server \u003cserver\u003e \u003cuser\u003e ❗ IMPORTANT\nReplace in the command before \u003cserver\u003e with the IP address or DNS name used to access the server, and \u003cuser\u003e with the username you have to use to access the server\nWait until the command completes and you will have OpenServerless up and running.\nPost Install Check the tutorial to learn how to use it.\nTo uninstall, execute the command:\nops setup server \u003cserver\u003e \u003cuser\u003e --uninstall ","categories":"","description":"Install on a Linux Server","excerpt":"Install on a Linux Server","ref":"/docs/installation/install/server/","tags":"","title":"Linux Server"},{"body":"Prerequisites to install OpenServerless in a Linux server You can install OpenServerless on any server either in your intranet or on in Internet running a Linux distribution, with the following requirements:\nYou know the IP address or DNS name of the server on Internet or in your Intranet.\nThe server requires at least 8GB of memory and 30GB of disk space available.\nIt should be running a Linux distribution supported by K3S.\nYou must open the firewall to access ports 80, 443 and 6443 (for K3S) or 16443 (for MicroK8S) from your machine.\nYou have to install a public ssh key to access it without a password.\nYou have to configure sudo to execute root commands without a password.\nYou can:\nget a server on any cloud provider or even install by yourself and then configure it\nprovision such a server with ops on Amazon Web Services\nprovision such a server with ops on on Google Cloud Platform\nOnce you have such a server you can optionally (it is not required) install K3S or MicroK8S in it.\nOnce you have configured you server, you can proceed configuring OpenServerless for the installation.\n","categories":"","description":"Install OpenServerless in a Linux server","excerpt":"Install OpenServerless in a Linux server","ref":"/docs/installation/prereq/server/","tags":"","title":"Linux Server"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/news/","tags":"","title":"News"},{"body":"Prerequisites to install OpenServerless This page lists the prerequisites to install OpenServerless in various environments.\nYou can install OpenServerless:\nfor development in a single node environment, either in your local machine or in a Linux server.\nfor production, in a multi node environment provided by a Kubernetes cluster.\nSingle Node development installation For development purposes, you can install a single node OpenServerless deployment in the following environments as soon as the following requirements are satisfied:\nTo install in your local machine, you need Docker Desktop\nTo install in a single node Linux server, you need a server with passwordless ssh access and sudo.\nOur installer can automatically install a Kubernetes environment, using K3S, but if you prefer you can install a single-node Kubernetes instance by yourself.\nIf you choose to install Kubernetes on your server, we provide support for:\nSuSE K3S\nCanonical MicroK8S\nMulti Node production installation For production purposes, you need a multi-node Kubernetes cluster that satisfies those requirements, accessible with its kubeconfig file.\nIf you have such a cluster, you can install OpenServerless in a Kubernetes cluster\nIf you do not have a cluster and you need to setup one, we provide support for provisioning a suitable cluster that satisfied our requirements for the following Kubernetes environments:\nEKS in Amazon AWS\nAKS in Microsoft Azure\nGKE in Google Cloud\nRedHat OpenShift\nOnce you have a suitable Kubernetes cluster, you can proceed installing OpenServerless.\n","categories":"","description":"","excerpt":"Prerequisites to install OpenServerless This page lists the …","ref":"/docs/installation/prereq/","tags":"","title":"Prerequisites"},{"body":"Provision a Linux server in Amazon Web Services You can provision a server suitable to install OpenServerless in cloud provider Amazon Web Services ops as follows:\ninstall aws, the AWS CLI\nget Access and Secret Key\nconfigure AWS\nprovision a server\nretrieve the ip address to configure a DNS name\nOnce you have a Linux server up and running you can proceed configuring and installing OpenServerless.\nInstalling the AWS CLI Our cli ops uses under the hood the AWS CLI version 2, so you need to dowload and install it following those instructions.\nOnce installed, ensure it is available on the terminal executing the following command:\naws --version you should receive something like this:\naws-cli/2.9.4 Python/3.9.11 Linux/5.19.0-1025-aws exe/x86_64.ubuntu.22 prompt/off Ensure the version is at least 2.\nGetting the Access and Secret key Next step is to retrieve credentials, in the form of an access key and a secret key.\nSo you need to:\naccess the AWS console following those instructions create an access key and secret key; give to the credentials the minimum required permissions as described here to build an EKS cluster. You will end up with a couple of string as follows:\nSample AWS Access Key ID: AKIAIOSFODNN7EXAMPLE Sample AWS Secret Access Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY Take note of them as you need them for configuring out CLI.\nConfigure AWS to provision a server Before you can provision a Linux server you have to configure AWS typing the command:\nops config aws The system will then ask the following questions:\n*** Please, specify AWS Access Id and press enter. AKIAIOSFODNN7EXAMPLE *** Please, specify AWS Secret Key and press enter. wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY *** Please, specify AWS Region to use and press enter. To get a list of valid values use: aws ec2 describe-regions --output table Just press enter for default [us-east-1]: *** Please, specify AWS public SSH key and press enter. If you already have a public SSH key in AWS, provide its name here. If you do not have it, generate a key pair with the following command: ssh-keygen The public key defaults to ~/.ssh/id_rsa.pub and you can import with: aws ec2 import-key-pair --key-name nuvolaris-key --public-key-material --region=\u003cyour-region\u003e fileb://~/.ssh/id_rsa.pub Just press enter for default [devkit-74s]: *** Please, specify AWS Image to use for VMs and press enter. The suggested image is an Ubuntu 22 valid only for us-east-1 Please check AWS website for alternative images in other zones Just press enter for default [ami-052efd3df9dad4825]: *** Please, specify AWS Default user for image to use for VMs and press enter. Default user to access the selected image. Just press enter for default [ubuntu]: *** Please, specify AWS Instance type to use for VMs and press enter. The suggested instance type has 8GB and 2vcp To get a list of valid values, use: aws ec2 describe-instance-types --query 'InstanceTypes[].InstanceType' --output table Just press enter for default [t3a.large]: *** Please, specify AWS Disk Size to use for VMs and press enter. Just press enter for default [100]: Provision a server You can provision one or more servers using ops. The servers will use the parameters you have just configured.\nYou can create a new server with:\nops cloud aws vm-create \u003cserver-name\u003e ❗ IMPORTANT\nReplace \u003cserver-name\u003e with a name you choose, for example ops-server\nThe command will create a new server in AWS with the parameters you specified in configuration.\nYou can also:\nlist servers you created with ops cloud aws vm-list\ndelete a server you created and you do not need anymore with ops cloud aws vm-delete \u003cserver-name\u003e\nRetrieve IP The server will be provisioned with an IP address assigned by AWS.\nYou can read the IP address of your server with\nops cloud aws vm-getip \u003cserver-name\u003e You need this IP when configuring a DNS name for the server.\n","categories":"","description":"Prerequisites to install OpenServerless in AWS","excerpt":"Prerequisites to install OpenServerless in AWS","ref":"/docs/installation/prereq/server/aws/","tags":"","title":"Server on AWS"},{"body":"Provision a Linux server in Azure Cloud Platform You can provision a server suitable to install OpenServerless in cloud provider Azure ops as follows:\ninstall az, the Azure CLI\nget Access and Secret Key\nconfigure Azure\nprovision a server\nretrieve the ip address to configure a DNS name\nOnce you have a Linux server up and running you can proceed configuring and installing OpenServerless.\nInstalling the Azure CLI Our cli ops uses under the hood the az, command so you need to dowload and install it following those instructions.\nOnce installed, ensure it is available on the terminal executing the following command:\naz version you should receive something like this:\n{ \"azure-cli\": \"2.64.0\", \"azure-cli-core\": \"2.64.0\", \"azure-cli-telemetry\": \"1.1.0\", \"extensions\": { \"ssh\": \"2.0.5\" } } Ensure the version is at least 2.64.0\nConnect a subscription Next step is to connect az to a valid Azure subscription. Azure supports several authentication methods: check which one you prefer.\nThe easiest is the one described in Sign in interactively:\naz login\nThis will open a browser and you will asked to login to you azure account. Once logged in, the az command will be automatically connected to the choosen subscription.\nTo check if the az command is properly connected to your subscription, check the output of this command:\n$ az account list --query \"[].{subscriptionId: id, name: name, user: user.name}\" --output table SubscriptionId Name User ------------------------------------ --------------------------- ------------------------- xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxxx Microsoft Azure Sponsorship openserverless@apache.org Configuring Azure to provision a server Before you can provision a Linux server you have to configure Openserverless for Azure typing the command:\nops config azcloud The system will then ask the following questions:\n*** Please, specify Azure Project Id and press enter. Azure Project Id: openserverless-k3s *** Please, specify Azure Zone and press enter. To get a list of valid values use: az account list-locations -o table Just press enter for default [eastus]: Azure Zone: *** Please, specify Azure virtual machine type and press enter. To get a list of valid values, use: az vm list-sizes --location \u003clocation\u003e -o table where \u003clocation\u003e is your current location. Just press enter for default [Standard_B4ms]: Azure virtual machine type: *** Please, specify Azure vm disk size in gigabyte and press enter. Just press enter for default [50]: Azure vm disk size in gigabyte: *** Please, specify Azure Cloud public SSH key and press enter. If you already have a public SSH key provide its path here. If you do not have it, generate a key pair with the following command: ssh-keygen The public key defaults to ~/.ssh/id_rsa.pub. Just press enter for default [~/.ssh/id_rsa.pub]: Azure Cloud public SSH key: *** Please, specify Azure Cloud VM image and press enter. Just press enter for default [Ubuntu2204]: Azure Cloud VM image: Provision a server You can provision one or more servers using ops. The servers will use the parameters you have just configured.\nYou can create a new server with:\nops cloud azcloud vm-create \u003cserver-name\u003e ❗ IMPORTANT\nReplace \u003cserver-name\u003e with a name you choose, for example ops-server\nThe command will create a new server in Azure Cloud with the parameters you specified in configuration.\nYou can also:\nlist servers you created with ops cloud azcloud vm-list\ndelete a server you created and you do not need anymore with ops cloud azcloud vm-delete \u003cserver-name\u003e\nRetrieve IP The server will be provisioned with an IP address assigned by Azure Cloud.\nYou can read the IP address of your server with\nops cloud azcloud vm-getip \u003cserver-name\u003e You need this IP when configuring a DNS name for the server.\n","categories":"","description":"Prerequisites to install OpenServerless in Azure","excerpt":"Prerequisites to install OpenServerless in Azure","ref":"/docs/installation/prereq/server/azure/","tags":"","title":"Server on Azure"},{"body":"What web actions are Web actions are OpenWhisk and OpenServerless actions annotated to quickly enable you to build web based applications. This allows you to program backend logic which your web application can access anonymously without requiring an OpenWhisk and OpenServerless authentication key. It is up to the action developer to implement their own desired authentication and authorization (i.e.OAuth flow).\nWeb action activations will be associated with the user that created the action. This actions defers the cost of an action activation from the caller to the owner of the action.\nLet’s take the following JavaScript action hello.js,\n$ cat hello.js function main({name}) { var msg = 'you did not tell me who you are.'; if (name) { msg = `hello ${name}!` } return {body: `\u003chtml\u003e\u003cbody\u003e\u003ch3\u003e${msg}\u003c/h3\u003e\u003c/body\u003e\u003c/html\u003e`} } You may create a web action hello in the package demo for the namespace guest using the CLI’s --web flag with a value of true or yes:\n$ ops package create demo ok: created package demo $ ops action create demo/hello hello.js --web true ok: created action demo/hello $ ops action get demo/hello --url ok: got action hello https://${APIHOST}/api/v1/web/guest/demo/hello Using the --web flag with a value of true or yes allows an action to be accessible via REST interface without the need for credentials. A web action can be invoked using a URL that is structured as follows:\nhttps://{APIHOST}/api/v1/web/{QUALIFIED ACTION NAME}.{EXT}` The fully qualified name of an action consists of three parts: the namespace, the package name, and the action name.\nThe fully qualified name of the action must include its package name, which is default if the action is not in a named package.\nAn example is guest/demo/hello. The last part of the URI called the extension which is typically .http although other values are permitted as described later. The web action API path may be used with curl or wget without an API key. It may even be entered directly in your browser.\nTry opening:\nhttps://${APIHOST}/api/v1/web/guest/demo/hello.http?name=Jane in your web browser. Or try invoking the action via curl:\ncurl https://${APIHOST}/api/v1/web/guest/demo/hello.http?name=Jane Here is an example of a web action that performs an HTTP redirect:\nfunction main() { return { headers: { location: 'http://openwhisk.org' }, statusCode: 302 } } Or sets a cookie:\nfunction main() { return { headers: { 'Set-Cookie': 'UserID=Jane; Max-Age=3600; Version=', 'Content-Type': 'text/html' }, statusCode: 200, body: '\u003chtml\u003e\u003cbody\u003e\u003ch3\u003ehello\u003c/h3\u003e\u003c/body\u003e\u003c/html\u003e' } } Or sets multiple cookies:\nfunction main() { return { headers: { 'Set-Cookie': [ 'UserID=Jane; Max-Age=3600; Version=', 'SessionID=asdfgh123456; Path = /' ], 'Content-Type': 'text/html' }, statusCode: 200, body: '\u003chtml\u003e\u003cbody\u003e\u003ch3\u003ehello\u003c/h3\u003e\u003c/body\u003e\u003c/html\u003e' } } Or returns an image/png:\nfunction main() { let png = \u003cbase 64 encoded string\u003e return { headers: { 'Content-Type': 'image/png' }, statusCode: 200, body: png }; } Or returns application/json:\nfunction main(params) { return { statusCode: 200, headers: { 'Content-Type': 'application/json' }, body: params }; } The default content-type for an HTTP response is application/json and the body may be any allowed JSON value. The default content-type may be omitted from the headers.\nIt is important to be aware of the response size limit for actions since a response that exceeds the predefined system limits will fail. Large objects should not be sent inline through OpenWhisk and OpenServerless, but instead deferred to an object store, for example.\nHandling HTTP requests with actions An OpenWhisk and OpenServerless action that is not a web action requires both authentication and must respond with a JSON object. In contrast, web actions may be invoked without authentication, and may be used to implement HTTP handlers that respond with headers, statusCode, and body content of different types. The web action must still return a JSON object, but the OpenWhisk and OpenServerless system (namely the controller) will treat a web action differently if its result includes one or more of the following as top level JSON properties:\nheaders: a JSON object where the keys are header-names and the values are string, number, or boolean values for those headers (default is no headers). To send multiple values for a single header, the header’s value should be a JSON array of values.\nstatusCode: a valid HTTP status code (default is 200 OK if body is not empty otherwise 204 No Content).\nbody: a string which is either plain text, JSON object or array, or a base64 encoded string for binary data (default is empty response).\nThe body is considered empty if it is null, the empty string \"\" or undefined.\nThe controller will pass along the action-specified headers, if any, to the HTTP client when terminating the request/response. Similarly the controller will respond with the given status code when present. Lastly, the body is passed along as the body of the response. If a content-type header is not declared in the action result’s headers, the body is interpreted as application/json for non-string values, and text/html otherwise. When the content-type is defined, the controller will determine if the response is binary data or plain text and decode the string using a base64 decoder as needed. Should the body fail to decoded correctly, an error is returned to the caller.\nHTTP Context All web actions, when invoked, receives additional HTTP request details as parameters to the action input argument. They are:\n__ow_method (type: string): the HTTP method of the request.\n__ow_headers (type: map string to string): the request headers.\n__ow_path (type: string): the unmatched path of the request (matching stops after consuming the action extension).\n__ow_user (type: string): the namespace identifying the OpenWhisk and OpenServerless authenticated subject.\n__ow_body (type: string): the request body entity, as a base64 encoded string when content is binary or JSON object/array, or plain string otherwise.\n__ow_query (type: string): the query parameters from the request as an unparsed string.\nA request may not override any of the named __ow_ parameters above; doing so will result in a failed request with status equal to 400 Bad Request.\nThe __ow_user is only present when the web action is annotated to require authentication and allows a web action to implement its own authorization policy. The __ow_query is available only when a web action elects to handle the “raw” HTTP request. It is a string containing the query parameters parsed from the URI (separated by \u0026). The __ow_body property is present either when handling “raw” HTTP requests, or when the HTTP request entity is not a JSON object or form data. Web actions otherwise receive query and body parameters as first class properties in the action arguments with body parameters taking precedence over query parameters, which in turn take precedence over action and package parameters.\nAdditional features Web actions bring some additional features that include:\nContent extensions: the request must specify its desired content type as one of.json,.html,.http, .svg or .text. This is done by adding an extension to the action name in the URI, so that an action /guest/demo/hello is referenced as /guest/demo/hello.http for example to receive an HTTP response back. For convenience, the .http extension is assumed when no extension is detected.\nQuery and body parameters as input: the action receives query parameters as well as parameters in the request body. The precedence order for merging parameters is: package parameters, binding parameters, action parameters, query parameter, body parameters with each of these overriding any previous values in case of overlap . As an example /guest/demo/hello.http?name=Jane will pass the argument {name: \"Jane\"} to the action.\nForm data: in addition to the standard application/json, web actions may receive URL encoded from data application/x-www-form-urlencoded data as input.\nActivation via multiple HTTP verbs: a web action may be invoked via any of these HTTP methods: GET, POST, PUT, PATCH, and DELETE, as well as HEAD and OPTIONS.\nNon JSON body and raw HTTP entity handling: A web action may accept an HTTP request body other than a JSON object, and may elect to always receive such values as opaque values (plain text when not binary, or base64 encoded string otherwise).\nThe example below briefly sketches how you might use these features in a web action. Consider an action /guest/demo/hello with the following body:\nfunction main(params) { return { response: params }; } This is an example of invoking the web action using the .json extension, indicating a JSON response.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json { \"response\": { \"__ow_method\": \"get\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } You can supply query parameters.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json?name=Jane { \"response\": { \"name\": \"Jane\", \"__ow_method\": \"get\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } You may use form data as input.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json -d \"name\":\"Jane\" { \"response\": { \"name\": \"Jane\", \"__ow_method\": \"post\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"content-length\": \"10\", \"content-type\": \"application/x-www-form-urlencoded\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } You may also invoke the action with a JSON object.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json -H 'Content-Type: application/json' -d '{\"name\":\"Jane\"}' { \"response\": { \"name\": \"Jane\", \"__ow_method\": \"post\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"content-length\": \"15\", \"content-type\": \"application/json\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } You see above that for convenience, query parameters, form data, and JSON object body entities are all treated as dictionaries, and their values are directly accessible as action input properties. This is not the case for web actions which opt to instead handle HTTP request entities more directly, or when the web action receives an entity that is not a JSON object.\nHere is an example of using a “text” content-type with the same example shown above.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json -H 'Content-Type: text/plain' -d \"Jane\" { \"response\": { \"__ow_method\": \"post\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"content-length\": \"4\", \"content-type\": \"text/plain\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\", \"__ow_body\": \"Jane\" } } Content extensions A content extension is generally required when invoking a web action; the absence of an extension assumes .http as the default. The fully qualified name of the action must include its package name, which is default if the action is not in a named package.\nProtected parameters Action parameters are protected and treated as immutable. Parameters are automatically finalized when enabling web actions.\n$ ops action create /guest/demo/hello hello.js \\ --parameter name Jane \\ --web true The result of these changes is that the name is bound to Jane and may not be overridden by query or body parameters because of the final annotation. This secures the action against query or body parameters that try to change this value whether by accident or intentionally.\nSecuring web actions By default, a web action can be invoked by anyone having the web action’s invocation URL. Use the require-whisk-auth web action annotation to secure the web action. When the require-whisk-auth annotation is set to true, the action will authenticate the invocation request’s Basic Authorization credentials to confirm they represent a valid OpenWhisk and OpenServerless identity. When set to a number or a case-sensitive string, the action’s invocation request must include a X-Require-Whisk-Auth header having this same value. Secured web actions will return a Not Authorized when credential validation fails.\nAlternatively, use the --web-secure flag to automatically set the require-whisk-auth annotation. When set to true a random number is generated as the require-whisk-auth annotation value. When set to false the require-whisk-auth annotation is removed. When set to any other value, that value is used as the require-whisk-auth annotation value.\nops action update /guest/demo/hello hello.js --web true --web-secure my-secret or\nops action update /guest/demo/hello hello.js --web true -a require-whisk-auth my-secret curl https://${APIHOST}/api/v1/web/guest/demo/hello.json?name=Jane -X GET -H \"X-Require-Whisk-Auth: my-secret\" It’s important to note that the owner of the web action owns all of the web action’s activations records and will incur the cost of running the action in the system regardless of how the action was invoked.\nDisabling web actions To disable a web action from being invoked via web API (https://APIHOST/api/v1/web/), pass a value of false or no to the --web flag while updating an action with the CLI.\nops action update /guest/demo/hello hello.js --web false Raw HTTP handling A web action may elect to interpret and process an incoming HTTP body directly, without the promotion of a JSON object to first class properties available to the action input (e.g., args.name vs parsing args.__ow_query). This is done via a raw-http annotation. Using the same example show earlier, but now as a “raw” HTTP web action receiving name both as a query parameters and as JSON value in the HTTP request body:\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json?name=Jane -X POST -H \"Content-Type: application/json\" -d '{\"name\":\"Jane\"}' { \"response\": { \"__ow_method\": \"post\", \"__ow_query\": \"name=Jane\", \"__ow_body\": \"eyJuYW1lIjoiSmFuZSJ9\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"content-length\": \"15\", \"content-type\": \"application/json\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } Enabling raw HTTP handling Raw HTTP web actions are enabled via the --web flag using a value of raw.\nops action create /guest/demo/hello hello.js --web raw Disabling raw HTTP handling Disabling raw HTTP can be accomplished by passing a value of false or no to the --web flag.\nops update create /guest/demo/hello hello.js --web false Decoding binary body content from Base64 When using raw HTTP handling, the __ow_body content will be encoded in Base64 when the request content-type is binary. Below are functions demonstrating how to decode the body content in Node, Python, and PHP. Simply save a method shown below to file, create a raw HTTP web action utilizing the saved artifact, and invoke the web action.\nNode function main(args) { decoded = new Buffer(args.__ow_body, 'base64').toString('utf-8') return {body: decoded} } Python def main(args): try: decoded = args['__ow_body'].decode('base64').strip() return {\"body\": decoded} except: return {\"body\": \"Could not decode body from Base64.\"} PHP \u003c?php function main(array $args) : array { $decoded = base64_decode($args['__ow_body']); return [\"body\" =\u003e $decoded]; } As an example, save the Node function as decode.js and execute the following commands:\n$ ops action create decode decode.js --web raw ok: created action decode $ curl -k -H \"content-type: application\" -X POST -d \"Decoded body\" https://${APIHOST}/api/v1/web/guest/default/decodeNode.json { \"body\": \"Decoded body\" } Options Requests By default, an OPTIONS request made to a web action will result in CORS headers being automatically added to the response headers. These headers allow all origins and the options, get, delete, post, put, head, and patch HTTP verbs. In addition, the header Access-Control-Request-Headers is echoed back as the header Access-Control-Allow-Headers if it is present in the HTTP request. Otherwise, a default value is generated as shown below.\nAccess-Control-Allow-Origin: * Access-Control-Allow-Methods: OPTIONS, GET, DELETE, POST, PUT, HEAD, PATCH Access-Control-Allow-Headers: Authorization, Origin, X-Requested-With, Content-Type, Accept, User-Agent Alternatively, OPTIONS requests can be handled manually by a web action. To enable this option add a web-custom-options annotation with a value of true to a web action. When this feature is enabled, CORS headers will not automatically be added to the request response. Instead, it is the developer’s responsibility to append their desired headers programmatically. Below is an example of creating custom responses to OPTIONS requests.\nfunction main(params) { if (params.__ow_method == \"options\") { return { headers: { 'Access-Control-Allow-Methods': 'OPTIONS, GET', 'Access-Control-Allow-Origin': 'example.com' }, statusCode: 200 } } } Save the above function to custom-options.js and execute the following commands:\n$ ops action create custom-option custom-options.js --web true -a web-custom-options true $ curl https://${APIHOST}/api/v1/web/guest/default/custom-options.http -kvX OPTIONS \u003c HTTP/1.1 200 OK \u003c Server: nginx/1.11.13 \u003c Content-Length: 0 \u003c Connection: keep-alive \u003c Access-Control-Allow-Methods: OPTIONS, GET \u003c Access-Control-Allow-Origin: example.com Web Actions in Shared Packages A web action in a shared (i.e., public) package is accessible as a web action either directly via the package’s fully qualified name, or via a package binding. It is important to note that a web action in a public package will be accessible for all bindings of the package even if the binding is private. This is because the web action annotation is carried on the action and cannot be overridden. If you do not wish to expose a web action through your package bindings, then you should clone-and-own the package instead.\nAction parameters are inherited from its package, and the binding if there is one. You can make package parameters immutable by defining their values through a package binding.\nError Handling When an OpenWhisk and OpenServerless action fails, there are two different failure modes. The first is known as an application error and is analogous to a caught exception: the action returns a JSON object containing a top level error property. The second is a developer error which occurs when the action fails catastrophically and does not produce a response (this is similar to an uncaught exception). For web actions, the controller handles application errors as follows:\nThe controller projects an error property from the response object.\nThe controller applies the content handling implied by the action extension to the value of the error property.\nDevelopers should be aware of how web actions might be used and generate error responses accordingly. For example, a web action that is used with the .http extension should return an HTTP response, for example: {error: { statusCode: 400 }. Failing to do so will in a mismatch between the implied content-type from the extension and the action content-type in the error response. Special consideration must be given to web actions that are sequences, so that components that make up a sequence can generate adequate errors when necessary.\n","categories":"","description":"Actions annotated to quickly build web based applications","excerpt":"Actions annotated to quickly build web based applications","ref":"/docs/reference/entities/webactions/","tags":"","title":"Web Actions"},{"body":"Activations When an event occurs that triggers a function, ops creates an activation record, which contains information about the function execution, such as input parameters, output results, and any metadata associated with the activation. It’s something similar to the classic concept of log.\nHow activations work When invoking an action with ops action invoke, you’ll receive only an invocation id as an answer.\nThis invocation id allows you to read results and outputs produced by the execution of an action.\nLet’s demonstrate how it works by modifying the hello.js file to add a command to log some output.\nfunction main(args) { console.log(\"Hello\") return { \"body\": \"Hello\" } } Now, let’s deploy and invoke it (with a parameter hello=world) to get the activation id:\n$ ops action update demo/hello hello.js ok: updated action demo/hello $ ops action invoke demo/hello ok: invoked /_/demo/hello with id 0367e39ba7c74268a7e39ba7c7126846 Associated with every invocation, there is an activation id (in the example, it is 0367e39ba7c74268a7e39ba7c7126846).\nWe use this id to retrieve the results of the invocation with ops activation result or its shortcut, just ops result, and we can retrieve the logs using ops activation logs or just ops logs.\n$ ops result 0367e39ba7c74268a7e39ba7c7126846 { \"body\": \"Hello\" } $ ops logs 0367e39ba7c74268a7e39ba7c7126846 2024-02-17T20:01:31.901124753Z stdout: Hello List of activations You can list the activations with ops activation list and limit the number with --limit if you are interested in a subset.\n$ ops activation list --limit 5 Datetime Activation ID Kind Start Duration Status Entity 2024-02-17 20:01:31 0367e39ba7c74268a7e39ba7c7126846 nodejs:18 warm 8ms success dashboard/hello:0.0.1 2024-02-17 20:00:00 f4f82ee713444028b82ee71344b0287d nodejs:18 warm 5ms success dashboard/hello:0.0.1 2024-02-17 19:59:54 98d19fe130da4e93919fe130da7e93cb nodejs:18 cold 33ms success dashboard/hello:0.0.1 2024-02-17 17:40:53 f25e1f8bc24f4f269e1f8bc24f1f2681 python:3 warm 3ms success dashboard/index:0.0.2 2024-02-17 17:35:12 bed3213547cc4aed93213547cc8aed8e python:3 warm 2ms success dashboard/index:0.0.2 Note also the --since option, which is useful to show activations from a given timestamp (you can obtain a timestamp with date +%s).\nSince it can be quite annoying to keep track of the activation id, there are two useful alternatives.\nWith ops result --last and ops logs --last, you can retrieve just the last result or log.\nPolling activations With ops activation poll, the CLI starts a loop and displays all the activations as they happen.\n$ ops activation poll Enter Ctrl-c to exit. Polling for activation logs Conclusion Activations provide a way to monitor and track the execution of functions, enabling understanding of how code behaves in response to different events and allowing for debugging and optimizing serverless applications.\n","categories":"","description":"Detailed records of action executions","excerpt":"Detailed records of action executions","ref":"/docs/cli/entities/activations/","tags":"","title":"Activations"},{"body":"OpenServerless CLI The ops command is the command line interface to OpenServerless\nIt let’s you to install and manipulate the components of the system.\nIf it is not already included in the development environment provided you can download the CLI suitable for your platform from here, and install it\nLogin into the system To start working with you have to login in some OpenServerless installation.\nThe administrator should have provided with username, password and the URL to access the system.\nFor example, let’s assume you are the user mirella and the system is available on https://nuvolaris.dev.\nIn order to login type the following command and enter you password.\nops -login https://nuvolaris.dev mirella Enter Password: If the password is correct you are logged in the system and you can use the commands described below.\nNext Steps Once logged in, you can:\nlearn how to manage OpenServerless entities\nlearn how to deploy projects and web assets\nlearn how to administer the system and debug the system\n","categories":"","description":"An handy command line to interact with all parts of OpenServerless","excerpt":"An handy command line to interact with all parts of OpenServerless","ref":"/docs/cli/","tags":"","title":"CLI"},{"body":"Configuring OpenServerless Installation This section guides configuring the OpenServerless installation.\nNote that you can also skip this configuration, and install OpenServerless without any configuration.\nOnce you configure the installation, you can proceed to Install OpenServerless.\nYou can then reconfigure the system later.\nMinimal Configuration Without any configuration, you get a minimal OpenServerless:\nonly the serverless engine, no extra services\naccessible is only in http\nYou can:\nconfigure a DNS name or wildcard for your server or cluster, thus enabling SSL and static publishing.\nenable some or all of the integrated services:\nStatic, publishing of static content\nREDIS, a powerful key-value store\nMinIO, an object storage\nPostgres, a powerful SQL database\nFerretDB a NO-SQL, MongoDB compatible adapter for Postgres\n","categories":"","description":"","excerpt":"Configuring OpenServerless Installation This section guides …","ref":"/docs/installation/configure/","tags":"","title":"Configure OpenServerless"},{"body":"The Contact Package The contact form we just uploaded does not do anything. To make it work let’s start to fill our package directory with backend actions.\nForm validation We well start to handle the form submission. We can do that by adding a new action that will be called when the form is submitted. Let’s create a submit.js file inside our packages/contact folder.\nYou directory structure should looks like this:\ncontact_us_app ├── packages │ └── contact │ └── submit.js └── web └── index.html Paste this content inside the submit.js file:\n//--web true //--kind nodejs:default function main(args) { let message = []; let errors = []; // TODO: Add here Form Validation code // TODO: Add here the code for returning the Result } This action is a bit more complex. It takes the input object (called args) which will contain the form data (accessible via args.name, args.email, etc.). With that. we will do some validation and then return the result.\n💡 NOTE\nYou may have noticed the strange comments at the beginning of the file. Those comments are used by ops ide to automatically handle the publishing of files by calling ops package or ops action as needed. In particular:\nthe --web true will enable this as a web action; --kind nodejs:default will ask OpenServerless to run this code on the nodejs default runtime. Validation Let’s start filling out the “Form Validation” part by checking the name:\n// validate the name if (args.name) { message.push(\"name: \" + args.name); } else { errors.push(\"No name provided\"); } Then the email by using a regular expression:\n// validate the email var re = /\\S+@\\S+\\.\\S+/; if (args.email \u0026\u0026 re.test(args.email)) { message.push(\"email: \" + args.email); } else { errors.push(\"Email missing or incorrect.\"); } The phone, by checking that it’s at least 10 digits:\n// validate the phone if (args.phone \u0026\u0026 args.phone.match(/\\d/g).length \u003e= 10) { message.push(\"phone: \" + args.phone); } else { errors.push(\"Phone number missing or incorrect.\"); } Finally, the message text, if present:\n// validate the message if (args.message) { message.push(\"message:\" + args.message); } Submission With the validation phase, we added to the “errors” array all the errors we found, and to the “message” array all the data we want to show to the user. So if there are errors, we have to show them, otherwise, we store the message and return a “thank you” page.\n// return the result if (errors.length) { var errs = \"\u003cul\u003e\u003cli\u003e\" + errors.join(\"\u003c/li\u003e\u003cli\u003e\") + \"\u003c/li\u003e\u003c/ul\u003e\"; return { body: \"\u003ch1\u003eErrors!\u003c/h1\u003e\" + errs + '\u003cbr\u003e\u003ca href=\"javascript:window.history.back()\"\u003eBack\u003c/a\u003e' }; } else { var data = \"\u003cpre\u003e\" + message.join(\"\\n\") + \"\u003c/pre\u003e\"; return { body: \"\u003ch1\u003eThank you!\u003c/h1\u003e\" + data, name: args.name, email: args.email, phone: args.phone, message: args.message }; } Note how this action is returning HTML code. Actions can return a { body: \u003chtml\u003e } kind of response and have their own url so they can be invoked via a browser and display some content.\nThe HTML code to display is always returned in the body field, but we can also return other stuff. In this case we added a a field for each of the form fields. This gives us the possibility to invoke in a sequence another action that can act just on those fields to store the data in the database.\nLet’s start deploying the action:\nops ide deploy You should see output like this:\n/home/openserverless/.ops/tmp/deploy.pid PID 70925 \u003e Scan: \u003e\u003e Action: packages/contact/submit.js \u003e Deploying: \u003e\u003e Package: contact $ $OPS package update contact ok: updated package contact \u003e\u003e\u003e Action: packages/contact/submit.js $ $OPS action update contact/submit packages/contact/submit.js --web true --kind python:default --param POSTGRES_URL $POSTGRES_URL ok: updated action contact/submit build process exited with code 0 UPLOAD ASSETS FROM web ==================| UPLOAD RESULTS |================== | FILES : 1 | COMPLETED : 1 | ERRORS : 0 | SKIPPED : 0 | EXEC. TIME : 40.76 ms ====================================================== URL: http://opstutorial.localhost:80 You can retrieve the url of the action with:\nops url contact/submit You should see this output:\nok: got action submit http://localhost:80/api/v1/web/opstutorial/contact/submit If you click on it you will see the Error page with a list of errors, that’s because we just invoked the submit logic for the contact form directly, without passing in any args. This is meant to be used via the contact form page!\nWe need to wire it into the index.html. So let’s open it again and add a couple of attributes to the form. Change the \u003cform\u003e tag as follow:\n\u003cform method=\"POST\" action=\"/api/v1/web/opstutorial/contact/submit\" enctype=\"application/x-www-form-urlencoded\"\u003e Upload the web folder again with the new changes:\nops ide deploy Now if you go to the contact form page the send button should work. It will invoke the submit action which in turn will return some html.\nIf you fill it correctly, you should see the “Thank you” page.\nNote how only the HTML from the body field is displayed, the other fields are ignored in this case.\nThe ops action command can be used for many more things besides creating actions. For example, you can use it to list all available actions:\nops action list actions /opstutorial/contact/submit private nodejs:21 And you can also get info on a specific action:\nops action get contact/submit ok: got action contact/submit { \"namespace\": \"opstutorial/contact\", \"name\": \"submit\", \"version\": \"0.0.1\", \"exec\": { \"kind\": \"nodejs:21\", \"binary\": false }, \"annotations\": [ { \"key\": \"web-export\", \"value\": true }, { \"key\": \"raw-http\", \"value\": false }, { \"key\": \"final\", \"value\": true }, { \"key\": \"provide-api-key\", \"value\": false }, { \"key\": \"exec\", \"value\": \"nodejs:21\" } ], \"parameters\": [ { \"key\": \"POSTGRES_URL\", \"value\": \"postgresql://opstutorial:\u003cpassword\u003e@nuvolaris-postgres.nuvolaris.svc.cluster.local:5432/opstutorial\" } ], ... } These commands can come in handy when you need to debug your actions.\nHere is the complete the submit.js action:\n//--web true //--kind nodejs:default function main(args) { let message = []; let errors = []; // validate the name if (args.name) { message.push(\"name: \" + args.name) } else { errors.push(\"No name provided\") } // validate the email var re = /\\S+@\\S+\\.\\S+/; if (args.email \u0026\u0026 re.test(args.email)) { message.push(\"email: \" + args.email); } else { errors.push(\"Email missing or incorrect.\"); } // validate the phone if (args.phone \u0026\u0026 args.phone.match(/\\d/g).length \u003e= 10) { message.push(\"phone: \" + args.phone); } else { errors.push(\"Phone number missing or incorrect.\"); } // validate the message if (args.message) { message.push(\"message:\" + args.message); } // return the result if (errors.length) { var errs = \"\u003cul\u003e\u003cli\u003e\" + errors.join(\"\u003c/li\u003e\u003cli\u003e\") + \"\u003c/li\u003e\u003c/ul\u003e\"; return { body: \"\u003ch1\u003eErrors!\u003c/h1\u003e\" + errs + '\u003cbr\u003e\u003ca href=\"javascript:window.history.back()\"\u003eBack\u003c/a\u003e' }; } else { var data = \"\u003cpre\u003e\" + message.join(\"\\n\") + \"\u003c/pre\u003e\"; return { body: \"\u003ch1\u003eThank you!\u003c/h1\u003e\" + data, name: args.name, email: args.email, phone: args.phone, message: args.message }; } } ","categories":"","description":"Learn how to add form validation from front to back-end","excerpt":"Learn how to add form validation from front to back-end","ref":"/docs/tutorial/form-validation/","tags":"","title":"Form validation"},{"body":"Installation Overview This page provides an overview of the installation process.\nBefore installation Please ensure you have:\ndownloaded the installer satisfied the prerequisites configured your installation Core Installation Once you have completed the preparation steps, you can proceed with:\na local installation on your local machine a single server installation on a Linux server a clustered installation on a Kubernetes cluster. 💡 NOTE\nThe install process will notify nuvolaris creators with the type of installation (for example: clustered or server installation), no other info will be submitted. If you want to disable the notification, you can execute the following command before the setup command:\nops -config DO_NOT_NOTIFY_NUVOLARIS=1 Post installation After the installation, you can consult the development guide for informations how to reconfigure and update the system.\nSupport If something goes wrong, you can check:\nthe Troubleshooting page our online Forum ","categories":"","description":"","excerpt":"Installation Overview This page provides an overview of the …","ref":"/docs/installation/install/","tags":"","title":"Install OpenServerless"},{"body":"Cluster Installation This section describes how to install OpenServerless on a Kubernetes Cluster\nPrerequisites Before installing, you need to:\nProvision a Kubernetes Cluster\nConfigure the installation\ninstall Download and install OpenServerless CLI, ops.\nInstallation If you have a Kubernetes cluster directly accessible with its configuration, or you provisioned a cluster in some cloud using ops embedded tools, you just need to type:\nops setup cluster Sometimes the kubeconfig includes access to multiple Kubernetes instances, each one identified by a different \u003ccontext\u003e name. You can install the OpenServerless cluster in a specified \u003ccontext\u003e with:\nops setup cluster \u003ccontext\u003e Post Install Check the tutorial to learn how to use it.\nTo uninstall, execute the command:\nops setup cluster --uninstall ","categories":"","description":"Install OpenServerless on a Kubernetes Cluster","excerpt":"Install OpenServerless on a Kubernetes Cluster","ref":"/docs/installation/install/cluster/","tags":"","title":"Kubernetes cluster"},{"body":"Prerequisites to install OpenServerless in a Kubernetes cluster You can install OpenServerless in any Kubernetes cluster which satisfy some requirements.\nKubernetes clusters are available pre-built from a variety of cloud providers. We provide with our ops tool the commands to install a Kubernetes cluster ready for OpenServerless in the following environments:\nAmazon EKS\nAzure AKS\nGoogle GKE\nRedHat OpenShift\nYou can also provision a suitable cluster by yourself, in any cloud or on premises, ensuring the prerequites are satisfied.\nOnce provisioned, you will receive a configuration file to access the cluster, called kubeconfig.\nThis file should be placed in ~/.kube/config to give access to the cluster\nIf you have this file, you can check if you have access to the cluster with the command:\nops debug kube info You should see something like this:\nKubernetes control plane is running at https://xxxxxx.yyy.us-east-1.eks.amazonaws.com Once you have got access to the Kubernetes cluster, either installing one with out commands or provisioning one by yourself, you can proceed configuring the installation and then installing OpenServerless in the cluster.\n","categories":"","description":"Install OpenServerless in a Kubernetes cluster","excerpt":"Install OpenServerless in a Kubernetes cluster","ref":"/docs/installation/prereq/kubernetes/","tags":"","title":"Kubernetes Cluster"},{"body":"The following sections provide more details about the OpenWhisk and OpenServerless system.\nEntities Namespaces and packages OpenWhisk and OpenServerless actions, triggers, and rules belong in a namespace, and optionally a package.\nPackages can contain actions and feeds. A package cannot contain another package, so package nesting is not allowed. Also, entities do not have to be contained in a package.\nIn OpenServerless a namespace corresponds to an user. You can create users with the admin subcommand of the CLI.\nThe fully qualified name of an entity is /namespaceName[/packageName]/entityName. Notice that / is used to delimit namespaces, packages, and entities.\nIf the fully qualified name has three parts: /namespaceName/packageName/entityName, then the namespace can be entered without a prefixed /; otherwise, namespaces must be prefixed with a /.\nFor convenience, the namespace can be left off if it is the user’s default namespace.\nFor example, consider a user whose default namespace is /myOrg. Following are examples of the fully qualified names of a number of entities and their aliases.\nFully qualified name Alias Namespace Package Name /whisk.system/cloudant/read\n/whisk.system\ncloudant\nread\n/myOrg/video/transcode\nvideo/transcode\n/myOrg\nvideo\ntranscode\n/myOrg/filter\nfilter\n/myOrg\nfilter\nYou will be using this naming scheme when you use the OpenWhisk and OpenServerless CLI, among other places.\nEntity names The names of all entities, including actions, triggers, rules, packages, and namespaces, are a sequence of characters that follow the following format:\nThe first character must be an alphanumeric character, or an underscore.\nThe subsequent characters can be alphanumeric, spaces, or any of the following: _, @, ., -.\nThe last character can’t be a space.\nMore precisely, a name must match the following regular expression (expressed with Java metacharacter syntax): \\A([\\w]|[\\w][\\w@ .-]*[\\w@.-]+)\\z.\nSystem limits Actions OpenWhisk and OpenServerless has a few system limits, including how much memory an action can use and how many action invocations are allowed per minute.\nNote: On Openwhisk 2.0 with the scheduler service, concurrent in the table below really means the max containers that can be provisioned at once for a namespace. The api may be able to accept more activations than this number at once depending on a number of factors.\nThe following table lists the default limits for actions.\nlimit description configurable unit default timeout\na container is not allowed to run longer than N milliseconds\nper action\nmilliseconds\n60000\nmemory\na container is not allowed to allocate more than N MB of memory\nper action\nMB\n256\nlogs\na container is not allowed to write more than N MB to stdout\nper action\nMB\n10\ninstances\nan action is not allowed to have more containers than this value (new scheduler only)\nper action\nnumber\nnamespace concurrency limit\nconcurrent\nno more than N activations may be submitted per namespace either executing or queued for execution\nper namespace\nnumber\n100\nminuteRate\nno more than N activations may be submitted per namespace per minute\nper namespace\nnumber\n120\ncodeSize\nthe maximum size of the action code\nconfigurable, limit per action\nMB\n48\nparameters\nthe maximum size of the parameters that can be attached\nnot configurable, limit per action/package/trigger\nMB\n1\nresult\nthe maximum size of the action result\nnot configurable, limit per action\nMB\n1\nPer action timeout (ms) (Default: 60s) The timeout limit N is in the range [100ms..300000ms] and is set per action in milliseconds.\nA user can change the limit when creating the action.\nA container that runs longer than N milliseconds is terminated.\nPer action memory (MB) (Default: 256MB) The memory limit M is in the range from [128MB..512MB] and is set per action in MB.\nA user can change the limit when creating the action.\nA container cannot have more memory allocated than the limit.\nPer action max instance concurrency (Default: namespace limit for concurrent invocations) Only applicable using new scheduler The max containers that will be created for an action before throttling in the range from [1..concurrentInvocations limit for namespace]\nBy default the max allowed containers / server instances for an action is equal to the namespace limit.\nA user can change the limit when creating the action.\nDefining a lower limit than the namespace limit means your max container concurrency will be the action defined limit.\nIf using actionConcurrency \u003e 1 such that your action can handle multiple requests per instance, your true concurrency limit is actionContainerConcurrency * actionConcurrency.\nThe actions within a namespaces containerConcurrency total do not have to add up to the namespace limit though you can configure it that way to guarantee an action will get exactly the action container concurrency.\nFor example with a namespace limit of 30 with 2 actions each with a container limit of 20; if the first action is using 20, there will still be space for 10 for the other.\nPer action logs (MB) (Default: 10MB) The log limit N is in the range [0MB..10MB] and is set per action.\nA user can change the limit when creating or updating the action.\nLogs that exceed the set limit are truncated and a warning is added as the last output of the activation to indicate that the activation exceeded the set log limit.\nPer action artifact (MB) (Default: 48MB) The maximum code size for the action is 48MB.\nIt is recommended for a JavaScript action to use a tool to concatenate all source code including dependencies into a single bundled file.\nPer activation payload size (MB) (Fixed: 1MB) The maximum POST content size plus any curried parameters for an action invocation or trigger firing is 1MB. Per activation result size (MB) (Fixed: 1MB) The maximum size of a result returned from an action is 1MB. Per namespace concurrent invocation (Default: 100) The number of activations that are either executing or queued for execution for a namespace cannot exceed 100.\nA user is currently not able to change the limits.\nInvocations per minute (Fixed: 120) The rate limit N is set to 120 and limits the number of action invocations in one minute windows.\nA user cannot change this limit when creating the action.\nA CLI or API call that exceeds this limit receives an error code corresponding to HTTP status code 429: TOO MANY REQUESTS.\nSize of the parameters (Fixed: 1MB) The size limit for the parameters on creating or updating of an action/package/trigger is 1MB.\nThe limit cannot be changed by the user.\nAn entity with too big parameters will be rejected on trying to create or update it.\nPer Docker action open files ulimit (Fixed: 1024:1024) The maximum number of open files is 1024 (for both hard and soft limits).\nThe docker run command use the argument --ulimit nofile=1024:1024.\nFor more information about the ulimit for open files see the docker run documentation.\nPer Docker action processes ulimit (Fixed: 1024) The maximum number of processes available to the action container is 1024.\nThe docker run command use the argument --pids-limit 1024.\nFor more information about the ulimit for maximum number of processes see the docker run documentation.\nTriggers Triggers are subject to a firing rate per minute as documented in the table below.\nlimit description configurable unit default minuteRate\nno more than N triggers may be fired per namespace per minute\nper user\nnumber\n60\nTriggers per minute (Fixed: 60) The rate limit N is set to 60 and limits the number of triggers that may be fired in one minute windows.\nA user cannot change this limit when creating the trigger.\nA CLI or API call that exceeds this limit receives an error code corresponding to HTTP status code 429: TOO MANY REQUESTS.\n","categories":"","description":"Details of OpenServerless and OpenWhisk system","excerpt":"Details of OpenServerless and OpenWhisk system","ref":"/docs/reference/references/naming-limits/","tags":"","title":"Naming Limits"},{"body":"Introduction to parameters When working with serverless actions, data is supplied by adding parameters to the actions; these are in the parameter declared as an argument to the main serverless function. All data arrives this way and the values can be set in a few different ways. The first option is to supply parameters when an action or package is created (or updated). This approach is useful for data that stays the same on every execution, equivalent to environment variables on other platforms, or for default values that might be overridden at invocation time. The second option is to supply parameters when the action is invoked - and this approach will override any parameters already set.\nThis page outlines how to configure parameters when deploying packages and actions, and how to supply parameters when invoking an action. There is also information on how to use a file to store the parameters and pass the filename, rather than supplying each parameter individually on the command-line.\nPassing parameters to an action at invoke time Parameters can be passed to the action when it is invoked. These examples use JavaScript but all the other languages work the same way.\nUse parameters in the action. For example, create ‘hello.js’ file with the following content: function main(params) { return {payload: 'Hello, ' + params.name + ' from ' + params.place}; } The input parameters are passed as a JSON object parameter to the main function. Notice how the name and place parameters are retrieved from the params object in this example.\nUpdate the action so it is ready to use: ops action update hello hello.js Parameters can be provided explicitly on the command-line, or by supplying a file containing the desired parameters To pass parameters directly through the command-line, supply a key/value pair to the --param flag: ops action invoke --result hello --param name Dorothy --param place Kansas\nThis produces the result:\n{ \"payload\": \"Hello, Dorothy from Kansas\" } Notice the use of the --result option: it implies a blocking invocation where the CLI waits for the activation to complete and then displays only the result. For convenience, this option may be used without --blocking which is automatically inferred.\nAdditionally, if parameter values specified on the command-line are valid JSON, then they will be parsed and sent to your action as a structured object. For example, if we update our hello action to:\nfunction main(params) { return {payload: 'Hello, ' + params.person.name + ' from ' + params.person.place}; } Now the action expects a single person parameter to have fields name and place. If we invoke the action with a single person parameter that is valid JSON:\nops action invoke --result hello -p person '{\"name\": \"Dorothy\", \"place\": \"Kansas\"}' The result is the same because the CLI automatically parses the person parameter value into the structured object that the action now expects: json { \"payload\": \"Hello, Dorothy from Kansas\" }\nSetting default parameters on an action Actions can be invoked with multiple named parameters. Recall that the hello action from the previous example expects two parameters: the name of a person, and the place where they’re from.\nRather than pass all the parameters to an action every time, you can bind certain parameters. The following example binds the place parameter so that the action defaults to the place “Kansas”:\nUpdate the action by using the --param option to bind parameter values, or by passing a file that contains the parameters to --param-file (for examples of using files, see the section on working with parameter files. To specify default parameters explicitly on the command-line, provide a key/value pair to the param flag:\nops action update hello --param place Kansas Invoke the action, passing only the name parameter this time. ops action invoke --result hello --param name Dorothy { \"payload\": \"Hello, Dorothy from Kansas\" } Notice that you did not need to specify the place parameter when you invoked the action. Bound parameters can still be overwritten by specifying the parameter value at invocation time.\nInvoke the action, passing both name and place values, and observe the output: ops action invoke --result hello --param name Dorothy --param place \"Washington, DC\" { \"payload\": \"Hello, Dorothy from Washington, DC\" } Despite a parameter set on the action when it was created/updated, this is overridden by a parameter that was supplied when invoking the action.\nSetting default parameters on a package Parameters can be set at the package level, and these will serve as default parameters for actions unless:\nThe action itself has a default parameter.\nThe action has a parameter supplied at invoke time, which will always be the “winner” where more than one parameter is available.\nThe following example sets a default parameter of name on the MyApp package and shows an action making use of it.\nCreate a package with a parameter set: ops package update MyApp --param name World Create an action in this package: function main(params) { return {payload: \"Hello, \" + params.name}; } ops action update MyApp/hello hello.js Invoke the action, and observe the default package parameter in use: ops action invoke --result MyApp/hello { \"payload\": \"Hello, World\" } Working with parameter files It’s also possible to put parameters into a file in JSON format, and then pass the parameters in by supplying the filename with the param-file flag. This works for both packages and actions when creating/updating them, and when invoking actions.\nAs an example, consider the very simple hello example from earlier. Using hello.js with this content: function main(params) { return {payload: 'Hello, ' + params.name + ' from ' + params.place}; } Update the action with the updated contents of hello.js: ops action update hello hello.js Create a parameter file called parameters.json containing JSON-formatted parameters: { \"name\": \"Dorothy\", \"place\": \"Kansas\" } Use the parameters.json filename when invoking the action, and observe the output ops action invoke --result hello --param-file parameters.json { \"payload\": \"Hello, Dorothy from Kansas\" } ","categories":"","description":"Supply data to actions adding parameters","excerpt":"Supply data to actions adding parameters","ref":"/docs/reference/entities/parameters/","tags":"","title":"Parameters"},{"body":"Using REST APIs with OpenWhisk and OpenServerless After your OpenWhisk and OpenServerlesss environment is enabled, you can use it with your web apps or mobile apps with REST API calls.\nFor more details about the APIs for actions, activations, packages, rules, and triggers, see the OpenWhisk and OpenServerless API documentation.\nAll the capabilities in the system are available through a REST API. There are collection and entity endpoints for actions, triggers, rules, packages, activations, and namespaces.\nThese are the collection endpoints:\nhttps://$APIHOST/api/v1/namespaces https://$APIHOST/api/v1/namespaces/{namespace}/actions https://$APIHOST/api/v1/namespaces/{namespace}/triggers https://$APIHOST/api/v1/namespaces/{namespace}/rules https://$APIHOST/api/v1/namespaces/{namespace}/packages https://$APIHOST/api/v1/namespaces/{namespace}/activations https://$APIHOST/api/v1/namespaces/{namespace}/limits The $APIHOST is the OpenWhisk and OpenServerless API hostname (for example, localhost, 172.17.0.1, and so on). For the {namespace}, the character _ can be used to specify the user’s default namespace.\nYou can perform a GET request on the collection endpoints to fetch a list of entities in the collection.\nThere are entity endpoints for each type of entity:\nhttps://$APIHOST/api/v1/namespaces/{namespace} https://$APIHOST/api/v1/namespaces/{namespace}/actions/[{packageName}/]{actionName} https://$APIHOST/api/v1/namespaces/{namespace}/triggers/{triggerName} https://$APIHOST/api/v1/namespaces/{namespace}/rules/{ruleName} https://$APIHOST/api/v1/namespaces/{namespace}/packages/{packageName} https://$APIHOST/api/v1/namespaces/{namespace}/activations/{activationName} The namespace and activation endpoints support only GET requests. The actions, triggers, rules, and packages endpoints support GET, PUT, and DELETE requests. The endpoints of actions, triggers, and rules also support POST requests, which are used to invoke actions and triggers and enable or disable rules.\nAll APIs are protected with HTTP Basic authentication. You can use the ops admin tool to generate a new namespace and authentication. The Basic authentication credentials are in the AUTH property in your ~/.nuvprops file, delimited by a colon. You can also retrieve these credentials using the CLI running ops property get --auth.\nThe following is an example that uses the cURL command tool to get the list of all packages in the whisk.system namespace:\ncurl -u USERNAME:PASSWORD https://$APIHOST/api/v1/namespaces/whisk.system/packages [ { \"name\": \"slack\", \"binding\": false, \"publish\": true, \"annotations\": [ { \"key\": \"description\", \"value\": \"Package that contains actions to interact with the Slack messaging service\" } ], \"version\": \"0.0.1\", \"namespace\": \"whisk.system\" } ] In this example the authentication was passed using the -u flag, you can pass this value also as part of the URL as https://USERNAME:PASSWORD@$APIHOST.\nThe OpenWhisk API supports request-response calls from web clients. OpenWhisk responds to OPTIONS requests with Cross-Origin Resource Sharing headers. Currently, all origins are allowed (that is, Access-Control-Allow-Origin is “*”), the standard set of methods are allowed (that is, Access-Control-Allow-Methods is GET, DELETE, POST, PUT, HEAD), and Access-Control-Allow-Headers yields Authorization, Origin, X-Requested-With, Content-Type, Accept, User-Agent.\nAttention: Because OpenWhisk and OpenServerless currently supports only one key per namespace, it is not recommended to use CORS beyond simple experiments. Use Web Actions to expose your actions to the public and not use the OpenWhisk and OpenServerless authorization key for client applications that require CORS.\nUsing the CLI verbose mode The OpenWhisk and OpenServerless CLI is an interface to the OpenWhisk and OpenServerless REST API. You can run the CLI in verbose mode with the flag -v, this will print truncated information about the HTTP request and response. To print all information use the flag -d for debug.\nNote: HTTP request and response bodies will only be truncated if they exceed 1000 bytes.\nLet’s try getting the namespace value for the current user.\nops namespace list -v REQUEST: [GET] https://$APIHOST/api/v1/namespaces Req Headers { \"Authorization\": [ \"Basic XXXYYYY\" ], \"User-Agent\": [ \"OpenWhisk and OpenServerless-CLI/1.0 (2017-08-10T20:09:30+00:00)\" ] } RESPONSE:Got response with code 200 Resp Headers { \"Content-Type\": [ \"application/json; charset=UTF-8\" ] } Response body size is 28 bytes Response body received: [\"john@example.com_dev\"] As you can see you the printed information provides the properties of the HTTP request, it performs a HTTP method GET on the URL https://$APIHOST/api/v1/namespaces using a User-Agent header OpenWhisk and OpenServerless-CLI/1.0 (\u003cCLI-Build-version\u003e) and Basic Authorization header Basic XXXYYYY. Notice that the authorization value is your base64-encoded OpenWhisk and OpenServerless authorization string. The response is of content type application/json.\nActions Note: In the examples that follow, $AUTH and $APIHOST represent environment variables set respectively to your OpenWhisk and OpenServerless authorization key and API host.\nTo create or update an action send a HTTP request with method PUT on the the actions collection. For example, to create a nodejs:6 action with the name hello using a single file content use the following:\ncurl -u $AUTH -d '{\"namespace\":\"_\",\"name\":\"hello\",\"exec\":{\"kind\":\"nodejs:6\",\"code\":\"function main(params) { return {payload:\\\"Hello \\\"+params.name}}\"}}' -X PUT -H \"Content-Type: application/json\" https://$APIHOST/api/v1/namespaces/_/actions/hello?overwrite=true To perform a blocking invocation on an action, send a HTTP request with a method POST and body containing the input parameter name use the following:\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/actions/hello?blocking=true \\ -X POST -H \"Content-Type: application/json\" \\ -d '{\"name\":\"John\"}' You get the following response:\n{ \"duration\": 2, \"name\": \"hello\", \"subject\": \"john@example.com_dev\", \"activationId\": \"c7bb1339cb4f40e3a6ccead6c99f804e\", \"publish\": false, \"annotations\": [{ \"key\": \"limits\", \"value\": { \"timeout\": 60000, \"memory\": 256, \"logs\": 10 } }, { \"key\": \"path\", \"value\": \"john@example.com_dev/hello\" }], \"version\": \"0.0.1\", \"response\": { \"result\": { \"payload\": \"Hello John\" }, \"success\": true, \"status\": \"success\" }, \"end\": 1493327653769, \"logs\": [], \"start\": 1493327653767, \"namespace\": \"john@example.com_dev\" } If you just want to get the response.result, run the command again with the query parameter result=true\ncurl -u $AUTH \"https://$APIHOST/api/v1/namespaces/_/actions/hello?blocking=true\u0026result=true\" \\ -X POST -H \"Content-Type: application/json\" \\ -d '{\"name\":\"John\"}' You get the following response:\n{ \"payload\": \"hello John\" } Annotations and Web Actions To create an action as a web action, you need to add an annotation of web-export=true for web actions. Since web-actions are publicly accessible, you should protect pre-defined parameters (i.e., treat them as final) using the annotation final=true. If you create or update an action using the CLI flag --web true this command will add both annotations web-export=true and final=true.\nRun the curl command providing the complete list of annotations to set on the action\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/actions/hello?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"namespace\":\"_\",\"name\":\"hello\",\"exec\":{\"kind\":\"nodejs:6\",\"code\":\"function main(params) { return {payload:\\\"Hello \\\"+params.name}}\"},\"annotations\":[{\"key\":\"web-export\",\"value\":true},{\"key\":\"raw-http\",\"value\":false},{\"key\":\"final\",\"value\":true}]}' You can now invoke this action as a public URL with no OpenWhisk and OpenServerless authorization. Try invoking using the web action public URL including an optional extension such as .json or .http for example at the end of the URL.\ncurl https://$APIHOST/api/v1/web/john@example.com_dev/default/hello.json?name=John { \"payload\": \"Hello John\" } Note that this example source code will not work with .http, see web actions documentation on how to modify.\nSequences To create an action sequence, you need to create it by providing the names of the actions that compose the sequence in the desired order, so the output from the first action is passed as input to the next action.\n$ ops action create sequenceAction –sequence /whisk-system/utils/split,/whisk-system/utils/sort\nCreate a sequence with the actions /whisk-system/utils/split and /whisk-system/utils/sort.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/actions/sequenceAction?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"namespace\":\"_\",\"name\":\"sequenceAction\",\"exec\":{\"kind\":\"sequence\",\"components\":[\"/whisk.system/utils/split\",\"/whisk.system/utils/sort\"]},\"annotations\":[{\"key\":\"web-export\",\"value\":true},{\"key\":\"raw-http\",\"value\":false},{\"key\":\"final\",\"value\":true}]}' Take into account when specifying the names of the actions, they have to be full qualified.\nTriggers To create a trigger, the minimum information you need is a name for the trigger. You could also include default parameters that get passed to the action through a rule when the trigger gets fired.\nCreate a trigger with name events with a default parameter type with value webhook set.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/triggers/events?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"name\":\"events\",\"parameters\":[{\"key\":\"type\",\"value\":\"webhook\"}]}' Now whenever you have an event that needs to fire this trigger it just takes an HTTP request with a method POST using the OpenWhisk and OpenServerless Authorization key.\nTo fire the trigger events with a parameter temperature, send the following HTTP request.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/triggers/events \\ -X POST -H \"Content-Type: application/json\" \\ -d '{\"temperature\":60}' Rules To create a rule that associates a trigger with an action, send a HTTP request with a PUT method providing the trigger and action in the body of the request.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/rules/t2a?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"name\":\"t2a\",\"status\":\"\",\"trigger\":\"/_/events\",\"action\":\"/_/hello\"}' Rules can be enabled or disabled, and you can change the status of the rule by updating its status property. For example, to disable the rule t2a send in the body of the request status: \"inactive\" with a POST method.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/rules/t2a?overwrite=true \\ -X POST -H \"Content-Type: application/json\" \\ -d '{\"status\":\"inactive\",\"trigger\":null,\"action\":null}' Packages To create an action in a package you have to create a package first, to create a package with name iot send an HTTP request with a PUT method\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/packages/iot?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"namespace\":\"_\",\"name\":\"iot\"}' To force delete a package that contains entities, set the force parameter to true. Failure will return an error either for failure to delete an action within the package or the package itself. The package will not be attempted to be deleted until all actions are successfully deleted.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/packages/iot?force=true \\ -X DELETE Activations To get the list of the last 3 activations use a HTTP request with a GET method, passing the query parameter limit=3\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/activations?limit=3 To get all the details of an activation including results and logs, send a HTTP request with a GET method passing the activation identifier as a path parameter\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/activations/f81dfddd7156401a8a6497f2724fec7b Limits To get the limits set for a namespace (i.e. invocationsPerMinute, concurrentInvocations, firesPerMinute, actionMemoryMax, actionLogsMax…)\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/limits Note that the default system values are returned if no specific limits are set for the user corresponding to the authenticated identity.\n","categories":"","description":"Use OpenServerless with your Rest API calls.","excerpt":"Use OpenServerless with your Rest API calls.","ref":"/docs/reference/references/rest_api/","tags":"","title":"Rest API"},{"body":"Annotations OpenWhisk and OpenServerless actions, triggers, rules and packages (collectively referred to as assets) may be decorated with annotations. Annotations are attached to assets just like parameters with a key that defines a name and value that defines the value. It is convenient to set them from the command line interface (CLI) via --annotation or -a for short.\nRationale: Annotations were added to OpenWhisk and OpenServerless to allow for experimentation without making changes to the underlying asset schema. We had, until the writing of this document, deliberately not defined what annotations are permitted. However as we start to use annotations more heavily to impart semantic changes, it’s important that we finally start to document them.\nThe most prevalent use of annotations to date is to document actions and packages. You’ll see many of the packages in the OpenWhisk and OpenServerless catalog carry annotations such as a description of the functionality offered by their actions, which parameters are required at package binding time, and which are invoke-time parameters, whether a parameter is a “secret” (e.g., password), or not. We have invented these as needed, for example to allow for UI integration.\nHere is a sample set of annotations for an echo action which returns its input arguments unmodified (e.g., function main(args) { return args }). This action may be useful for logging input parameters for example as part of a sequence or rule.\nops action create echo echo.js \\ -a description 'An action which returns its input. Useful for logging input to enable debug/replay.' \\ -a parameters '[{ \"required\":false, \"description\": \"Any JSON entity\" }]' \\ -a sampleInput '{ \"msg\": \"Five fuzzy felines\"}' \\ -a sampleOutput '{ \"msg\": \"Five fuzzy felines\"}' The annotations we have used for describing packages are:\ndescription: a pithy description of the package\nparameters: an array describing parameters that are scoped to the package (described further below)\nSimilarly, for actions:\ndescription: a pithy description of the action\nparameters: an array describing actions that are required to execute the action\nsampleInput: an example showing the input schema with typical values\nsampleOutput: an example showing the output schema, usually for the sampleInput\nThe annotations we have used for describing parameters include:\nname: the name of the parameter\ndescription: a pithy description of the parameter\ndoclink: a link to further documentation for parameter (useful for OAuth tokens for example)\nrequired: true for required parameters and false for optional ones\nbindTime: true if the parameter should be specified when a package is bound\ntype: the type of the parameter, one of password, array (but may be used more broadly)\nThe annotations are not checked. So while it is conceivable to use the annotations to infer if a composition of two actions into a sequence is legal, for example, the system does not yet do that.\nAnnotations for all actions The following annotations on an action are available.\nprovide-api-key: This annotation may be attached to actions which require an API key, for example to make REST API calls to the OpenWhisk and OpenServerless host. For newly created actions, if not specified, it defaults to a false value. For existing actions, the absence of this annotation, or its presence with a value that is not falsy (i.e., a value that is different from zero, null, false, and the empty string) will cause an API key to be present in the action execution context. Annotations specific to web actions Web actions are enabled with explicit annotations which decorate individual actions. The annotations only apply to the web actions API, and must be present and explicitly set to true to have an affect. The annotations have no meaning otherwise in the system. The annotations are:\nweb-export: Makes its corresponding action accessible to REST calls without authentication. We call these web actions because they allow one to use OpenWhisk and OpenServerless actions from a browser for example. It is important to note that the owner of the web action incurs the cost of running them in the system (i.e., the owner of the action also owns the activations record). The rest of the annotations described below have no effect on the action unless this annotation is also set.\nfinal: Makes all of the action parameters that are already defined immutable. A parameter of an action carrying the annotation may not be overridden by invoke-time parameters once the parameter has a value defined through its enclosing package or the action definition.\nraw-http: When set, the HTTP request query and body parameters are passed to the action as reserved properties.\nweb-custom-options: When set, this annotation enables a web action to respond to OPTIONS requests with customized headers, otherwise a default CORS response applies.\nrequire-whisk-auth: This annotation protects the web action so that it is only invoked by requests that provide appropriate authentication credentials. When set to a boolean value, it controls whether or not the request’s Basic Authentication value (i.e. Whisk auth key) will be authenticated - a value of true will authenticate the credentials, a value of false will invoke the action without any authentication. When set to a number or a string, this value must match the request’s X-Require-Whisk-Auth header value. In both cases, it is important to note that the owner of the web action will still incur the cost of running them in the system (i.e., the owner of the action also owns the activations record).\nAnnotations specific to activations The system decorates activation records with annotations as well. They are:\npath: the fully qualified path name of the action that generated the activation. Note that if this activation was the result of an action in a package binding, the path refers to the parent package.\nbinding: the entity path of the package binding. Note that this is only present for actions in a package binding.\nkind: the kind of action executed, and one of the support OpenWhisk and OpenServerless runtime kinds.\nlimits: the time, memory and log limits that this activation were subject to.\nAdditionally for sequence related activations, the system will generate the following annotations:\ntopmost: this is only present for an outermost sequence action.\ncausedBy: this is only present for actions that are contained in a sequence.\nLastly, and in order to provide you with some performance transparency, activations also record:\nwaitTime: the time spent waiting in the internal OpenWhisk and OpenServerless system. This is roughly the time spent between the controller receiving the activation request and when the invoker provisioned a container for the action.\ninitTime: the time spent initializing the function. If this value is present, the action required initialization and represents a cold start. A warm activation will skip initialization, and in this case, the annotation is not generated.\nAn example of these annotations as they would appear in an activation record is shown below.\n\"annotations\": [ { \"key\": \"path\", \"value\": \"guest/echo\" }, { \"key\": \"waitTime\", \"value\": 66 }, { \"key\": \"kind\", \"value\": \"nodejs:6\" }, { \"key\": \"initTime\", \"value\": 50 }, { \"key\": \"limits\", \"value\": { \"logs\": 10, \"memory\": 256, \"timeout\": 60000 } } ] ","categories":"","description":"How to use annotations to decorate actions","excerpt":"How to use annotations to decorate actions","ref":"/docs/reference/entities/annotations/","tags":"","title":"Annotations"},{"body":"Install K3S in a server You can install OpenServerless as described here, and you do not need to install any Kubernetes in it, as it is installed as part of the procedure. In this case it installs K3S.\nOr you can install K3S in advance, and then proceed configuring and then installing OpenServerless as in any other Kubernetes cluster.\nInstalling K3S in a server Before installing ensure you have satified the prerequisites, most notably:\nyou know the IP address or DNS name\nyour server operating system satisfies the K3S requirements\nyou have passwordless access with ssh\nyou have a user with passwordless sudo rights\nyou have opened the port 6443 in the firewall\nThen you can use the following subcommand to install in the server:\nops cloud k3s create \u003cserver\u003e [\u003cusername\u003e] where \u003cserver\u003e is the IP address or DNS name to access the server, and the optional \u003cusername\u003e is the user you use to access the server: if is not specified, the root username will be used.\nThose pieces of information should have been provided when provisioning the server.\n❗ IMPORTANT\nIf you installed a Kubernetes cluster in the server this way, you should proceed installing OpenServerless as in a Kubernetes cluster, not as a server.\nThe installation retrieves also a Kubernetes configuration file, so you can proceed to installing it without any other step involved.\nAdditional Commands In addition to create the following subcommands are also available:\nops cloud k3s delete \u003cserver\u003e [\u003cusername\u003e]: uninstall K3S from the server\nops cloud k3s kubeconfig \u003cserver\u003e [\u003cusername\u003e]: retrieve the kubeconfig from the K3S server\nops cloud k3s info: some information about the server\nops cloud k3s status: status of the server\n","categories":"","description":"Prerequisites to install OpenServerless in K3S","excerpt":"Prerequisites to install OpenServerless in K3S","ref":"/docs/installation/prereq/server/k3s/","tags":"","title":"Install K3S"},{"body":"Welcome to OpenServerless Developer guide.\nOpenServerless is based on Apache OpenWhisk and the documentation in this section is derived for the official OpenWhisk documentation.\nIn this sections we mostly document how to write actions (functions), the building blocks of OpenWhisk and OpenServerless applications. There are also a few related entities for managing actions (packages, parameters etc) you also need to know.\nYou can write actions in a number of programming languages. OpenServerless supports directly this list of programming languages. The list is expanding over the time.\nSee below for documentation related to:\nOpenWhisk Entities\nOpenServerless Runtimes\nOpenServerless ops Tools\nOpenServerless ops Tasks\nAdvanced Reference Documentation\nThere is also a tutorial and a development kit to build your own runtime for your favorite programming language.\n","categories":"","description":"OpenServerless Developer Guide","excerpt":"OpenServerless Developer Guide","ref":"/docs/reference/","tags":"","title":"Reference"},{"body":"OpenServerless Operator offers the possibility to deploy a simple “scheduler” to invoke repetitive or one-shot OpenWhisk actions. For example, an action executing a SQL script to create a PostgreSQL Database or inserting reference data, or simply an action that sends notifications with an API call every day at the same time.\nHow to Activate the Scheduler Using the ops CLI, you can enable the scheduler with the following command:\nops config enable --cron # if OpenServerless is not yet deployed ops setup devcluster # alternatively if OpenServerless is already deployed ops update apply By default, the internal scheduler executes a job every minute that starts searching for OpenWhisk actions with special annotations.\nHow to Deploy a Repetitive Action Let’s assume we want to deploy an OpenWhisk action to be executed every 30 minutes. Suppose it’s an action that simply prints something, like this:\ndef main(args): print('Hello from a repeated action') return { 'body': 'action invoked' } abd save it to a file called scheduled-action.py\nTo deploy the action and instruct OpenServerless to execute it every 30 minutes, issue the following command:\nops action create scheduled-action scheduled-action.py -a cron \"*/30 * * * *\"\nSo you can create the action in the usual way and at the end add -a cron yourCronExpression.\nHow to Deploy a One-Shot Execution Action Now suppose we want to execute the same action scheduled-action.py only once.\nTo deploy an action and request a single execution automatically via the OpenServerless Scheduler, issue the following command:\nops action create scheduled-action scheduled-action.py -a autoexec true\nIf we now print activation logs with ops activation poll, we will see our action execution log:\nActivation: 'scheduled' (ebd532139a464e9d9532139a46ae9d8a) [ \"2024-03-08T07:28:02.050739962Z stdout: Hello from a scheduled action\" ] Remarks The Scheduler executes the action according to the following rules:\nActions are called in a non-blocking fashion. To verify execution and logs, use the command ops activation list. Actions are invoked without any parameters. It is advised to deploy actions with self-contained parameters.\n","categories":"","description":"Use the scheduler to invoke repetitive or one-shot actions","excerpt":"Use the scheduler to invoke repetitive or one-shot actions","ref":"/docs/reference/references/scheduler/","tags":"","title":"Scheduler"},{"body":"Sequences You can combine actions into sequences and invoke them as a single action. Therefore, a sequence represents a logical junction between two or more actions, where each action is invoked in a specific order.\nCombine actions sequentially Suppose we want to describe an algorithm for preparing a pizza. We could prepare everything in a single action, creating it all in one go, from preparing the dough to adding all the ingredients and cooking it.\nWhat if you would like to edit only a specific part of your algorithm, like adding fresh tomato instead of classic, or reducing the amount of water in your pizza dough? Every time, you have to edit your main action to modify only a part.\nAgain, what if before returning a pizza you’d like to invoke a new action like “add basil,” or if you decide to refrigerate the pizza dough after preparing it but before cooking it?\nThis is where sequences come into play.\nCreate a file called preparePizzaDough.js\nfunction main(args) { let persons = args.howManyPerson; let flour = persons * 180; // grams let water = persons * 120; // ml let yeast = (flour + water) * 0.02; let pizzaDough = \"Mix \" + flour + \" grams of flour with \" + water + \" ml of water and add \" + yeast + \" grams of brewer's yeast\"; return { pizzaDough: pizzaDough, whichPizza: args.whichPizza, }; } Now, in a file cookPizza.js\nfunction main(args) { let pizzaDough = args.pizzaDough; let whichPizza = args.whichPizza; let baseIngredients = \"tomato and mozzarella\"; if (whichPizza === \"Margherita\") { return { result: \"Cook \" + pizzaDough + \" topped with \" + baseIngredients + \" for 3 minutes at 380°C\", }; } else if (whichPizza === \"Sausage\") { baseIngredients += \"plus sausage\"; return { result: \"Cook \" + pizzaDough + \" topped with \" + baseIngredients + \". Cook for 3 minutes at 380°C\", }; } } We have now split our code to prepare pizza into two different actions. When we need to edit only one action without editing everything, we can do it! Otherwise, we can now add new actions that can be invoked or not before cooking pizza (or after).\nLet’s try it.\nTesting the sequence First, create our two actions\nops action create preparePizzaDough preparePizzaDough.js ops action create cookPizza cookPizza.js Now, we can create the sequence:\nops action create pizzaSequence --sequence preparePizzaDough,cookPizza Finally, let’s invoke it\nops action invoke --result pizzaSequence -p howManyPerson 4 -p whichPizza \"Margherita\" { \"result\": \"Cook Mix 720 grams of flour with 480 ml of water and add 24 grams of brewer's yeast topped with tomato and mozzarella for 3 minutes at 380°C\" } Conclusion Now, thanks to sequences, our code is split correctly, and we are able to scale it more easily!\n","categories":"","description":"Combine actions in sequences","excerpt":"Combine actions in sequences","ref":"/docs/cli/entities/sequences/","tags":"","title":"Sequences"},{"body":"Use database Storing the Message in the Database We are ready to use the database that we enabled at the beginning of the tutorial.\nUsually, when working with relational databases, the best choice is to use a schema migration system. In our case, to keep things simple, we will emulate a migration using an action.\nNow, we need to create a table to store the contact data: start by creating a new action called create-table.js in the packages/contact folder.\nThe directory structure have to be like this:\ncontact_us_app ├── packages │ └── contact │ ├── create-table.js │ └── submit.js └── web └── index.html Put this content inside the create-table.js file:\n//--kind nodejs:default //--param POSTGRES_URL $POSTGRES_URL const { Client } = require('pg') async function main(args) { console.log('Starting create-table action') const client = new Client({ connectionString: args.POSTGRES_URL }); const createSchema = `CREATE SCHEMA IF NOT EXISTS demo;` const createTable = ` CREATE TABLE IF NOT EXISTS demo.contacts ( id serial PRIMARY KEY, name varchar(50), email varchar(50), phone varchar(50), message varchar(300) ); ` try { console.log(`Connecting to ${args.POSTGRES_URL}`); await client.connect(); console.log('Connected to database'); await client.query(createSchema); console.log('Schema demo created'); await client.query(createTable); console.log('Contact table created'); return { result: 'OK' }; } catch (e) { if (e instanceof AggregateError) { for (const err of e.errors) { console.error('[ERROR] - ', err.message || err); } } else if (e instanceof Error) { console.error('[ERROR] - ', e.message); } else { console.error('[ERROR] - ', e); } return { result: 'ERROR' }; } finally { console.log('Closing connection'); if (client) { await client.end(); } } } 💡 NOTE\nYou may have noticed here again the comments on top of the file. As said before, these comments are used by ops ide to automatically handle the publishing of files by calling ops package or ops action as needed. In particular:\n--kind nodejs:default will ask OpenServerless to run this code on the nodejs default runtime. the --param POSTGRES_URL $POSTGRES_URL will automatically fill in the parameters required by the action, taking it's value from ops's configuration file. The action is idempotent, so you may call the action multiple times, but the schema and the table is created only once.\nYou can deploy this action using ops ide deploy command.\nops ide deploy The output will be like:\n/home/openserverless/.ops/tmp/deploy.pid PID 52906 \u003e Scan: \u003e\u003e Action: packages/contact/create-table.js \u003e\u003e Action: packages/contact/submit.js \u003e Deploying: \u003e\u003e Package: contact $ $OPS package update contact ok: updated package contact \u003e\u003e\u003e Action: packages/contact/create-table.js $ $OPS action update contact/create-table packages/contact/create-table.js --kind nodejs:default --param POSTGRES_URL $POSTGRES_URL ok: updated action contact/create-table \u003e\u003e\u003e Action: packages/contact/submit.js $ $OPS action update contact/submit packages/contact/submit.js --web true --kind nodejs:default ok: updated action contact/submit build process exited with code 0 UPLOAD ASSETS FROM web ==================| UPLOAD RESULTS |================== | FILES : 1 | COMPLETED : 1 | ERRORS : 0 | SKIPPED : 0 | EXEC. TIME : 28.37 ms ====================================================== URL: http://opstutorial.localhost:80 In OpenServerless an action invocation is called an activation. You can keep track, retrieve information and check logs from an action with ops activation. For example, with:\nops activation list You can retrieve the list of invocations. For caching reasons the first time you run the command the list might be empty. Just run it again and you will see the latest invocations (probably some hello actions from the deployment).\nIf we want to invoke the create-table action, we can do it with this command.\nops action invoke contact/create-table The output will be like:\nok: invoked /_/contact/create-table with id e67a6c6f5a9c4667ba6c6f5a9c46675b The activation will return an id: in our case the id is e67a6c6f5a9c4667ba6c6f5a9c46675b. You can retrieve the activation log with the command ops activation logs \u003cid\u003e or ops activation logs --last to retrieve the last activation log.\nops activation logs e67a6c6f5a9c4667ba6c6f5a9c46675b 2025-03-17T23:28:03.390748125Z stdout: Starting create-table action 2025-03-17T23:28:03.391745125Z stdout: Connecting to postgresql://opstutorial:password@nuvolaris-postgres.nuvolaris.svc.cluster.local:5432/opstutorial 2025-03-17T23:28:03.405132167Z stdout: Connected to database 2025-03-17T23:28:03.406006792Z stdout: Schema demo created 2025-03-17T23:28:03.406601042Z stdout: Contact table created 2025-03-17T23:28:03.406604209Z stdout: Closing connection .. We could run ops activation poll or ops ide poll to listen for new logs.\nTo check that the table is really there, and inspect it’s schema you can use the ops devel psql describe tool:\nops devel psql describe \"demo.contacts\" --format=table You should see:\n┌───┬───────────────┬──────────────┬─────────────┬───────────────────┬─────────────┐ │ │ table_catalog │ table_schema │ column_name │ data_type │ is_nullable │ ├───┼───────────────┼──────────────┼─────────────┼───────────────────┼─────────────┤ │ 0 │ opstutorial │ demo │ id │ integer │ NO │ │ 1 │ opstutorial │ demo │ name │ character varying │ YES │ │ 2 │ opstutorial │ demo │ email │ character varying │ YES │ │ 3 │ opstutorial │ demo │ phone │ character varying │ YES │ │ 4 │ opstutorial │ demo │ message │ character varying │ YES │ └───┴───────────────┴──────────────┴─────────────┴───────────────────┴─────────────┘ The Action to Store the Data We could just write the code to insert data into the table in the submit.js action, but it’s better to have a separate action for that.\nLet’s create a new file called write.js in the packages/contact folder:\n// write.js //--kind nodejs:default //--param POSTGRES_URL $POSTGRES_URL const {Client} = require('pg') async function main(args) { const client = new Client({connectionString: args.POSTGRES_URL}); // Connect to database server await client.connect(); const {name, email, phone, message} = args; try { let res = await client.query( 'INSERT INTO demo.contacts(name,email,phone,message) VALUES($1,$2,$3,$4)', [name, email, phone, message] ); console.log(res); } catch (e) { console.log(e); throw e; } finally { client.end(); } return { body: args.body, name, email, phone, message }; } Very similar to the create table action, but this time we are inserting data into the table by passing the values as parameters. There is also a console.log on the response in case we want to check some logs again.\nLet’s deploy it:\nops ide deploy /home/openserverless/.ops/tmp/deploy.pid /Users/bruno/.ops/tmp/deploy.pid PID 57700 \u003e Scan: \u003e\u003e Action: packages/contact/write.js \u003e\u003e Action: packages/contact/create-table.js \u003e\u003e Action: packages/contact/submit.js \u003e Deploying: \u003e\u003e Package: contact $ $OPS package update contact ok: updated package contact \u003e\u003e\u003e Action: packages/contact/write.js $ $OPS action update contact/write packages/contact/write.js --kind nodejs:default --param POSTGRES_URL $POSTGRES_URL ok: updated action contact/write \u003e\u003e\u003e Action: packages/contact/create-table.js $ $OPS action update contact/create-table packages/contact/create-table.js --kind nodejs:default --param POSTGRES_URL $POSTGRES_URL ok: updated action contact/create-table \u003e\u003e\u003e Action: packages/contact/submit.js $ $OPS action update contact/submit packages/contact/submit.js --web true --kind nodejs:default ok: updated action contact/submit build process exited with code 0 UPLOAD ASSETS FROM web ==================| UPLOAD RESULTS |================== | FILES : 1 | COMPLETED : 1 | ERRORS : 0 | SKIPPED : 0 | EXEC. TIME : 28.92 ms ====================================================== URL: http://opstutorial.localhost:80 Finalizing the Submit Alright, we are almost done. We just need to create a pipeline of submit → write actions. The submit action returns the 4 form fields together with the HTML body. The write action expects those 4 fields to store them. Let’s put them together into a sequence:\nops action create contact/submit-write --sequence contact/submit,contact/write --web true ok: created action contact/submit-write With this command we created a new action called submit-write that is a sequence of submit and write. This means that OpenServerless will call in a sequence submit first, then get its output and use it as input to call write.\nNow the pipeline is complete, and we can test it by submitting the form again. This time the data will be stored in the database.\nNote that write passes on the HTML body so we can still see the thank you message. If we want to hide it, we can just remove the body property from the return value of write. We are still returning the other 4 fields, so another action can use them (spoiler: it will happen next chapter).\nLet’s check out again the action list:\nops action list actions /opstutorial/contact/submit-write private sequence /opstutorial/contact/submit private nodejs:21 /opstutorial/contact/create-table private nodejs:21 /opstutorial/contact/write private nodejs:21 You probably have something similar. Note the submit-write is managed as an action, but it’s actually a sequence of 2 actions. This is a very powerful feature of OpenServerless, as it allows you to create complex pipelines of actions that can be managed as a single unit.\nTrying the Sequence As before, we have to update our index.html to use the new action. First let’s get the URL of the submit-write action:\nops url contact/submit-write \u003capihost\u003e/api/v1/web/openserverless/contact/submit-write Then we can update the index.html file. Change the form submit action with the url from the previous command:\n\u003cform method=\"POST\" action=\"/api/v1/web/opstutorial/contact/submit-write\" enctype=\"application/x-www-form-urlencoded\"\u003e We just need to add -write to the action name.\nNow give a ops ide deploy to publish all the modifications.\nTry again to fill the contact form (with correct data) and submit it. This time the data will be stored in the database.\nView data from db If you want to retrieve data from your database, ops provides several utilities under the ops devel command. They are useful to interact with the integrated services, such as the database we are using.\nFor instance, to interact with PostgreSQL database, let’s run:\necho \"SELECT * FROM demo.CONTACTS\" | ops devel psql sql --format=table You should see an output like this:\n┌───┬────┬────────────────┬─────────────────────────┬─────────────┬──────────────────────────────┐ │ │ id │ name │ email │ phone │ message │ ├───┼────┼────────────────┼─────────────────────────┼─────────────┼──────────────────────────────┤ │ 0 │ 1 │ OpenServerless │ user@openserverless.dev │ 39123123123 │ Hello Apache OpenServerless! │ └───┴────┴────────────────┴─────────────────────────┴─────────────┴──────────────────────────────┘ ","categories":"","description":"Store data into a relational database","excerpt":"Store data into a relational database","ref":"/docs/tutorial/use-database/","tags":"","title":"Use database"},{"body":"Installation Overview If you are in hurry and you think this guide is TL;DR (too long, don’t read), please read at least our Quick Start single page installation guide.\nIt gives you an overview of the installation process, omitting some more advanced details. It can be enough to get you started and install OpenServerless.\nOnce you want to know more, you can come back.\nIf you instead want the read the full documentation first, please read on.\nSteps to follow OpenServerless can be installed in many environments, using our powerful command line interface ops.\nSo you should start downloading the CLI from this page.\nOnce you installed ops, before installing you need to check the prerequisites for the installation, and satisfy them\nIf the the prerequisites are OK, you can make your choices of what you want to Configure your OpenServerless installation.\nFinally, once you have:\ndownloaded ops\nsatisfied the prerequisites\nconfigured your installation\nyou can choose where to install, either:\nin your Local machine\nin a Linux server\nin a Kubernetes cluster\nPost Installation After the installation, you can change later the configuration and update the system.\nSupport If you have issues, please check:\nthe Troubleshooting page\nour Discussion forum\n","categories":"","description":"How to and where install OpenServerless","excerpt":"How to and where install OpenServerless","ref":"/docs/installation/","tags":"","title":"Installation"},{"body":" Creating and invoking JavaScript actions The process of creating JavaScript actions is similar to that of other actions. The following sections guide you through creating and invoking a single JavaScript action, and demonstrate how to bundle multiple JavaScript files and third party dependencies.\nCreate a package directory. Create a JavaScript file with the following content inside our packages/nodejs. For this example, the file name is hello.js. //--web true //--kind nodejs:default function main() { return { msg: 'Hello world' }; } The JavaScript file might contain additional functions. However, by convention, a function called main must exist to provide the entry point for the action.\nYou directory structure should looks like this:\nnodejs_app └── packages └── nodejs └── hello.js Create an action from the following JavaScript function. For this example, the action is called hello. /home/openserverless/.ops/tmp/deploy.pid PID 278075 \u003e Scan: \u003e\u003e Action: packages/nodejs/hello.js \u003e Deploying: \u003e\u003e Package: nodejs $ $OPS package update nodejs ok: updated package nodejs \u003e\u003e\u003e Action: packages/nodejs/hello.js $ $OPS action update nodejs/hello packages/nodejs/hello.js --web true --kind nodejs:default ok: updated action nodejs/hello build process exited with code 0 UPLOAD ASSETS FROM web ==================| UPLOAD RESULTS |================== | FILES : 0 | COMPLETED : 0 | ERRORS : 0 | SKIPPED : 0 | EXEC. TIME : 2.37 ms ====================================================== URL: http://opstutorial.localhost:80 Note: To use a specific version of NodeJs runtime, change the kind property --kind nodejs:18, or --kind nodejs:20 in the hello.js file.\nCreating asynchronous actions JavaScript functions that run asynchronously may need to return the activation result after the main function has returned. You can accomplish this by returning a Promise in your action.\nSave the following content in a file called asyncAction.js inside the folder packages/nodejs. //--web true //--kind nodejs:default function main(args) { return new Promise(function(resolve, reject) { setTimeout(function() { resolve({ done: true }); }, 2000); }) } Notice that the main function returns a Promise, which indicates that the activation hasn’t completed yet, but is expected to in the future.\nThe setTimeout() JavaScript function in this case waits for two seconds before calling the callback function. This represents the asynchronous code and goes inside the Promise’s callback function.\nThe Promise’s callback takes two arguments, resolve and reject, which are both functions. The call to resolve() fulfills the Promise and indicates that the activation has completed normally.\nA call to reject() can be used to reject the Promise and signal that the activation has completed abnormally.\nRun the following commands to create the action and invoke it: ops ide deploy ops action invoke nodejs/asyncAction --result { \"done\": true } Notice that you performed a blocking invocation of an asynchronous action.\nFetch the activation log to see how long the activation took to complete: ops activation list --limit 1 nodejs/asyncAction Datetime Activation ID Kind Start Duration Status Entity 2024-03-27 19:46:43 64581426b44e4b3d981426b44e3b3d19 nodejs:21 cold 2.033s success openserverless/asyncAction:0.0.1 ops activation get 64581426b44e4b3d981426b44e3b3d19 { ... \"start\": 1743101268649, \"end\": 1743101270964, ... } Comparing the start and end time stamps in the activation record, you can see that this activation took slightly over two seconds to complete.\nUsing actions to call an external API The examples so far have been self-contained JavaScript functions. You can also create an action that calls an external API.\nThis example invokes a Yahoo Weather service to get the current conditions at a specific location.\nSave the following content in a file called weather.js. const fetch = require('node-fetch') const getWeatherForecast = async (latitude, longitude) =\u003e { const url = `https://api.open-meteo.com/v1/forecast?latitude=${latitude}\u0026longitude=${longitude}\u0026hourly=temperature_2m,relative_humidity_2m,wind_speed_10m` try { const response = await fetch(url) if (!response.ok) { throw new Error('Error during the request') } const data = await response.json() return data } catch (error) { console.error('Error:', error) return JSON.Stringify(error) } }; function main(args) { const {latitude, longitude} = args return await getWeatherForecast(latitude, longitude) } Note that the action in the example uses a Node.js library to fetch forecast data. However, you can use a library available in runtime dependencies or you can add a package.json file and specify the action’s dependencies.\nCheck a specific version of the Node.js runtime for packages available in the runtime environment.\nThis example also shows the need for asynchronous actions. The action returns uses ‘async/await’ to fetch the data from another system. When the action is completed, the action will return the values from the other sistem.\nCreate an action from the weather.js file: ops ide deploy Use the following command to run the action, and observe the output: ops action invoke nodejs/weather --param latitude \"51.509865\" --param longitude \"-0.118092\" --result Using the --result flag means that the value returned from the action is shown as output on the command-line:\n{ \"elevation\": 21, \"generationtime_ms\": 0.03039836883544922, \"hourly\": { \"temperature_2m\": [ 12.8, 12.9, ... ], \"time\": [ \"2025-03-27T00:00\", \"2025-03-27T01:00\", ... ] }, \"hourly_units\": { \"temperature_2m\": \"°C\", \"time\": \"iso8601\" }, \"latitude\": 51.5, \"longitude\": -0.120000124, \"timezone\": \"GMT\", \"timezone_abbreviation\": \"GMT\", \"utc_offset_seconds\": 0 } This example also passed a parameter to the action by using the --param flag and a value that can be changed each time the action is invoked.\nPackaging actions as Node.js modules with NPM libraries Instead of writing all your action code in a single JavaScript source file, actions can be deployed from a zip file containing a Node.js module.\nArchive zip files are extracted into the runtime environment and dynamically imported using require() during initialisation. Actions packaged as a zip file MUST contain a valid package.json with a main field used to denote the module index file to return.\nops ide deploy will include automatically node_modules folder in a zip file means external NPM libraries can be used on the platform.\nNote: remember that each runtime has a set of dependecies already installed. if it’s possible use this set of libraries. It’s better to don’t load too much external libraries because it will deteriorate the action’s performance\nSimple Example Create a folder called packageAction inside packages/nodejs folder\nCreate the following package.json file:\n{ \"name\": \"my-action\", \"main\": \"index.js\", \"dependencies\" : { \"left-pad\" : \"1.1.3\" } } Create the following index.js file: //--web true //--kind nodejs:default const leftPad = require(\"left-pad\") function main (args) { const lines = args.lines || []; return { padded: lines.map(l =\u003e leftPad(l, 30, \".\")) } } Now you should have this folder structure:\nnodejs_app └── packages └── nodejs └── packageAction ├── hello.js └── package.json Create the action\nops ide deploy When creating an action from a folder, ops ide deploy will create automatically the following artifacts:\nnode_modules package-lock.json \u003cfoldername\u003e.zip the zip fill is used by ops to create/update the function in your ops environment\nInvoke the action as normal. ops action invoke nodejs/packageAction --param lines \"[\\\"and now\\\", \\\"for something completely\\\", \\\"different\\\" ]\" --result { \"padded\": [ \".......................and now\", \"......for something completely\", \".....................different\" ] } Using JavaScript Bundlers to package action source files Using a JavaScript module bundler can transform application source files (with external dependencies) into a single compressed JavaScript file. This can lead to faster deployments, lower cold-starts and allow you to deploy large applications where individual sources files in a zip archive are larger than the action size limit.\nHere are the instructions for how to use three popular module bundlers with the Node.js runtime. The “left pad” action example will be used as the source file for bundling along with the external library.\nUsing rollup.js In this example we will use rollupjs to deliver the action\nCreate rollupAction folder inside packages/nodejs. Then re-write the index.js to use ES6 Modules, rather than CommonJS module format. Create the package.json and copy the content from the previous example import leftPad from 'left-pad'; function myAction(args) { const lines = args.lines || []; return { padded: lines.map(l =\u003e leftPad(l, 30, \".\")) } } export const main = myAction Make sure you export the function using the const main = ... pattern. Using export {myAction as main} does not work due to tree-shaking. See this blog post for full details on why this is necessary.\nCreate the Rollup.js configuration file in rollup.config.js with the following contents. import commonjs from 'rollup-plugin-commonjs'; import resolve from 'rollup-plugin-node-resolve'; export default { input: 'index.js', output: { file: 'bundle.js', format: 'cjs' }, plugins: [ resolve(), commonjs() ] }; Note: run the following command inside the rollupAction folder\nInstall the Rollup.js library and plugins using NPM. npm install rollup rollup-plugin-commonjs rollup-plugin-node-resolve --save-dev Run the Rollup.js tool using the configuration file. npx rollup --config Create an action using the bundle source file. ops action create nodejs/rollupAction bundle.js --kind nodejs:20 Invoke the action as normal. Results should be the same as the example above. ops action invoke nodejs/rollupAction --result --param lines \"[\\\"and now\\\", \\\"for something completely\\\", \\\"different\\\" ]\" Using webpack In this example we will use webpack to deliver the action\nCreate webpackAction folder inside packages/nodejs. Then re-write the index.js to export the main function using as a global reference. Then, create the package.json and copy the content from the previous example const leftPad = require('left-pad'); function myAction(args) { const lines = args.lines || []; return { padded: lines.map(l =\u003e leftPad(l, 30, \".\")) } } global.main = myAction This allows the bundle source to “break out” of the closures Webpack uses when defining the modules.\nCreate the Webpack configuration file in webpack.config.js with the following contents. module.exports = { entry: './index.js', target: 'node', output: { filename: 'bundle.js' } }; Install the Webpack library and CLI using NPM. npm install webpack-cli --save-dev Run the Webpack tool using the configuration file. npx webpack --config webpack.config.js Create an action using the bundle source file. ops action create nodejs/webpackAction dist/bundle.js --kind nodejs:21 Invoke the action as normal. Results should be the same as the example above. ops action invoke nodejs/webpackAction --result --param lines \"[\\\"and now\\\", \\\"for something completely\\\", \\\"different\\\" ]\" ","categories":"","description":"","excerpt":" Creating and invoking JavaScript actions The process of creating …","ref":"/docs/reference/runtimes/nodejs/","tags":"","title":"NodeJS"},{"body":"nodejs:v18 (default: false) Library Version Link @azure/openai ^1.0.0-beta.11 npm @langchain/community ^0.0.34 npm minio ^7.1.3 npm mongodb ^6.4.0 npm node-auth0 ^1.0.0 npm ollama ^0.5.0 npm openai ^4.28.4 npm openwhisk ^3.21.8 npm pg ^8.11.3 npm plotly ^1.0.6 npm redis ^4.6.13 npm uuid ^9.0.1 npm ","categories":"","description":"","excerpt":"nodejs:v18 (default: false) Library Version Link @azure/openai …","ref":"/docs/reference/runtimes/nodejs/nodejsv18/","tags":"","title":"nodejs:v18"},{"body":"nodejs:v20 (default: false) Library Version Link @azure/openai ^1.0.0-beta.11 npm @langchain/community ^0.0.34 npm minio ^7.1.3 npm mongodb ^6.4.0 npm node-auth0 ^1.0.0 npm ollama ^0.5.0 npm openai ^4.28.4 npm openwhisk ^3.21.8 npm pg ^8.11.3 npm plotly ^1.0.6 npm redis ^4.6.13 npm uuid ^9.0.1 npm ","categories":"","description":"","excerpt":"nodejs:v20 (default: false) Library Version Link @azure/openai …","ref":"/docs/reference/runtimes/nodejs/nodejsv20/","tags":"","title":"nodejs:v20"},{"body":"nodejs:v21 (default: true) Library Version Link @azure/openai ^1.0.0-beta.11 npm @langchain/community ^0.0.34 npm minio ^7.1.3 npm mongodb ^6.4.0 npm node-auth0 ^1.0.0 npm ollama ^0.5.0 npm openai ^4.28.4 npm openwhisk ^3.21.8 npm pg ^8.11.3 npm plotly ^1.0.6 npm redis ^4.6.13 npm uuid ^9.0.1 npm ","categories":"","description":"","excerpt":"nodejs:v21 (default: true) Library Version Link @azure/openai …","ref":"/docs/reference/runtimes/nodejs/nodejsv21/","tags":"","title":"nodejs:v21"},{"body":"In OpenWhisk and OpenServerless, you can use packages to bundle together a set of related actions, and share them with others.\nA package can include actions and feeds. - An action is a piece of code that runs on OpenWhisk. For example, the Cloudant package includes actions to read and write records to a Cloudant database. - A feed is used to configure an external event source to fire trigger events. For example, the Alarm package includes a feed that can fire a trigger at a specified frequency.\nEvery OpenWhisk and OpenServerless entity, including packages, belongs in a namespace, and the fully qualified name of an entity is /namespaceName[/packageName]/entityName. Refer to the naming guidelines for more information.\nThe following sections describe how to browse packages and use the triggers and feeds in them. In addition, if you are interested in contributing your own packages to the catalog, read the sections on creating and sharing packages.\nBrowsing packages Several packages are registered with OpenWhisk and OpenServerless. You can get a list of packages in a namespace, list the entities in a package, and get a description of the individual entities in a package.\nGet a list of packages in the /nuvolaris namespace. $ ops package list /nuvolaris packages /nuvolaris/openai private /nuvolaris/mastrogpt private /nuvolaris/examples private Get a list of entities in the /nuvolaris/openai package. $ ops package get --summary /nuvolaris/openai package /nuvolaris/openai (parameters: none defined) action /nuvolaris/openai/models (parameters: none defined) action /nuvolaris/openai/chat (parameters: none defined) Note: Parameters listed under the package with a prefix * are predefined, bound parameters. Parameters without a * are those listed under the annotations for each entity. Furthermore, any parameters with the prefix ** are finalized bound parameters. This means that they are immutable, and cannot be changed by the user. Any entity listed under a package inherits specific bound parameters from the package. To view the list of known parameters of an entity belonging to a package, you will need to run a get --summary of the individual entity.\nGet a description of the /nuvolaris/openai/chat action. $ ops action get --summary /nuvolaris/openai/chat action /nuvolaris/openai/chat: Returns a result based on parameters OPENAI_API_HOST and OPENAI_API_KEY (parameters: **OPENAI_API_HOST, **OPENAI_API_KEY) NOTE: Notice that the parameters listed for the action read were expanded upon from the action summary compared to the package summary above. To see the official bound parameters for actions and triggers listed under packages, run an individual get summary for the particular entity.\nCreating a package A package is used to organize a set of related actions and feeds. It also allows for parameters to be shared across all entities in the package.\nTo create a custom package with a simple action in it, try the following example:\nCreate a package called custom. $ ops package create custom ok: created package custom Get a summary of the package. $ ops package get --summary custom package /myNamespace/custom (parameters: none defined) Notice that the package is empty.\nCreate a file called identity.js that contains the following action code. This action returns all input parameters. function main(args) { return args; } Create an identity action in the custom package. $ ops action create custom/identity identity.js ok: created action custom/identity Creating an action in a package requires that you prefix the action name with a package name. Package nesting is not allowed. A package can contain only actions and can’t contain another package.\nGet a summary of the package again. $ ops package get --summary custom package /myNamespace/custom (parameters: none defined) action /myNamespace/custom/identity (parameters: none defined) You can see the custom/identity action in your namespace now.\nInvoke the action in the package. $ ops action invoke --result custom/identity {} You can set default parameters for all the entities in a package. You do this by setting package-level parameters that are inherited by all actions in the package. To see how this works, try the following example:\nUpdate the custom package with two parameters: city and country. $ ops package update custom --param city Austin --param country USA ok: updated package custom Display the parameters in the package and action, and see how the identity action in the package inherits parameters from the package. $ ops package get custom ok: got package custom ... \"parameters\": [ { \"key\": \"city\", \"value\": \"Austin\" }, { \"key\": \"country\", \"value\": \"USA\" } ] ... $ ops action get custom/identity ok: got action custom/identity ... \"parameters\": [ { \"key\": \"city\", \"value\": \"Austin\" }, { \"key\": \"country\", \"value\": \"USA\" } ] ... Invoke the identity action without any parameters to verify that the action indeed inherits the parameters. $ ops action invoke --result custom/identity { \"city\": \"Austin\", \"country\": \"USA\" } Invoke the identity action with some parameters. Invocation parameters are merged with the package parameters; the invocation parameters override the package parameters. $ ops action invoke --result custom/identity --param city Dallas --param state Texas { \"city\": \"Dallas\", \"country\": \"USA\", \"state\": \"Texas\" } Sharing a package After the actions and feeds that comprise a package are debugged and tested, the package can be shared with all OpenWhisk and OpenServerless users. Sharing the package makes it possible for the users to bind the package, invoke actions in the package, and author OpenWhisk and OpenServerless rules and sequence actions.\nShare the package with all users: $ ops package update custom --shared yes ok: updated package custom Display the publish property of the package to verify that it is now true. $ ops package get custom ok: got package custom ... \"publish\": true, ... Others can now use your custom package, including binding to the package or directly invoking an action in it. Other users must know the fully qualified names of the package to bind it or invoke actions in it. Actions and feeds within a shared package are public. If the package is private, then all of its contents are also private.\nGet a description of the package to show the fully qualified names of the package and action. $ ops package get --summary custom package /myNamespace/custom: Returns a result based on parameters city and country (parameters: *city, *country) action /myNamespace/custom/identity (parameters: none defined) In the previous example, you’re working with the myNamespace namespace, and this namespace appears in the fully qualified name.\n","categories":"","description":"Create and Use packages","excerpt":"Create and Use packages","ref":"/docs/reference/entities/packages/","tags":"","title":"Packages"},{"body":" Creating and invoking PHP actions The process of creating PHP actions is similar to that of other actions. The following sections guide you through creating and invoking a single PHP action, and demonstrate how to bundle multiple PHP files and third party dependencies.\nCreate a Python_app folder and then create a package directory.Now create a Python file with the following content inside our packages/php. For this example, the file name is hello.php. \u003c?php //--web true //--kind php:default function main(array $args) : array { $name = $args[\"name\"] ?? \"stranger\"; $greeting = \"Hello $name!\"; echo $greeting; return [\"greeting\" =\u003e $greeting]; } ?\u003e The PHP file might contain additional functions. However, by convention, a function called main must exist to provide the entry point for the action.\nYour directory structure should looks like this:\nPHP_app └── packages └── php └── hello.php Run the following command to deploy the action ops ide deploy Ops will create the action automatically. For this example, the action is called php/hello. /home/openserverless.ops/tmp/deploy.pid PID 220917 \u003e Scan: \u003e\u003e Action: packages/php/hello.php \u003e Deploying: \u003e\u003e Package: php $ $OPS package update php ok: updated package php \u003e\u003e\u003e Action: packages/php/hello.php $ $OPS action update php/hello packages/php/hello.php ok: updated action php/hello build process exited with code 0 UPLOAD ASSETS FROM web ==================| UPLOAD RESULTS |================== | FILES : 0 | COMPLETED : 0 | ERRORS : 0 | SKIPPED : 0 | EXEC. TIME : 2.61 ms ====================================================== URL: http://openserverless.localhost:80 Note: To use a specific version of Python runtime, change the kind property --kind php:8.1, or --kind php:8.3 in the hello.py file.\nTo invoke the action run the following command: ops action invoke php/hello --param name Marina --result ","categories":"","description":"","excerpt":" Creating and invoking PHP actions The process of creating PHP actions …","ref":"/docs/reference/runtimes/php/","tags":"","title":"PHP"},{"body":"php:v8.0 (default: false) Library Version Link guzzlehttp/guzzle 7.2.0 packagist ramsey/uuid 4.1.1 packagist aws/aws-sdk-php 3.209.31 || 3.210.0 packagist bcmath Latest* PHP.net gd Latest* PHP.net intl Latest* PHP.net mysqli Latest* PHP.net mongodb Latest* PHP.net opcache Latest* PHP.net pgsql Latest* PHP.net pdo_mysql Latest* PHP.net pdo_pgsql Latest* PHP.net redis Latest* PHP.net soap Latest* PHP.net zip Latest* PHP.net *Latest version available for current runtime version\n","categories":"","description":"","excerpt":"php:v8.0 (default: false) Library Version Link guzzlehttp/guzzle 7.2.0 …","ref":"/docs/reference/runtimes/php/phpv8.0/","tags":"","title":"php:v8.0"},{"body":"php:v8.1 (default: false) Library Version Link guzzlehttp/guzzle 7.4.5 packagist ramsey/uuid 4.4.0 packagist openai-php/client v0.8.5 packagist aws/aws-sdk-php 3.306.7 packagist bcmath Latest* PHP.net gd Latest* PHP.net intl Latest* PHP.net mysqli Latest* PHP.net mongodb Latest* PHP.net opcache Latest* PHP.net pgsql Latest* PHP.net pdo_mysql Latest* PHP.net pdo_pgsql Latest* PHP.net redis Latest* PHP.net soap Latest* PHP.net zip Latest* PHP.net *Latest version available for current runtime version\n","categories":"","description":"","excerpt":"php:v8.1 (default: false) Library Version Link guzzlehttp/guzzle 7.4.5 …","ref":"/docs/reference/runtimes/php/phpv8.1/","tags":"","title":"php:v8.1"},{"body":"php:v8.2 (default: false) Library Version Link guzzlehttp/guzzle 7.7.0 packagist ramsey/uuid 4.7.4 packagist openai-php/client v0.8.5 packagist aws/aws-sdk-php 3.306.7 packagist bcmath Latest* PHP.net gd Latest* PHP.net intl Latest* PHP.net mysqli Latest* PHP.net mongodb Latest* PHP.net opcache Latest* PHP.net pgsql Latest* PHP.net pdo_mysql Latest* PHP.net pdo_pgsql Latest* PHP.net redis Latest* PHP.net soap Latest* PHP.net zip Latest* PHP.net *Latest version available for current runtime version\n","categories":"","description":"","excerpt":"php:v8.2 (default: false) Library Version Link guzzlehttp/guzzle 7.7.0 …","ref":"/docs/reference/runtimes/php/phpv8.2/","tags":"","title":"php:v8.2"},{"body":"php:v8.3 (default: true) Library Version Link guzzlehttp/guzzle 7.8.1 packagist ramsey/uuid 4.7.5 packagist openai-php/client v0.8.5 packagist aws/aws-sdk-php 3.306.7 packagist bcmath Latest* PHP.net gd Latest* PHP.net intl Latest* PHP.net mysqli Latest* PHP.net mongodb Latest* PHP.net opcache Latest* PHP.net pgsql Latest* PHP.net pdo_mysql Latest* PHP.net pdo_pgsql Latest* PHP.net redis Latest* PHP.net soap Latest* PHP.net zip Latest* PHP.net *Latest version available for current runtime version\n","categories":"","description":"","excerpt":"php:v8.3 (default: true) Library Version Link guzzlehttp/guzzle 7.8.1 …","ref":"/docs/reference/runtimes/php/phpv8.3/","tags":"","title":"php:v8.3"},{"body":" Creating and invoking Python actions The process of creating Python actions is similar to that of other actions. The following sections guide you through creating and invoking a single Python action, and demonstrate how to bundle multiple Python files and third party dependencies.\nCreate a Python_app folder and then create a package directory.Now create a Python file with the following content inside our packages/python. For this example, the file name is hello.py. #--web true #--kind python:default def main(args): name = args.get(\"name\", \"stranger\") result = f\"Hello {name}!\" print(result) return {\"greeting\": result} The Python file might contain additional functions. However, by convention, a function called main must exist to provide the entry point for the action.\nYour directory structure should looks like this:\nPython_app └── packages └── Python └── hello.py Run the following command to deploy the action ops ide deploy Ops will create the action automatically. For this example, the action is called python/hello. /home/openserverless/.ops/tmp/deploy.pid PID 278075 \u003e Scan: \u003e\u003e Action: packages/python/hello.py \u003e Deploying: \u003e\u003e Package: python $ $OPS package update python ok: updated package python \u003e\u003e\u003e Action: packages/python/hello.py $ $OPS action update python/hello packages/python/hello.py --web true --kind python:default ok: updated action python/hello build process exited with code 0 UPLOAD ASSETS FROM web ==================| UPLOAD RESULTS |================== | FILES : 0 | COMPLETED : 0 | ERRORS : 0 | SKIPPED : 0 | EXEC. TIME : 2.37 ms ====================================================== URL: http://opstutorial.localhost:80 Note: To use a specific version of Python runtime, change the kind property --kind python:3.11, or --kind python:3.12 in the hello.py file.\nTo invoke the action run the following command: ops action invoke python/hello --param name Marina --result Packaging Python actions in zip files Sometimes you action would be more complex and probably you prefer to create multiple file in order to organize better your code.\nIn this example we’re creating a more complex python action.\nCreate a folder complex_action inside packages/python folder. Then create two python files main.py\n#--web true #--kind python:default import utils def main(args): name = args.get(\"name\", \"stranger\") result = utils.concat_string(\"Nice to meet you,\",name) return {\"greeting\": result} utils.py\ndef concat_string(first_string: str, second_string: str): return f\"{first_string} {second_string}\" Note: The filename of the source file containing the entry point (e.g., main) must be __main__.py.\nDeploy the action using ide deploy ops ide deploy Now you can invoke your action. In this case the action name is python/complex_action ops action invoke python/complex_action --param name Marina --result ","categories":"","description":"","excerpt":" Creating and invoking Python actions The process of creating Python …","ref":"/docs/reference/runtimes/python/","tags":"","title":"Python"},{"body":"python:v3.10 (default: false) Library Version Link beautifulsoup4 4.10.0 PyPI httplib2 0.19.1 PyPI kafka_python 2.0.2 PyPI python-dateutil 2.8.2 PyPI requests 2.31.0 PyPI scrapy 2.5.0 PyPI simplejson 3.17.5 PyPI twisted 21.7.0 PyPI netifaces 0.11.0 PyPI pyyaml 6.0 PyPI redis 4.4.2 PyPI boto3 1.28.25 PyPI psycopg 3.1.10 PyPI pymongo 4.4.1 PyPI minio 7.1.16 PyPI openai 1.7.1 PyPI auth0-python 4.6.0 PyPI langchain 0.1.0 PyPI farm-haystack 1.23.0 PyPI nltk 3.8.1 PyPI langdetect 1.0.9 PyPI ollama 0.1.9 PyPI joblib 1.4.2 PyPI lightgbm 4.5.0 PyPI feedparser 6.0.11 PyPI numpy 1.26.4 PyPI scikit-learn 1.5.2 PyPI bcrypt 4.2.1 PyPI ","categories":"","description":"","excerpt":"python:v3.10 (default: false) Library Version Link beautifulsoup4 …","ref":"/docs/reference/runtimes/python/pythonv3.10/","tags":"","title":"python:v3.10"},{"body":"python:v3.11 (default: false) Library Version Link beautifulsoup4 4.10.0 PyPI httplib2 0.19.1 PyPI kafka_python 2.0.2 PyPI python-dateutil 2.8.2 PyPI requests 2.31.0 PyPI scrapy 2.5.0 PyPI simplejson 3.17.5 PyPI twisted 21.7.0 PyPI netifaces 0.11.0 PyPI pyyaml 6.0 PyPI redis 4.4.2 PyPI boto3 1.28.25 PyPI psycopg 3.1.10 PyPI pymongo 4.4.1 PyPI minio 7.1.16 PyPI openai 1.7.1 PyPI auth0-python 4.6.0 PyPI langchain 0.1.0 PyPI farm-haystack 1.23.0 PyPI nltk 3.8.1 PyPI langdetect 1.0.9 PyPI plotly 5.19.0 PyPI ollama 0.1.9 PyPI joblib 1.4.2 PyPI lightgbm 4.5.0 PyPI feedparser 6.0.11 PyPI numpy 1.26.4 PyPI scikit-learn 1.5.2 PyPI bcrypt 4.2.1 PyPI ","categories":"","description":"","excerpt":"python:v3.11 (default: false) Library Version Link beautifulsoup4 …","ref":"/docs/reference/runtimes/python/pythonv3.11/","tags":"","title":"python:v3.11"},{"body":"python:v3.12 (default: false) Library Version Link beautifulsoup4 4.10.0 PyPI ollama 0.4.5 PyPI openai 1.59.3 PyPI pymilvus 2.5.3 PyPI redis 5.2.1 PyPI pillow 11.1.0 PyPI nltk 3.8.1 PyPI httplib2 0.19.1 PyPI kafka_python 2.0.2 PyPI python-dateutil 2.8.2 PyPI requests 2.32.2 PyPI scrapy 2.5.0 PyPI simplejson 3.17.5 PyPI twisted 21.7.0 PyPI netifaces 0.11.0 PyPI pyyaml 6.0.2 PyPI boto3 1.35.98 PyPI psycopg 3.1.10 PyPI pymongo 4.4.1 PyPI minio 7.1.16 PyPI auth0-python 4.6.0 PyPI langdetect 1.0.9 PyPI plotly 5.19.0 PyPI joblib 1.4.2 PyPI lightgbm 4.5.0 PyPI feedparser 6.0.11 PyPI numpy 1.26.4 PyPI scikit-learn 1.5.2 PyPI langchain 0.3.14 PyPI langchain-ollama 0.2.2 PyPI langchain-openai 0.2.14 PyPI langchain-anthropic 0.3.1 PyPI langchain-together 0.2.0 PyPI langchain-postgres 0.0.12 PyPI langchain-milvus 0.1.7 PyPI bcrypt 4.2.1 PyPI chevron 0.14.0 PyPI chess 1.11.1 PyPI ","categories":"","description":"","excerpt":"python:v3.12 (default: false) Library Version Link beautifulsoup4 …","ref":"/docs/reference/runtimes/python/pythonv3.12/","tags":"","title":"python:v3.12"},{"body":"Adding Action Language Runtimes OpenWhisk and OpenServerless supports several languages and runtimes but there may be other languages or runtimes that are important for your organization, and for which you want tighter integration with the platform.\nThe platform is extensible and you can add new languages or runtimes (with custom packages and third-party dependencies)\n💡 NOTE\nThis guide describes the contract a runtime must satisfy. However all the OpenServerless runtimes are implemented the using the ActionLoop Proxy. This proxy is implemented in Go, already satifies the semantic of a runtime ands makes very easy to build a new runtime. You just need to provide “launcher code” in your favorite programming language and a compilation script (generally written in python) for the initialization of an action. You are advised to use it for your own runtimes and use the material of this document as reference for the behaviour of a runtime.\nRuntime general requirements The unit of execution for all functions is a Docker container which must implement a specific Action interface that, in general performs:\nInitialization - accepts an initialization payload (the code) and prepared for execution,\nActivation - accepts a runtime payload (the input parameters) and\nprepares the activation context,\nruns the function,\nreturns the function result,\nLogging - flushes all stdout and stderr logs and adds a frame marker at the end of the activation.\nThe specifics of the Action interface and its functions are shown below.\nThe runtimes manifest Actions when created specify the desired runtime for the function via a property called kind. When using the nuv CLI, this is specified as --kind \u003cruntime-kind\u003e. The value is typically a string describing the language (e.g., nodejs) followed by a colon and the version for the runtime as in nodejs:20 or php:8.1.\nThe manifest is a map of runtime family names to an array of specific kinds. As an example, the following entry add a new runtime family called nodejs with a single kind nodejs:20.\n{ \"nodejs\": [{ \"kind\": \"nodejs:20\", \"default\": true, \"image\": { \"prefix\": \"openwhisk\", \"name\": \"action-nodejs-v20\", \"tag\": \"latest\" } }] } The default property indicates if the corresponding kind should be treated as the default for the runtime family. The JSON image structure defines the Docker image name that is used for actions of this kind (e.g., openwhisk/nodejs10action:latest for the JSON example above).\nThe test action The standard test action is shown below in JavaScript. It should be adapted for the new language and added to the test artifacts directory with the name \u003cruntime-kind\u003e.txt for plain text file or \u003cruntime-kind\u003e.bin for a a binary file. The \u003cruntime-kind\u003e must match the value used for kind in the corresponding runtime manifest entry, replacing : in the kind with a -. For example, a plain text function for nodejs:20 becomes nodejs-20.txt.\nfunction main(args) { var str = args.delimiter + \" ☃ \" + args.delimiter; console.log(str); return { \"winter\": str }; } Action Interface An action consists of the user function (and its dependencies) along with a proxy that implements a canonical protocol to integrate with the OpenWhisk and OpenServerless platform.\nThe proxy is a web server with two endpoints.\nIt listens on port 8080.\nIt implements /init to initialize the container.\nIt also implements /run to activate the function.\nThe proxy also prepares the execution context, and flushes the logs produced by the function to stdout and stderr.\nInitialization The initialization route is /init. It must accept a POST request with a JSON object as follows:\n{ \"value\": { \"name\" : String, \"main\" : String, \"code\" : String, \"binary\": Boolean, \"env\": Map[String, String] } } name is the name of the action.\nmain is the name of the function to execute.\ncode is either plain text or a base64 encoded string for binary functions (i.e., a compiled executable).\nbinary is false if code is in plain text, and true if code is base64 encoded.\nenv is a map of key-value pairs of properties to export to the environment. And contains several properties starting with the __OW_ prefix that are specific to the running action.\n__OW_API_KEY the API key for the subject invoking the action, this key may be a restricted API key. This property is absent unless explicitly requested.\n__OW_NAMESPACE the namespace for the activation (this may not be the same as the namespace for the action).\n__OW_ACTION_NAME the fully qualified name of the running action.\n__OW_ACTION_VERSION the internal version number of the running action.\n__OW_ACTIVATION_ID the activation id for this running action instance.\n__OW_DEADLINE the approximate time when this initializer will have consumed its entire duration quota (measured in epoch milliseconds).\nThe initialization route is called exactly once by the OpenWhisk and OpenServerless platform, before executing a function. The route should report an error if called more than once. It is possible however that a single initialization will be followed by many activations (via /run). If an env property is provided, the corresponding environment variables should be defined before the action code is initialized.\nSuccessful initialization: The route should respond with 200 OK if the initialization is successful and the function is ready to execute. Any content provided in the response is ignored.\nFailures to initialize: Any response other than 200 OK is treated as an error to initialize. The response from the handler if provided must be a JSON object with a single field called error describing the failure. The value of the error field may be any valid JSON value. The proxy should make sure to generate meaningful log message on failure to aid the end user in understanding the failure.\nTime limit: Every action in OpenWhisk and OpenServerless has a defined time limit (e.g., 60 seconds). The initialization must complete within the allowed duration. Failure to complete initialization within the allowed time frame will destroy the container.\nLimitation: The proxy does not currently receive any of the activation context at initialization time. There are scenarios where the context is convenient if present during initialization. This will require a change in the OpenWhisk and OpenServerless platform itself. Note that even if the context is available during initialization, it must be reset with every new activation since the information will change with every execution.\nActivation The proxy is ready to execute a function once it has successfully completed initialization. The OpenWhisk and OpenServerless platform will invoke the function by posting an HTTP request to /run with a JSON object providing a new activation context and the input parameters for the function. There may be many activations of the same function against the same proxy (viz. container). Currently, the activations are guaranteed not to overlap — that is, at any given time, there is at most one request to /run from the OpenWhisk and OpenServerless platform.\nThe route must accept a JSON object and respond with a JSON object, otherwise the OpenWhisk and OpenServerless platform will treat the activation as a failure and proceed to destroy the container. The JSON object provided by the platform follows the following schema:\n{ \"value\": JSON, \"namespace\": String, \"action_name\": String, \"api_host\": String, \"api_key\": String, \"activation_id\": String, \"transaction_id\": String, \"deadline\": Number } value is a JSON object and contains all the parameters for the function activation.\nnamespace is the OpenWhisk and OpenServerless namespace for the action (e.g., whisk-system).\naction_name is the fully qualified name of the action.\nactivation_id is a unique ID for this activation.\ntransaction_id is a unique ID for the request of which this activation is part of.\ndeadline is the deadline for the function.\napi_key is the API key used to invoke the action.\nThe value is the function parameters. The rest of the properties become part of the activation context which is a set of environment variables constructed by capitalizing each of the property names, and prefixing the result with __OW_. Additionally, the context must define __OW_API_HOST whose value is the OpenWhisk and OpenServerless API host. This value is currently provided as an environment variable defined at container startup time and hence already available in the context.\nSuccessful activation: The route must respond with 200 OK if the activation is successful and the function has produced a JSON object as its result. The response body is recorded as the result of the activation.\nFailed activation: Any response other than 200 OK is treated as an activation error. The response from the handler must be a JSON object with a single field called error describing the failure. The value of the error field may be any valid JSON value. Should the proxy fail to respond with a JSON object, the OpenWhisk and OpenServerless platform will treat the failure as an uncaught exception. These two failures modes are distinguished by the value of the response.status in the activation record which is application error if the proxy returned an error object, and action developer error otherwise.\nTime limit: Every action in OpenWhisk and OpenServerless has a defined time limit (e.g., 60 seconds). The activation must complete within the allowed duration. Failure to complete activation within the allowed time frame will destroy the container.\nLogging The proxy must flush all the logs produced during initialization and execution and add a frame marker to denote the end of the log stream for an activation. This is done by emitting the token XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX as the last log line for the stdout and stderr streams. Failure to emit this marker will cause delayed or truncated activation logs.\nTesting Action Interface tests The Action interface is enforced via a canonical test suite which validates the initialization protocol, the runtime protocol, ensures the activation context is correctly prepared, and that the logs are properly framed. Your runtime should extend this test suite, and of course include additional tests as needed.\nRuntime proxy tests The tests verify that the proxy can handle the following scenarios:\nTest the proxy can handle the identity functions (initialize and run).\nTest the proxy can handle pre-defined environment variables as well as initialization parameters.\nTest the proxy properly constructs the activation context.\nTest the proxy can properly handle functions with Unicode characters.\nTest the proxy can handle large payloads (more than 1MB).\nTest the proxy can handle an entry point other than main.\nTest the proxy does not permit re-initialization.\nTest the error handling for an action returning an invalid response.\nTest the proxy when initialized with no content.\nThe canonical test suite should be extended by the new runtime tests. Additional tests will be required depending on the feature set provided by the runtime.\nSince the OpenWhisk and OpenServerless platform is language and runtime agnostic, it is generally not necessary to add integration tests. That is the unit tests verifying the protocol are sufficient. However, it may be necessary in some cases to modify the ops CLI or other OpenWhisk and OpenServerless clients. In which case, appropriate tests should be added as necessary. The OpenWhisk and OpenServerless platform will perform a generic integration test as part of its basic system tests. This integration test will require a test function to be available so that the test harness can create, invoke, and delete the action.\n","categories":"","description":"How to add new languages to your system","excerpt":"How to add new languages to your system","ref":"/docs/reference/references/actions-new/","tags":"","title":"Runtimes under the hood"},{"body":"Sending notifications Contact notification It would be great if we receive a notification when a user tries to contact us.\nFor this tutorial we will use a free service that instantly generates a unique URL through which you can receive and view webhook payloads in real time.\n💡 NOTE\nYou could replace this service with a workflow automation system, with your CRM webhook, with Slack hooks etc.\nBy navigating to the site https://webhook.site/ you will receive a unique url, as in the image below:\nTake note of the url under the “Your unique URL” title.\nOnce we have a webhook we can proceed to create a new action called notify.js (in the packages/contact folder).\nThe directory structure will be:\ncontact_us_app ├── packages │ └── contact │ ├── create-table.js │ ├── notify.js │ ├── submit.js │ └── write.js └── web └── index.html Place this content inside the notify.js file:\n// notify.js //--param NOTIFICATION_URL $NOTIFICATION_URL function main(args) { const { name, email, phone, message } = args; const subject = `New contact request from Apache OpenServerless`; const payload = { subject, name, email, phone, message, }; console.log(\"Built message\", payload); return fetch(args.NOTIFICATION_URL, { method: 'POST', headers: { 'Content-Type': 'application/json', }, body: JSON.stringify(payload), }) .then(response =\u003e { if (!response.ok) { console.log(\"Error sending message. Status code:\", response.status); } else { console.log(\"Message sent successfully\"); } return { body: args.body, }; }) .catch(error =\u003e { console.log(\"Error sending message\", error); return { body: error, }; }); } 💡 NOTE\nIn this case, we don’t need to annotate the action as web. This because this action will be invoked in a sequence: so it’s an internal action and is not exposed as an api.\nThis action has the args.NOTIFICATION_URL parameter, which is the webhook. It also has the usual 4 form fields parameters that receives in input, used to build the text of the message. The action will return the body of the response from the webhook.\nThe NOTIFICATION_URL may contains different values between a development environment and a production one. No problem! Apache OpenServerless deployer supports .env file. Create a .env file under the package directory.\nThe directory structure now will look like:\ncontact_us_app ├── packages │ ├── .env │ └── contact │ ├── create-table.js │ ├── notify.js │ ├── submit.js │ └── write.js └── web └── index.html Inside the .env file put this content:\nNOTIFICATION_URL=\u003curl\u003e Replace \u003curl\u003e with the url received from webhook.site.\nNow deploy everything as usual, giving:\nops ide deploy Creating Another Action Sequence We have developed an action that can send a message as a standalone action, but we designed it to take the output of the submit action and return it as is. Time to extend the previous sequence!\nNote that it will send messages for every submission, even for incorrect inputs, so we will know if someone is trying to use the form without providing all the information. But we will only store the fully validated data in the database.\nLet’s create the sequence, and then test it:\nops action create contact/submit-notify --sequence contact/submit-write,contact/notify --web true You should see this output:\nok: created action contact/submit-notify We just created a new sequence submit-notify from the previous sequence submit-write and the new notify.\nIf you want to get more info about this sequence, you can use the ops action get command:\nops action get contact/submit-notify You should see this output:\n{ \"namespace\": \"openserverless/contact\", \"name\": \"submit-notify\", \"version\": \"0.0.1\", \"exec\": { \"kind\": \"sequence\", \"components\": [ \"/openserverless/contact/submit-write\", \"/openserverless/contact/notify\" ] }, ... } See how the exec key has a kind of sequence and a list of components that are the actions that compose the sequence.\nNow to start using this sequence instead of using the submit action, we need to update the web/index.html page to invoke the new sequence.\nAs before let’s grab the url:\nops url contact/submit-notify \u003capihost\u003e/api/v1/web/openserverless/contact/submit-notify And update the action inside the file web/index.html:\n\u003cform method=\"POST\" action=\"/api/v1/web/opstutorial/contact/submit-notify\" enctype=\"application/x-www-form-urlencoded\"\u003e Don’t forget to re-publish everything with ops ide deploy.\nNow try to fill out the form again and press send! It will execute the sequence and you will receive the message piped from action /contact/submit-write to /contact/notify.\nThe tutorial introduced you to some utilities to retrieve information and to the concept of activation. Let’s use some more commands to check out the logs and see if the message was really sent.\nThe easiest way to check for all the activations that happen in this app with all their logs is:\nops activation poll Enter Ctrl-c to exit. Polling for activation logs This command polls continuously for log messages. If you go ahead and submit a message in the app, all the actions will show up here together with their log messages.\nTo also check if there are some problems with your actions, run a couple of times ops activation list and check the Status of the activations. If you see some developer error or any other errors, just grab the activation ID and run ops logs \u003cactivation ID\u003e.\n","categories":"","description":"Sending notifications on user interaction","excerpt":"Sending notifications on user interaction","ref":"/docs/tutorial/notify-message/","tags":"","title":"Sending notifications"},{"body":"Triggers Now let’s see what a trigger is and how to use it.\nWe can define a trigger as an object representing an event source that triggers the execution of actions. When activated by an event, associated actions are executed.\nIn other words, a trigger is a mechanism that listens for specific events or conditions and initiates actions in response to those events. It acts as the starting point for a workflow.\nExample: Sending Slack Notifications Let’s consider a scenario where we want to send Slack notifications when users visit specific pages and submit a contact form.\nStep 1: Define the Trigger We create a trigger named “PageVisitTrigger” that listens for events related to user visits on our website. To create it, you can use the following command:\nops trigger create PageVisitTrigger Once the trigger is created, you can update it to add parameters, such as the page parameter:\nops trigger update PageVisitTrigger --param page homepage 💡 NOTE\nOf course, there are not only create and update, but also delete, and they work as expected, updating and deleting triggers. In the next paragraph, we will also see the fire command, which requires you to first create rules to do something useful.\nStep 2: Associate the Trigger with an Action Next, we create an action named “SendSlackNotification” that sends a notification to Slack when invoked. Then, we associate this action with our “PageVisitTrigger” trigger, specifying that it should be triggered when users visit certain pages.\nTo associate the trigger with an action, you can use the following command:\nops rule create TriggerRule PageVisitTrigger SendSlackNotification We’ll have a better understanding of this aspect in Rules\nIn this example, whenever a user visits either the homepage or the contact page, the “SendSlackNotification” action will be triggered, resulting in a Slack notification being sent.\nConclusion Triggers provide a flexible and scalable way to automate workflows based on various events. By defining triggers and associating them with actions, you can create powerful applications that respond dynamically to user interactions, system events, or any other specified conditions.\n","categories":"","description":"Event source that triggers an action execution","excerpt":"Event source that triggers an action execution","ref":"/docs/cli/entities/triggers/","tags":"","title":"Triggers"},{"body":"App Deployment Deploy Apache OpenServerless makes publishing a project a very simple operation. The project, organized in two main folders packages for the backend and web for the frontend, can be published immediately using the command ops ide deploy.\nOnce launched, the command takes care of:\ncreating the packages preparing the actions with the relative dependencies publishing the actions Through the use of files according to the OpenWhisk manifests.yml standard, it is also possible to publish sequences, triggers and much more at the same time.\n💡 NOTE\nAn OpenWhisk’s manifest file can be useful to automate the deploy of sequences, triggers, rules. Action and packages are simpler to deploy using ops ide deploy\nThe ops ide deploy command also takes care of managing the parameters inserted in the annotations and injecting the variables from the configuration or from the .env file located in the packages folder.\nPackaging the App Even if not necessary, we’ll package both actions and sequences. Let’s create, inside the packages folder, two files:\n01-actions.yaml 02-sequences.yaml We’ll do so, because actions are required to deploy sequences.\nThe directory structure should be like this:\ncontact_us_app ├── packages │ ├── 01-actions.yaml │ ├── 02-sequences.yaml │ └── contact │ ├── create-table.js │ ├── notify.js │ ├── submit.js │ └── write.js └── web └── index.html The Action Manifest File Inside the 01-actions.yaml put this content:\npackages: contact: inputs: POSTGRES_URL: type: string value: $POSTGRES_URL actions: submit: function: contact/submit.js web: true write: function: contact/write.js web: true notify: function: contact/notify.js web: true inputs: NOTIFICATION_URL: type: string value: $NOTIFICATION_URL create-table: function: contact/create-table.js At the top level we have the standard packages keyword, under which we can define the packages we want. Until now we created all of our actions in the contact package so we add it under packages.\nThen under each package, the actions keyword is needed so we can add our action custom names with the path to the code (with function). Finally we also add web: true which is equivalent to --web true when creating the action manually.\nFinally we used the inputs keyword to define the parameters to inject in the function.\nThis file will be automatically deployed by the ops ide deploy command.\nThe Sequences Manifest File Inside the 01-actions.yaml put this content:\npackages: contact: sequences: submit-write: actions: submit, write web: true submit-notify: actions: submit-write, notify web: true At the top level we define the packages keyword and immediately after, the contact package. We just have to add the sequences key at the contact level and define the sequences we want with the available actions.\nAlso this file will be automatically deployed by the ops ide deploy command.\nTest the deploy To test the deploy, let’s run again the command ops ide deploy:\nops ide deploy /Users/openserverless/.ops/tmp/deploy.pid PID 28177 \u003e Scan: \u003e\u003e Action: packages/contact/write.js \u003e\u003e Action: packages/contact/create-table.js \u003e\u003e Action: packages/contact/submit.js \u003e\u003e Action: packages/contact/notify.js \u003e Deploying: \u003e\u003e Package: contact $ $OPS package update contact ok: updated package contact \u003e\u003e\u003e Action: packages/contact/write.js $ $OPS action update contact/write packages/contact/write.js --kind nodejs:default --param POSTGRES_URL $POSTGRES_URL ok: updated action contact/write \u003e\u003e\u003e Action: packages/contact/create-table.js $ $OPS action update contact/create-table packages/contact/create-table.js --kind nodejs:default --param POSTGRES_URL $POSTGRES_URL ok: updated action contact/create-table \u003e\u003e\u003e Action: packages/contact/submit.js $ $OPS action update contact/submit packages/contact/submit.js --web true --kind nodejs:default ok: updated action contact/submit \u003e\u003e\u003e Action: packages/contact/notify.js $ $OPS action update contact/notify packages/contact/notify.js --param NOTIFICATION_URL $NOTIFICATION_URL ok: updated action contact/notify Found packages .env file. Reading it \u003e\u003e\u003e Manifest: packages/01-actions.yaml $ $OPS -wsk project deploy --manifest packages/01-actions.yaml Success: Deployment completed successfully. \u003e\u003e\u003e Manifest: packages/02-sequences.yaml $ $OPS -wsk project deploy --manifest packages/02-sequences.yaml Success: Deployment completed successfully. build process exited with code 0 UPLOAD ASSETS FROM web ==================| UPLOAD RESULTS |================== | FILES : 1 | COMPLETED : 1 | ERRORS : 0 | SKIPPED : 0 | EXEC. TIME : 35.72 ms ====================================================== URL: http://opstutorial.localhost:80 As you can see, after deploying the actions, the deployer will find the manifest files and deploy them in lexicographic order.\n","categories":"","description":"Learn how to deploy your app on Apache Openserverless","excerpt":"Learn how to deploy your app on Apache Openserverless","ref":"/docs/tutorial/packaging/","tags":"","title":"App Deployment"},{"body":"Developing a new Runtime with the ActionLoop proxy The OpenWhisk and OpenServerless runtime specification defines the expected behavior of an OpenWhisk and OpenServerless runtime; you can choose to implement a new runtime from scratch by just following this specification. However, the fastest way to develop a new, compliant runtime is by reusing the ActionLoop proxy which already implements most of the specification and requires you to write code for just a few hooks to get a fully functional (and fast) runtime in a few hours or less.\nWhat is the ActionLoop proxy The ActionLoop proxy is a runtime “engine”, written in the Go programming language, originally developed specifically to support the OpenWhisk and OpenServerless Go language runtime. However, it was written in a generic way such that it has since been adopted to implement OpenWhisk and OpenServerless runtimes for Swift, PHP, Python, Rust, Java, Ruby and Crystal. Even though it was developed with compiled languages in mind it works equally well with scripting languages.\nUsing it, you can develop a new runtime in a fraction of the time needed for authoring a full-fledged runtime from scratch. This is due to the fact that you have only to write a command line protocol and not a fully-featured web server (with a small amount of corner cases to consider). The results should also produce a runtime that is fairly fast and responsive. In fact, the ActionLoop proxy has also been adopted to improve the performance of existing runtimes like Python, Ruby, PHP, and Java where performance has improved by a factor between 2x to 20x.\nPrecompilation of OpenWhisk and OpenServerless Actions In addition to being the basis for new runtime development, ActionLoop runtimes can also support offline “precompilation” of OpenWhisk and OpenServerless Action source files into a ZIP file that contains only the compiled binaries which are very fast to start once deployed. More information on this approach can be found here: Precompiling Go Sources Offline which describes how to do this for the Go language, but the approach applies to any language supported by ActionLoop.\nTutorial - How to write a new runtime with the ActionLoop Proxy This section contains a stepwise tutorial which will take you through the process of developing a new ActionLoop runtime using the Ruby language as the example.\nGeneral development process The general procedure for authoring a runtime with the ActionLoop proxy requires the following steps:\nbuilding a docker image containing your target language compiler and the ActionLoop runtime.\nwriting a simple line-oriented protocol in your target language.\nwriting a compilation script for your target language.\nwriting some mandatory tests for your language.\nActionLoop Starter Kit To facilitate the process, there is an actionloop-starter-kit in the openwhisk-devtools GitHub repository, that implements a fully working runtime for Python. It contains a stripped-down version of the real Python runtime (with some advanced features removed) along with guided, step-by-step instructions on how to translate it to a different target runtime language using Ruby as an example.\nIn short, the starter kit provides templates you can adapt in creating an ActionLoop runtime for each of the steps listed above, these include :\n-checking out the actionloop-starter-kit from the openwhisk-devtools repository -editing the Dockerfile to create the target environment for your target language. -converting (rewrite) the launcher.py script to an equivalent for script for your target language. -editing the compile script to compile your action in your target language. -writing the mandatory tests for your target language, by adapting the ActionLoopPythonBasicTests.scala file.\nAs a starting language, we chose Python since it is one of the more human-readable languages (can be treated as pseudo-code). Do not worry, you should only need just enough Python knowledge to be able to rewrite launcher.py and edit the compile script for your target language.\nFinally, you will need to update the ActionLoopPythonBasicTests.scala test file which, although written in the Scala language, only serves as a wrapper that you will use to embed your target language tests into.\nNotation In each step of this tutorial, we typically show snippets of either terminal transcripts (i.e., commands and results) or “diffs” of changes to existing code files.\nWithin terminal transcript snippets, comments are prefixed with # character and commands are prefixed by the $ character. Lines that follow commands may include sample output (from their execution) which can be used to verify against results in your local environment.\nWhen snippets show changes to existing source files, lines without a prefix should be left “as is”, lines with - should be removed and lines with + should be added.\nPrerequisites Docker engine - please have a valid docker engine installed that supports multi-stage builds (i.e., Docker 17.05 or higher) and assure the Docker daemon is running. # Verify docker version $ docker --version Docker version 18.09.3 # Verify docker is running $ docker ps # The result should be a valid response listing running processes Setup the development directory So let’s start to create our own actionloop-demo-ruby-2.6 runtime. First, check out the devtools repository to access the starter kit, then move it in your home directory to work on it.\ngit clone https://github.com/apache/openwhisk-devtools mv openwhisk-devtools/actionloop-starter-kit ~/actionloop-demo-ruby-v2.6 Now, take the directory python3.7 and rename it to ruby2.6 and use sed to fix the directory name references in the Gradle build files.\ncd ~/actionloop-demo-ruby-v2.6 mv python3.7 ruby2.6 sed -i.bak -e 's/python3.7/ruby2.6/' settings.gradle sed -i.bak -e 's/actionloop-demo-python-v3.7/actionloop-demo-ruby-v2.6/' ruby2.6/build.gradle Let’s check everything is fine building the image.\n# building the image $ ./gradlew distDocker # ... intermediate output omitted ... BUILD SUCCESSFUL in 1s 2 actionable tasks: 2 executed # checking the image is available $ docker images actionloop-demo-ruby-v2.6 REPOSITORY TAG IMAGE ID CREATED SIZE actionloop-demo-ruby-v2.6 latest df3e77c9cd8f 2 minutes ago 94.3MB At this point, we have built a new image named actionloop-demo-ruby-v2.6. However, despite having Ruby in the name, internally it still is a Python language runtime which we will need to change to one supporting Ruby as we continue in this tutorial.\nPreparing the Docker environment Our language runtime’s Dockerfile has the task of preparing an environment for executing OpenWhisk and OpenServerless Actions. Using the ActionLoop approach, we use a multistage Docker build to\nderive our OpenWhisk and OpenServerless language runtime from an existing Docker image that has all the target language’s tools and libraries for running functions authored in that language.\nIn our case, we will reference the ruby:2.6.2-alpine3.9 image from the Official Docker Images for Ruby on Docker Hub. leverage the existing openwhisk/actionlooop-v2 image on Docker Hub from which we will “extract” the ActionLoop proxy (i.e. copy /bin/proxy binary) our runtime will use to process Activation requests from the OpenWhisk and OpenServerless platform and execute Actions by using the language’s tools and libraries from step #1.\nRepurpose the renamed Python Dockerfile for Ruby builds Let’s edit the ruby2.6/Dockerfile to use the official Ruby image on Docker Hub as our base image, instead of a Python image, and add our our Ruby launcher script:\nFROM openwhisk/actionloop-v2:latest as builder -FROM python:3.7-alpine +FROM ruby:2.6.2-alpine3.9 RUN mkdir -p /proxy/bin /proxy/lib /proxy/action WORKDIR /proxy COPY --from=builder /bin/proxy /bin/proxy -ADD lib/launcher.py /proxy/lib/launcher.py +ADD lib/launcher.rb /proxy/lib/launcher.rb ADD bin/compile /proxy/bin/compile +RUN apk update \u0026\u0026 apk add python3 ENV OW_COMPILER=/proxy/bin/compile ENTRYPOINT [\"/bin/proxy\"] Next, let’s rename the launcher.py (a Python script) to one that indicates it is a Ruby script named launcher.rb.\nmv ruby2.6/lib/launcher.py ruby2.6/lib/launcher.rb Note that:\nYou changed the base Docker image to use a Ruby language image.\nYou changed the launcher script from Python to Ruby.\nWe had to add a python3 package to our Ruby image since our compile script will be written in Python for this tutorial. Of course, you may choose to rewrite the compile script in Ruby if you wish to as your own exercise.\nImplementing the ActionLoop protocol This section will take you through how to convert the contents of launcher.rb (formerly launcher.py) to the target Ruby programming language and implement the ActionLoop protocol.\nWhat the launcher needs to do Let’s recap the steps the launcher must accomplish to implement the ActionLoop protocol :\nimport the Action function’s main method for execution.\nNote: the compile script will make the function available to the launcher. open the system’s file descriptor 3 which will be used to output the functions response.\nread the system’s standard input, stdin, line-by-line. Each line is parsed as a JSON string and produces a JSON object (not an array nor a scalar) to be passed as the input arg to the function.\nNote: within the JSON object, the value key contains the user parameter data to be passed to your functions. All the other keys are made available as process environment variables to the function; these need to be uppercased and prefixed with \"__OW_\". invoke the main function with the JSON object payload.\nencode the result of the function in JSON (ensuring it is only one line and it is terminated with one newline) and write it to file descriptor 3.\nOnce the function returns the result, flush the contents of stdout, stderr and file descriptor 3 (FD 3).\nFinally, include the above steps in a loop so that it continually looks for Activations. That’s it.\nConverting launcher script to Ruby Now, let’s look at the protocol described above, codified within the launcher script launcher.rb, and work to convert its contents from Python to Ruby.\nImport the function code Skipping the first few library import statements within launcer.rb, which we will have to resolve later after we determine which ones Ruby may need, we see the first significant line of code importing the actual Action function.\n# now import the action as process input/output from main__ import main as main In Ruby, this can be rewritten as:\n# requiring user's action code require \"./main__\" Note that you are free to decide the path and filename for the function’s source code. In our examples, we chose a base filename that includes the word \"main\" (since it is OpenWhisk and OpenServerless default function name) and append two underscores to better assure uniqueness.\nOpen File Descriptor (FD) 3 for function results output The ActionLoop proxy expects to read the results of invoking the Action function from File Descriptor (FD) 3.\nThe existing Python:\nout = fdopen(3, \"wb\") would be rewritten in Ruby as:\nout = IO.new(3) Process Action’s arguments from STDIN Each time the function is invoked via an HTTP request, the ActionLoop proxy passes the message contents to the launcher via STDIN. The launcher must read STDIN line-by-line and parse it as JSON.\nThe launcher’s existing Python code reads STDIN line-by-line as follows:\nwhile True: line = stdin.readline() if not line: break # ...continue... would be translated to Ruby as follows:\nwhile true # JSON arguments get passed via STDIN line = STDIN.gets() break unless line # ...continue... end Each line is parsed in JSON, where the payload is extracted from contents of the \"value\" key. Other keys and their values are as uppercased, \"__OW_\" prefixed environment variables:\nThe existing Python code for this is:\n# ... continuing ... args = json.loads(line) payload = {} for key in args: if key == \"value\": payload = args[\"value\"] else: os.environ[\"__OW_%s\" % key.upper()]= args[key] # ... continue ... would be translated to Ruby:\n# ... continuing ... args = JSON.parse(line) payload = {} args.each do |key, value| if key == \"value\" payload = value else # set environment variables for other keys ENV[\"__OW_#{key.upcase}\"] = value end end # ... continue ... Invoking the Action function We are now at the point of invoking the Action function and producing its result. Note we must also capture exceptions and produce an {\"error\": \u003cresult\u003e } if anything goes wrong during execution.\nThe existing Python code for this is:\n# ... continuing ... res = {} try: res = main(payload) except Exception as ex: print(traceback.format_exc(), file=stderr) res = {\"error\": str(ex)} # ... continue ... would be translated to Ruby:\n# ... continuing ... res = {} begin res = main(payload) rescue Exception =\u003e e puts \"exception: #{e}\" res [\"error\"] = \"#{e}\" end # ... continue ... Finalize File Descriptor (FD) 3, STDOUT and STDERR Finally, we need to write the function’s result to File Descriptor (FD) 3 and “flush” standard out (stdout), standard error (stderr) and FD 3.\nThe existing Python code for this is:\nout.write(json.dumps(res, ensure_ascii=False).encode('utf-8')) out.write(b'\\n') stdout.flush() stderr.flush() out.flush() would be translated to Ruby:\nSTDOUT.flush() STDERR.flush() out.puts(res.to_json) out.flush() Congratulations! You just completed your ActionLoop request handler.\nWriting the compilation script Now, we need to write the compilation script. It is basically a script that will prepare the uploaded sources for execution, adding the launcher code and generate the final executable.\nFor interpreted languages, the compilation script will only “prepare” the sources for execution. The executable is simply a shell script to invoke the interpreter.\nFor compiled languages, like Go it will actually invoke a compiler in order to produce the final executable. There are also cases like Java where we still need to execute the compilation step that produces intermediate code, but the executable is just a shell script that will launch the Java runtime.\nHow the ActionLoop proxy handles action uploads The OpenWhisk and OpenServerless user can upload actions with the ops Command Line Interface (CLI) tool as a single file.\nThis single file can be:\na source file\nan executable file\na ZIP file containing sources\na ZIP file containing an executable and other support files\nImportant: an executable for ActionLoop is either a Linux binary (an ELF executable) or a script. A script is, using Linux conventions, is anything starting with #!. The first line is interpreted as the command to use to launch the script: #!/bin/bash, #!/usr/bin/python etc.\nThe ActionLoop proxy accepts any file, prepares a work folder, with two folders in it named \"src\" and \"bin\". Then it detects the format of the uploaded file. For each case, the behavior is different.\nIf the uploaded file is an executable, it is stored as bin/exec and executed.\nIf the uploaded file is not an executable and not a zip file, it is stored as src/exec then the compilation script is invoked.\nIf the uploaded file is a zip file, it is unzipped in the src folder, then the src/exec file is checked.\nIf it exists and it is an executable, the folder src is renamed to bin and then again the bin/exec is executed.\nIf the src/exec is missing or is not an executable, then the compiler script is invoked.\nCompiling an action in source format The compilation script is invoked only when the upload contains sources. According to the description in the past paragraph, if the upload is a single file, we can expect the file is in src/exec, without any prefix. Otherwise, sources are spread the src folder and it is the task of the compiler script to find the sources. A runtime may impose that when a zip file is uploaded, then there should be a fixed file with the main function. For example, the Python runtime expects the file __main__.py. However, it is not a rule: the Go runtime does not require any specific file as it compiles everything. It only requires a function with the name specified.\nThe compiler script goal is ultimately to leave in bin/exec an executable (implementing the ActionLoop protocol) that the proxy can launch. Also, if the executable is not standalone, other files must be stored in this folder, since the proxy can also zip all of them and send to the user when using the pre-compilation feature.\nThe compilation script is a script pointed by the OW_COMPILER environment variable (you may have noticed it in the Dockerfile) that will be invoked with 3 parameters:\n\u003cmain\u003e is the name of the main function specified by the user on the ops command line\n\u003csrc\u003e is the absolute directory with the sources already unzipped\nan empty \u003cbin\u003e directory where we are expected to place our final executables\nNote that both the \u003csrc\u003e and \u003cbin\u003e are disposable, so we can do things like removing the \u003cbin\u003e folder and rename the \u003csrc\u003e.\nSince the user generally only sends a function specified by the \u003cmain\u003e parameter, we have to add the launcher we wrote and adapt it to execute the function.\nImplementing the compile for Ruby This is the algorithm that the compile script in the kit follows for Python:\nif there is a \u003csrc\u003e/exec it must rename to the main file; I use the name main__.py\nif there is a \u003csrc\u003e/__main__.py it will rename to the main file main__.py\ncopy the launcher.py to exec__.py, replacing the main(arg) with \u003cmain\u003e(arg); this file imports the main__.py and invokes the function \u003cmain\u003e\nadd a launcher script \u003csrc\u003e/exec\nfinally it removes the \u003cbin\u003e folder and rename \u003csrc\u003e to \u003cbin\u003e\nWe can adapt this algorithm easily to Ruby with just a few changes.\nThe script defines the functions sources and build then starts the execution, at the end of the script.\nStart from the end of the script, where the script collect parameters from the command line. Instead of launcher.py, use launcher.rb:\n- launcher = \"%s/lib/launcher.py\" % dirname(dirname(sys.argv[0])) + launcher = \"%s/lib/launcher.rb\" % dirname(dirname(sys.argv[0])) Then the script invokes the source function. This function renames the exec file to main__.py, you will rename it instead to main__.rb:\n- copy_replace(src_file, \"%s/main__.py\" % src_dir) + copy_replace(src_file, \"%s/main__.rb\" % src_dir) If instead there is a __main__.py the function will rename to main__.py (the launcher invokes this file always). The Ruby runtime will use a main.rb as starting point. So the next change is:\n- # move __main__ in the right place if it exists - src_file = \"%s/__main__.py\" % src_dir + # move main.rb in the right place if it exists + src_file = \"%s/main.rb\" % src_dir Now, the source function copies the launcher as exec__.py, replacing the line from main__ import main as main (invoking the main function) with from main__ import \u003cmain\u003e as main. In Ruby you may want to replace the line res = main(payload) with res = \u003cmain\u003e(payload). In code it is:\n- copy_replace(launcher, \"%s/exec__.py\" % src_dir, - \"from main__ import main as main\", - \"from main__ import %s as main\" % main ) + copy_replace(launcher, \"%s/exec__.rb\" % src_dir, + \"res = main(payload)\", + \"res = %s(payload)\" % main ) We are almost done. We just need the startup script that instead of invoking python will invoke Ruby. So in the build function do this change:\nwrite_file(\"%s/exec\" % tgt_dir, \"\"\"#!/bin/sh cd \"$(dirname $0)\" -exec /usr/local/bin/python exec__.py +exec ruby exec__.rb \"\"\") For an interpreted language that is all. We move the src folder in the bin. For a compiled language instead, we may want to actually invoke the compiler to produce the executable.\nDebugging Now that we have completed both the launcher and compile scripts, it is time to test them.\nHere we will learn how to:\nenter in a test environment\nsimple smoke tests to check things work\nwriting the validation tests\ntesting the image in an actual OpenWhisk and OpenServerless environment\nEntering in the test environment In the starter kit, there is a Makefile that can help with our development efforts.\nWe can build the Dockerfile using the provided Makefile. Since it has a reference to the image we are building, let’s change it:\nsed -i.bak -e 's/actionloop-demo-python-v3.7/actionloop-demo-ruby-v2.6/' ruby2.6/Makefile We should be now able to build the image and enter in it with make debug. It will rebuild the image for us and put us into a shell so we can enter access the image environment for testing and debugging:\n$ cd ruby2.6 $ make debug # results omitted for brevity ... Let’s start with a couple of notes about this test environment.\nFirst, use --entrypoint=/bin/sh when starting the image to have a shell available at our image entrypoint. Generally, this is true by default; however, in some stripped down base images a shell may not be available.\nSecond, the /proxy folder is mounted in our local directory, so that we can edit the bin/compile and the lib/launcher.rb using our editor outside the Docker image\nNOTE It is not necessary to rebuild the Docker image with every change when using make debug since directories and environment variables used by the proxy indicate where the code outside the Docker container is located.\nOnce at the shell prompt that we will use for development, we will have to start and stop the proxy. The shell will help us to inspect what happened inside the container.\nA simple smoke test It is time to test. Let’s write a very simple test first, converting the example\\hello.py in example\\hello.rb to appear as follows:\ndef hello(args) name = args[\"name\"] || \"stranger\" greeting = \"Hello #{name}!\" puts greeting { \"greeting\" =\u003e greeting } end Now change into the ruby2.6 subdirectory of our runtime project and in one terminal type:\n$ cd \u003cprojectdir\u003e/ruby2.6 $ make debug # results omitted for brevity ... # (you should see a shell prompt of your image) $ /bin/proxy -debug 2019/04/08 07:47:36 OpenWhisk and OpenServerless ActionLoop Proxy 2: starting Now the runtime is started in debug mode, listening on port 8080, and ready to accept Action deployments.\nOpen another terminal (while leaving the first one running the proxy) and go into the top-level directory of our project to test the Action by executing an init and then a couple of run requests using the tools/invoke.py test script.\nThese steps should look something like this in the second terminal:\n$ cd \u003cprojectdir\u003e $ python tools/invoke.py init hello example/hello.rb {\"ok\":true} $ python tools/invoke.py run '{}' {\"greeting\":\"Hello stranger!\"} $ python tools/invoke.py run '{\"name\":\"Mike\"}' {\"greeting\":\"Hello Mike!\"} We should also see debug output from the first terminal running the proxy (with the debug flag) which should have successfully processed the init and run requests above.\nThe proxy’s debug output should appear something like:\n/proxy # /bin/proxy -debug 2019/04/08 07:54:57 OpenWhisk and OpenServerless ActionLoop Proxy 2: starting 2019/04/08 07:58:00 compiler: /proxy/bin/compile 2019/04/08 07:58:00 it is source code 2019/04/08 07:58:00 compiling: ./action/16/src/exec main: hello 2019/04/08 07:58:00 compiling: /proxy/bin/compile hello action/16/src action/16/bin 2019/04/08 07:58:00 compiler out: , \u003cnil\u003e 2019/04/08 07:58:00 env: [__OW_API_HOST=] 2019/04/08 07:58:00 starting ./action/16/bin/exec 2019/04/08 07:58:00 Start: 2019/04/08 07:58:00 pid: 13 2019/04/08 07:58:24 done reading 13 bytes Hello stranger! XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX 2019/04/08 07:58:24 received::{\"greeting\":\"Hello stranger!\"} 2019/04/08 07:58:54 done reading 27 bytes Hello Mike! XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX 2019/04/08 07:58:54 received::{\"greeting\":\"Hello Mike!\"} Hints and tips for debugging Of course, it is very possible something went wrong. Here a few debugging suggestions:\nThe ActionLoop runtime (proxy) can only be initialized once using the init command from the invoke.py script. If we need to re-initialize the runtime, we need to stop the runtime (i.e., with Control-C) and restart it.\nWe can also check what is in the action folder. The proxy creates a numbered folder under action and then a src and bin folder.\nFor example, using a terminal window, we would would see a directory and file structure created by a single action:\n$ find action/ action/1 action/1/bin action/1/bin/exec__.rb action/1/bin/exec action/1/bin/main__.rb Note that the exec starter, exec__.rb launcher and main__.rb action code are have all been copied under a directory numbered`1`.\nIn addition, we can try to run the action directly and see if it behaves properly:\n$ cd action/1/bin $ ./exec 3\u003e\u00261 $ {\"value\":{\"name\":\"Mike\"}} Hello Mike! {\"greeting\":\"Hello Mike!\"} Note we redirected the file descriptor 3 in stdout to check what is happening, and note that logs appear in stdout too.\nAlso, we can test the compiler invoking it directly.\nFirst let’s prepare the environment as it appears when we just uploaded the action:\n$ cd /proxy $ mkdir -p action/2/src action/2/bin $ cp action/1/bin/main__.rb action/2/src/exec $ find action/2 action/2 action/2/bin action/2/src action/2/src/exec Now compile and examine the results again:\n$ /proxy/bin/compile main action/2/src action/2/bin $ find action/2 action/2/ action/2/bin action/2/bin/exec__.rb action/2/bin/exec action/2/bin/main__.rb Testing If we have reached this point in the tutorial, the runtime is able to run and execute a simple test action. Now we need to validate the runtime against a set of mandatory tests both locally and within an OpenWhisk and OpenServerless staging environment. Additionally, we should author and automate additional tests for language specific features and styles.\nThe starter kit includes two handy makefiles that we can leverage for some additional tests. In the next sections, we will show how to update them for testing our Ruby runtime.\nTesting multi-file Actions So far we tested a only an Action comprised of a single file. We should also test multi-file Actions (i.e., those with relative imports) sent to the runtime in both source and binary formats.\nFirst, let’s try a multi-file Action by creating a Ruby Action script named example/main.rb that invokes our hello.rb as follows:\nrequire \"./hello\" def main(args) hello(args) end Within the example/Makefile makefile:\nupdate the name of the image to ruby-v2.6\" as well as the name of the main action.\nupdate the PREFIX with your DockerHub username.\n-IMG=actionloop-demo-python-v3.7:latest -ACT=hello-demo-python -PREFIX=docker.io/openwhisk +IMG=actionloop-demo-ruby-v2.6:latest +ACT=hello-demo-ruby +PREFIX=docker.io/\u003cdocker username\u003e Now, we are ready to test the various cases. Again, start the runtime proxy in debug mode:\ncd ruby2.6 make debug /bin/proxy -debug On another terminal, try to deploy a single file:\n$ make test-single python ../tools/invoke.py init hello ../example/hello.rb {\"ok\":true} python ../tools/invoke.py run '{}' {\"greeting\":\"Hello stranger!\"} python ../tools/invoke.py run '{\"name\":\"Mike\"}' {\"greeting\":\"Hello Mike!\"} Now, stop and restart the proxy and try to send a ZIP file with the sources:\n$ make test-src-zip zip src.zip main.rb hello.rb adding: main.rb (deflated 42%) adding: hello.rb (deflated 42%) python ../tools/invoke.py init ../example/src.zip {\"ok\":true} python ../tools/invoke.py run '{}' {\"greeting\":\"Hello stranger!\"} python ../tools/invoke.py run '{\"name\":\"Mike\"}' {\"greeting\":\"Hello Mike!\"} Finally, test the pre-compilation: the runtime builds a zip file with the sources ready to be deployed. Again, stop and restart the proxy then:\n$ make test-bin-zip docker run -i actionloop-demo-ruby-v2.6:latest -compile main \u003csrc.zip \u003ebin.zip python ../tools/invoke.py init ../example/bin.zip {\"ok\":true} python ../tools/invoke.py run '{}' {\"greeting\":\"Hello stranger!\"} python ../tools/invoke.py run '{\"name\":\"Mike\"}' {\"greeting\":\"Hello Mike!\"} Congratulations! The runtime works locally! Time to test it on the public cloud. So as the last step before moving forward, let’s push the image to Docker Hub with make push.\nTesting on OpenWhisk and OpenServerless To run this test you need to configure access to OpenWhisk and OpenServerless with ops. A simple way is to get access is to register a free account in the IBM Cloud but this works also with our own deployment of OpenWhisk and OpenServerless.\nEdit the Makefile as we did previously:\nIMG=actionloop-demo-ruby-v2.6:latest ACT=hello-demo-ruby PREFIX=docker.io/\u003cdocker username\u003e Also, change any reference to hello.py and main.py to hello.rb and main.rb.\nOnce this is done, we can re-run the tests we executed locally on “the real thing”.\nTest single:\n$ make test-single ops action update hello-demo-ruby hello.rb --docker docker.io/linus/actionloop-demo-ruby-v2.6:latest --main hello ok: updated action hello-demo-ruby ops action invoke hello-demo-ruby -r { \"greeting\": \"Hello stranger!\" } ops action invoke hello-demo-ruby -p name Mike -r { \"greeting\": \"Hello Mike!\" } Test source zip:\n$ make test-src-zip zip src.zip main.rb hello.rb adding: main.rb (deflated 42%) adding: hello.rb (deflated 42%) ops action update hello-demo-ruby src.zip --docker docker.io/linus/actionloop-demo-ruby-v2.6:latest ok: updated action hello-demo-ruby ops action invoke hello-demo-ruby -r { \"greeting\": \"Hello stranger!\" } ops action invoke hello-demo-ruby -p name Mike -r { \"greeting\": \"Hello Mike!\" } Test binary ZIP:\n$ make test-bin-zip docker run -i actionloop-demo-ruby-v2.6:latest -compile main \u003csrc.zip \u003ebin.zip ops action update hello-demo-ruby bin.zip --docker docker.io/actionloop/actionloop-demo-ruby-v2.6:latest ok: updated action hello-demo-ruby ops action invoke hello-demo-ruby -r { \"greeting\": \"Hello stranger!\" } ops action invoke hello-demo-ruby -p name Mike -r { \"greeting\": \"Hello Mike!\" } Congratulations! Your runtime works also in the real world.\nWriting the validation tests Before you can submit your runtime you should ensure your runtime pass the validation tests.\nUnder tests/src/test/scala/runtime/actionContainers/ActionLoopPythonBasicTests.scala there is the template for the test.\nRename to tests/src/test/scala/runtime/actionContainers/ActionLoopRubyBasicTests.scala, change internally the class name to class ActionLoopRubyBasicTests and implement the following test cases:\ntestNotReturningJson\ntestUnicode\ntestEnv\ntestInitCannotBeCalledMoreThanOnce\ntestEntryPointOtherThanMain\ntestLargeInput\nYou should convert Python code to Ruby code. We do not do go into the details of each test, as they are pretty simple and obvious. You can check the source code for the real test here.\nYou can verify tests are running properly with:\n$ ./gradlew test Starting a Gradle Daemon, 1 busy Daemon could not be reused, use --status for details \u003e Task :tests:test runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should handle initialization with no code PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should handle initialization with no content PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should run and report an error for function not returning a json object PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should fail to initialize a second time PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should invoke non-standard entry point PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should echo arguments and print message to stdout/stderr PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should handle unicode in source, input params, logs, and result PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should confirm expected environment variables PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should echo a large input PASSED BUILD SUCCESSFUL in 55s Big congratulations are in order having reached this point successfully. At this point, our runtime should be ready to run on any OpenWhisk and OpenServerless platform and also can be submitted for consideration to be included in the Apache OpenWhisk and OpenServerless project.\n","categories":"","description":"How to implement your runtime from scratch","excerpt":"How to implement your runtime from scratch","ref":"/docs/reference/references/actions-actionloop/","tags":"","title":"Building your runtime"},{"body":"OpenWhisk and OpenServerless support an open API, where any user can expose an event producer service as a feed in a package. This section describes architectural and implementation options for providing your own feed.\nThis material is intended for advanced OpenWhisk and OpenServerless users who intend to publish their own feeds. Most OpenWhisk and OpenServerless users can safely skip this section.\nFeed Architecture There are at least 3 architectural patterns for creating a feed: Hooks, Polling and Connections.\nHooks In the Hooks pattern, we set up a feed using a webhook facility exposed by another service. In this strategy, we configure a webhook on an external service to POST directly to a URL to fire a trigger. This is by far the easiest and most attractive option for implementing low-frequency feeds.\nPolling In the Polling pattern, we arrange for an OpenWhisk and OpenServerless action to poll an endpoint periodically to fetch new data. This pattern is relatively easy to build, but the frequency of events will of course be limited by the polling interval.\nConnections In the Connections pattern, we stand up a separate service somewhere that maintains a persistent connection to a feed source. The connection based implementation might interact with a service endpoint via long polling, or to set up a push notification.\nDifference between Feed and Trigger Feeds and triggers are closely related, but technically distinct concepts.\nOpenWhisk and OpenServerless process events which flow into the system.\nA trigger is technically a name for a class of events. Each event belongs to exactly one trigger; by analogy, a trigger resembles a topic in topic-based pub-sub systems. A rule T → A means “whenever an event from trigger T arrives, invoke action A with the trigger payload.\nA feed is a stream of events which all belong to some trigger T. A feed is controlled by a feed action which handles creating, deleting, pausing, and resuming the stream of events which comprise a feed. The feed action typically interacts with external services which produce the events, via a REST API that manages notifications.\nImplementing Feed Actions The feed action is a normal OpenWhisk and OpenServerless action, but it should accept the following parameters:\nlifecycleEvent: one of ‘CREATE’, ‘READ’, ‘UPDATE’, ‘DELETE’, ‘PAUSE’, or ‘UNPAUSE’. triggerName: the fully-qualified name of the trigger which contains events produced from this feed. authKey: the Basic auth credentials of the OpenWhisk and OpenServerless user who owns the trigger just mentioned. The feed action can also accept any other parameters it needs to manage the feed. For example the cloudant changes feed action expects to receive parameters including `dbname’, `username’, etc.\nWhen the user creates a trigger from the CLI with the –feed parameter, the system automatically invokes the feed action with the appropriate parameters.\nFor example, assume the user has created a mycloudant binding for the cloudant package with their username and password as bound parameters. When the user issues the following command from the CLI:\nops trigger create T --feed mycloudant/changes -p dbName myTable\nthen under the covers the system will do something equivalent to:\nops action invoke mycloudant/changes -p lifecycleEvent CREATE -p triggerName T -p authKey \u003cuserAuthKey\u003e -p password \u003cpassword value from mycloudant binding\u003e -p username \u003cusername value from mycloudant binding\u003e -p dbName mytype\nThe feed action named changes takes these parameters, and is expected to take whatever action is necessary to set up a stream of events from Cloudant, with the appropriate configuration, directed to the trigger T.\nFor the Cloudant changes feed, the action happens to talk directly to a cloudant trigger service we’ve implemented with a connection-based architecture. We’ll discuss the other architectures below.\nA similar feed action protocol occurs for ops trigger delete, ops trigger update and ops trigger get.\nImplementing Feeds with Hooks It is easy to set up a feed via a hook if the event producer supports a webhook/callback facility.\nWith this method there is no need to stand up any persistent service outside of OpenWhisk and OpenServerless. All feed management happens naturally though stateless OpenWhisk and OpenServerless feed actions, which negotiate directly with a third part webhook API.\nWhen invoked with CREATE, the feed action simply installs a webhook for some other service, asking the remote service to POST notifications to the appropriate fireTrigger URL in OpenWhisk and OpenServerless.\nThe webhook should be directed to send notifications to a URL such as:\nPOST /namespaces/{namespace}/triggers/{triggerName} The form with the POST request will be interpreted as a JSON document defining parameters on the trigger event. OpenWhisk and OpenServerless rules pass these trigger parameters to any actions to fire as a result of the event.\nImplementing Feeds with Polling It is possible to set up an OpenWhisk and OpenServerless action to poll a feed source entirely within OpenWhisk and OpenServerless, without the need to stand up any persistent connections or external service.\nFor feeds where a webhook is not available, but do not need high-volume or low latency response times, polling is an attractive option.\nTo set up a polling-based feed, the feed action takes the following steps when called for CREATE:\nThe feed action sets up a periodic trigger (T) with the desired frequency, using the whisk.system/alarms feed.\nThe feed developer creates a pollMyService action which simply polls the remote service and returns any new events.\nThe feed action sets up a rule T → pollMyService.\nThis procedure implements a polling-based trigger entirely using OpenWhisk and OpenServerless actions, without any need for a separate service.\nImplementing Feeds via Connections The previous 2 architectural choices are simple and easy to implement. However, if you want a high-performance feed, there is no substitute for persistent connections and long-polling or similar techniques.\nSince OpenWhisk and OpenServerless actions must be short-running, an action cannot maintain a persistent connection to a third party . Instead, we must stand up a separate service (outside of OpenWhisk and OpenServerless) that runs all the time. We call these provider services. A provider service can maintain connections to third party event sources that support long polling or other connection-based notifications.\nThe provider service should provide a REST API that allows the OpenWhisk and OpenServerless feed action to control the feed. The provider service acts as a proxy between the event provider and OpenWhisk and OpenServerless – when it receives events from the third party, it sends them on to OpenWhisk and OpenServerless by firing a trigger.\nThe connection-based architecture is the highest performance option, but imposes more overhead on operations compared to the polling and hook architectures.\n","categories":"","description":"Implement Feeds","excerpt":"Implement Feeds","ref":"/docs/reference/entities/feeds/","tags":"","title":"Feeds"},{"body":"Rules Once we have a trigger and some actions, we can create rules for the trigger. A rule connects the trigger with an action, so if you fire the trigger, it will invoke the action. Let’s see this in practice in the next listing.\nCreate data First of all, create a file called alert.js.\nfunction main() { console.log(\"Suspicious activity!\"); return { result: \"Suspicious activity!\" }; } Then, create a OpenServerless action for this file:\nops action create alert alert.js Now, create a trigger that we’ll call notifyAlert:\nops trigger create notifyAlert Now, all is ready, and now we can create our rule! The syntax follows this pattern: “ops rule create {ruleName} {triggerName} {actionName}”.\nops rule create alertRule notifyAlert alert Test your rule Our environment can now be alerted if something suspicious occurs! Before starting, let’s open another terminal window and enable polling (with the command ops activation poll) to see what happens.\n$ ops activation poll Enter Ctrl-c to exit. Polling for activation logs It’s time to fire the trigger!\n$ ops trigger fire notifyAlert ok: triggered /notifyAlert with id 86b8d33f64b845f8b8d33f64b8f5f887 Now, go to see the result! Check the terminal where you are polling activations now!\nEnter Ctrl-c to exit. Polling for activation logs Activation: 'alert' (dfb43932d304483db43932d304383dcf) [ \"2024-02-20T03:15.15472494535Z stdout: Suspicious activity!\" ] Conclusion 💡 NOTE\nAs with all the other commands, you can execute list, update, and delete by name.\nA trigger can enable multiple rules, so firing one trigger actually activates multiple actions. Rules can also be enabled and disabled without removing them. As in the last example, let’s try to disable the first rule and fire the trigger again to see what happens.\n$ ops rule disable alertRule ok: disabled rule alertRule $ ops trigger fire notifyAlert ok: triggered /_/notifyAlert with id 0f4fa69d910f4c738fa69d910f9c73af Disabling the rule.\nFiring the trigger again.\nIn the activation polling window, we can see that no action is executed now. Of course, we can enable the rule again with:\nops rule enable alertRule ","categories":"","description":"Connection rules between triggers and actions","excerpt":"Connection rules between triggers and actions","ref":"/docs/cli/entities/rules/","tags":"","title":"Rules"},{"body":"Summarizing what we have seen so far, in this tutorial we have seen how to:\nset up an application; create and publish the frontend create and publish the backend, in the form of packages and actions; interact with services using the ops utility; publish the application and distribute it on test and production environments. At this point, all you have to do is give space to your developer imagination and create your applications by taking advantage of the flexibility and scalability of Apache OpenServerless.\nIf you have questions or need support, reach us through:\nthe Developer Mailing List our Discord channels our Telegram ","categories":"","description":"Let's continue our journey","excerpt":"Let's continue our journey","ref":"/docs/tutorial/conclusions/","tags":"","title":"Conclusions"},{"body":"It’s 2025, and apparently, if your infrastructure isn’t running on MCP servers, are you even in tech? From stealth startups to sleepy enterprises pretending to innovate, everyone claims to be “built on MCP” — or at least wishes they were. It’s the new badge of modernity.\nIn this guide, I’ll show how to build an MCP-compliant server using Apache OpenServerless and our custom MCP plugin. By deploying OpenServerless and using the plugin, you can quickly expose tools via the Model Context Protocol (MCP). This setup enables fast and portable AI workflows across any cloud or on-prem environment.\nThe hard part about running an MCP Server Spinning up an MCP server sounds cool and it looks easy. But the real pain doesn’t start until after the “hello world” works. Because running an MCP server isn’t the challenge — it’s keeping it running and updating it.\nWant to make it available on the Internet? Prepare for a joyride through SSL, firewall configs, and reverse proxies. Thinking of scaling it? That’s when the fun begins: orchestration, autoscaling, persistence, model versioning, billing — suddenly you’re less “AI pioneer” and more “distributed systems janitor.”\nThis is where OpenServerless with MCP truly shines: enabling fast, portable, and secure AI tool deployment with zero DevOps, seamless orchestration, and full compliance with the Model Context Protocol.\nIntroducing olaris-mcp, the OpenServerless plugin to build MCP servers We developed an Apache OpenServerless plugin, or more precisely an ops plugin for building MCP servers with Apache OpenServerless functions. A quick reminder: ops is the CLI and it supports plugins as a way to extend the CLI with new commands.\nThis plugin allows you to create an MCP-compliant server in a fully serverless way—by simply writing functions and publishing them to OpenServerless.\nThe plugin can run locally for development or be deployed to any server for production use. We support both local and public (published on the Internet) MCP servers. We will cover the latter in a future article as it enables interesting scenarios like inter-servers communications to be explored.\nNote: In OpenServerless, a single MCP server consists of a number of functions, so one single MCP server is a package. It consists of a collection of tools, prompts, and resources, each represented as a distinct OpenServerless function. That means one server is always split into a number of microservices.\nInstalling the MCP Plugin for OpenServerless As we said, it’s an ops plugin and can be installed directly using:\n$ ops -plugin https://github.com/mastrogpt/olaris-mcp To verify that the plugin has been installed correctly, run:\n$ ops mcp You should see the following usage synopsis (shortened):\nUsage: mcp new \u003cpackage\u003e [\u003cdescription\u003e] (--tool=\u003ctool\u003e|--resource=\u003cresource\u003e|--prompt=\u003cprompt\u003e|--clean=\u003cclean\u003e) [--redis] [--postgres] [--milvus] [--s3] mcp run \u003cpackage\u003e [--sse] mcp test \u003cpackage\u003e [--sample] [--norun] mcp install [\u003cpackage\u003e] [--cursor] [--claude] [--5ire] [--uninstall] mcp inspect \u003cpackage\u003e [--sse] Let’s see in detail what the available commands do:\nops mcp new – Create a new MCP package tool, prompt or resource. ops mcp run – Run the specified package as an MCP server. ops mcp test – Test the generated MCP server via CLI. ops mcp inspect – Launch the MCP web inspector for the specified package. ops mcp install – Install or uninstall the MCP server locally to Cursor, Claude, or 5ire environments. Creating a new MCP Server with a serverless function Let’s walk through the steps to create a simple MCP server – for example, one that provides weather information for any location in the world.\nWe’ll start by creating a serverless function that acts as a proxy using the following command:\n$ ops mcp new demomcp --tool=weather This command initializes a new MCP package named demomcp and defines a tool called weather.\nNext, you’ll need to describe your MCP tool using metadata annotations. These annotations define the tool type, description, and input parameters:\n#-a mcp:type tool #-a mcp:desc \"Provides weather information for a given location\" #-a input:str \"The location to retrieve weather data for\" Implementing a Weather Function Now it’s time to implement the logic for your weather function.\nYou can use generative AI to get the required code quickly. For instance, the following prompt can help you generate a simple function that retrieves weather information:\nAI Prompt: A Python function get_weather(location) using requests and open-meteo.com that retrieves the given location, selects the first match, then fetches and returns the weather information for that location. We do not include the implementation here, ChatGPT typically returns a valid and usable function.\nAssuming you’ve implemented a get_weather(location) function, you can now create a wrapper to handle MCP-style invocation:\ndef weather(args): inp = args.get(\"input\", \"\") if inp: out = get_weather(inp) else: out = \"Please provide a location to get the weather information for.\" return {\"output\": out} Deploy and Test the Function You can deploy and test your MCP function as follows:\n$ ops ide deploy demomcp/weather ok: updated action demomcp/weather $ ops invoke demomcp/weather { \"output\": \"Please provide a location to get the weather information for.\" } $ ops invoke demomcp/weather input=Rome { \"output\": { \"location\": \"Rome, Italy\", \"temperature\": 26.0, \"time\": \"2025-06-22T06:45\", \"weathercode\": 2, \"winddirection\": 360, \"windspeed\": 2.9 } } $ ops invoke demomcp/weather input=NontExistingCity { \"output\": \"Could not find location: NontExistingCity\" } Testing the MCP Server Your MCP server is now up and running, and you can test it using the graphical inspector with the following command:\n$ ops mcp inspect demomcp The Inspector connects to your MCP server, lists available tools and resources, and allows you to test their behavior interactively.\nUsing the MCP Server Your MCP server is now ready to be integrated into any chat interface that supports MCP servers.\nIn this example, we use 5ire, a free AI assistant and MCP client that provides an excellent environment for running and testing MCP tools.\nStep 1: Install the ops CLI First, install the ops CLI. You can find installation instructions on the OpenServerless installation page.\nStep 2: Add the MCP Plugin Install the MCP plugin using:\n$ ops -plugin https://github.com/mastrogpt/olaris-mcp Step 3: Log in to Your OpenServerless Account Use the following command to authenticate:\n$ ops ide login Step 4: Install the MCP Server into 5ire Deploy your toolset to 5ire with:\n$ ops mcp install demomcp --5ire You’re all set! Now you can access your 5ire client and use the deployed MCP server in real conversations.\nLet’s walk through how the tool works in practice: Testing it step-by-step Ask a Chatbot\nAsk a chatbot for the weather in Rome. It will likely reply that, as a language model, it doesn’t have up-to-date weather information. Open the Tool List\nIn the 5ire interface, open the list of available MCP tools. Enable the MCP Tool\nLocate your toolset (demomcp) and enable it. Ask Again\nNow that the tool is active, ask the chatbot again: “What’s the weather in Rome?” Observe What Happens\nBehind the scenes, the LLM invokes the MCP server, which triggers the serverless function that retrieves live weather data. Success!\nYou’ve successfully extended your LLM to provide real-time weather information for any location in the world. Conclusion With Apache OpenServerless, we showed how to build and deploy a serverless MCP server in minutes, bypassing all complex system configuration.\nThis example covered only local MCP server configuration. However, the optimal solution utilizes public MCP servers, enabling inter-server communication via agent interaction protocols.\nThis is just the beginning. Public MCP servers open the door to multi-agent interactions, federation, and more.\nStay tuned for more updates from Apache OpenServerless!\nAuthors Michele Sciabarrà CEO Nuvolaris, Serverless Freedom for Private AI - O'Reilly Author, Committer OpenWhisk and OpenServerless - ex Nimbella and Digital Ocean Developer Advocate michele@nuvolaris.io | LinkedIn Bruno Salzano Enthusiastic and experienced ICT Manager with a passion for innovation and problem-solving. With over 5 years of experience in managing complex microservices ecosystems, he has a strong background in Typescript/Node and Golang, along with solid expertise in infrastructure management. Eager to contribute to a Company with a forward-thinking approach and a commitment to driving technological advancement. bruno@brunosalzano.com | LinkedIn ","categories":"","description":"How to build an MCP-compliant server using Apache OpenServerless and a custom MCP plugin.\n","excerpt":"How to build an MCP-compliant server using Apache OpenServerless and a …","ref":"/blog/2025/07/08/building-mcp-servers-the-easy-way-with-apache-openserverless/","tags":"","title":"Building MCP Servers the Easy Way with Apache OpenServerless"},{"body":"If you have never heard of it, you may wonder: what is Apache OpenServerless? The short answer is: a portable, self-contained and complete cloud-native serverless platform, built on top of Kubernetes and especially suitable to develop production-ready AI applications with minimal effort. Because of its portability and availability in every environment, including air-gapped ones, it shines when you have strong privacy and security constraints and need to build Private AI applications.\nOpenServerless embraces the functional programming paradigm, enabling developers to build modular, stateless functions ideal for scalable AI workloads: this model aligns naturally with serverless architecture and simplifies the integration of both public and private LLMs - developers can invoke proprietary APIs like OpenAI or deploy and run private models locally, ensuring full control over sensitive data. A key strength is its ability to run GPU-accelerated runtimes, allowing execution of code directly on GPUs for high-performance inference or training tasks.\nThe origins of Apache OpenServerless The project Apache OpenServerless is closely related to another serverless project: Apache OpenWhisk. OpenWhisk is a portable serverless engine originally developed and open sourced by IBM, and later adopted and further developed by vendors of the calibre of Adobe, Naver, and Digital Ocean.\nOpenWhisk is an excellent foundation to provide FaaS services and indeed it is adopted by many cloud providers as their serverless engine. It is also widely used in academia for research on serverless. It is highly scalable and extremely robust and reliable. However, OpenWhisk is not yet widely used because in itself is not a full platform: it is only a FaaS service and, while it is used by cloud providers, their users have little interest in making it available for wider use.\nA team of contributors to OpenWhisk, working initially with the startup Nimbella (acquired by Digital Ocean), and later Nuvolaris, developed it further to make it widely accessible and more useful out-of-the-box, adding all the required components with the goal of making it a complete serverless environment. Indeed in general serverless is useful when it is coupled with storage, cache, database and frontend. Given the popularity of LLM based application development it has been also extended to fully support the development of AI applications.\nThe project was then donated to the Apache Software Foundation and released as Apache OpenServerless. Note in this text we sometimes omit Apache in the name, but always keep in mind that the full names of the projects are respectively Apache OpenWhisk and Apache OpenServerless, as they are both projects copyrighted by the Apache Software Foundation.\nWhat is in Apache OpenServerless? To clarify the difference between OpenWhisk and OpenServerless you can think in this way: if OpenWhisk were Linux, then OpenServerless would be Ubuntu. In short, it is a distribution of OpenWhisk providing a Kubernetes operator to install and manage it, a rich CLI with integrated installation and development tools and a collection of starters to build AI applications.\nYou can see what is in openserverless in the picture below:\nAs you can note at the core there is OpenWhisk, providing the scalable FaaS service, composed of a set of controllers accepting requests and queuing them in Kafka, and a set of invokers serving the requests on demand, instantiating runtimes. OpenServerless also adds a Kubernetes Operator that manages all the systems. The main purpose of the operator is to deploy OpenWhisk, but also the integrated services. At the moment there is Redis (in the open ValKey flavour), Postgresql (SQL database) and the MongoDB compatible adapter FerretDB (NoSQL), the Vector Database Milvus and an S3 object storage services. We currently support both Minio and Ceph as backends.\nAlso we have a special service, called streamer, designed to support SSE (server side events) commonly used with AI applications to stream answers from LLM.\nThe operator is actually pretty powerful as it is configurable, and allows for the creation and management of resources as it is able to create databases, buckets and redis prefixes in the environment it manages, and manage the secrets to access them.\nOpenWhisk has a large set of runtimes but instead of supporting all of them, we focused and optimized the more used languages, typically Python, Javascript and PHP, and provided a rich set of libraries in order to use the integrated services.\nThe operator is controlled by a rich CLI, called ops. The name is a pun, a short of OPenServerless, but also Operation… and also what you say (“OoooPS!”) when you make a mistake. The CLI completes the picture as it is extremely powerful and even expandable with plugins. It manages the serverless resources as in OpenWhisk, but also includes the ability to install OpenServerless in multiple cloud providers and integrates powerful development tools. We will discuss it more in detail later.\nInstallation and configuration Let’s start from the installation: you install OpenWhisk with a helm chart on a set of well known Kubernetes clusters, like Amazon EKS, IBM IKS or OpenShift v4. You need a Kubernetes cluster, that should also be configured properly. Also the installer only installs the engine and no other services.\nOpenServerless CLI is more complete. It installs OpenWhisk by deploying the operator in a Kubernetes cluster and sending a configuration. But it is also able to create a suitable cluster.\nIndeed the documentation explains how to prepare a Kubernetes cluster on Amazon AWS, Microsoft Azure and Google GCP using the cli called ops: there is an interactive configuration, then ops builds a suitable cluster with all the parameters in place to install OpenServerless in it.\nWhen installing OpenServerless, you can also select which services you want to enable, and many configuration parameters that are essential. All of this just using the ops CLI to set the configuration parameters before performing the installation.\nAfter the installation, the CLI is useful to administer the cluster, adding new users, etc. Note that each user has a complete set of services included, so you do not only create an area (called namespace) for serverless functions but also a SQL database (and a No-SQL adapter), a Vector Database, a bucket for web content (public) and another for private data, a Redis prefix (to isolate your keys in Redis).\nNote that the system supports a public area for web content using a dns configuration. You need a DNS domain for an OpenServerless installation, and you usually need to point the root of the domain (@) and a wildcard (*) to a load balancer accessing it. Each user will have a different web area to upload their web content, and a mapping to their serverless functions (’/api/my’) suitable for deploying SPA applications with serverless backend support.\nDevelopment tools So far so good, but work would not be complete without suitable development tools. You can deploy each function easily but it is a bit painful to have to deploy each function separately. Furthermore, you have to provide each function with options to change the runtime type, the memory constraints, timeouts etc. OpenWhisk supports a manifest format to do that, but does not offer other facilities for deployment.\nIt is still possible to use the manifest, but we also added a configuration system based on conventions: just put your code in directories and the system will automatically build and deploy.\nAlso, in this case, the super powers of cli ops come to our rescue! The ops development tools allow us to incrementally publish all the functions we have written, to manage their dependencies, annotations during publication; as well as publish the web part of our application. Furthermore it is possible to integrate the build scripts of our Angular, React, or Svelte application so as to be invoked during the publication process. Other useful tools allow us to handle and interact with the integrated services (Postgresql, Minio, Redis).\nConclusions and a new beginning All of this looks interesting, but it is actually just the starting point for building AI applications, as this is our main focus. OpenServerless lays the groundwork by providing a flexible, event-driven foundation, but its real power emerges when applied to AI-centric workflows.\nOur primary goal is to enable developers and data scientists to move beyond basic automation and toward complex AI systems that integrate reasoning, natural language understanding, and data processing. OpenServerless becomes a powerful platform for rapid experimentation, secure deployment, and scalable AI services. From RAG pipelines to autonomous agents, this environment is designed to evolve with the needs of modern AI, turning abstract ideas into production-ready solutions without the usual overhead of managing infrastructure or sacrificing control.\nAuthors Michele Sciabarrà CEO Nuvolaris, Serverless Freedom for Private AI - O'Reilly Author, Committer OpenWhisk and OpenServerless - ex Nimbella and Digital Ocean Developer Advocate michele@nuvolaris.io | LinkedIn Bruno Salzano Enthusiastic and experienced ICT Manager with a passion for innovation and problem-solving. With over 5 years of experience in managing complex microservices ecosystems, he has a strong background in Typescript/Node and Golang, along with solid expertise in infrastructure management. Eager to contribute to a Company with a forward-thinking approach and a commitment to driving technological advancement. bruno@brunosalzano.com | LinkedIn ","categories":"","description":"Meet this portable, self-contained and complete cloud-native serverless platform built on Kubernetes.\n","excerpt":"Meet this portable, self-contained and complete cloud-native …","ref":"/blog/2025/05/15/apache-openserverless-is-the-easiest-way-to-build-your-cloud-native-ai-application/","tags":"","title":"Apache OpenServerless is the easiest way to build your cloud native AI application"},{"body":"Introduction Apache OpenServerless is an innovative project from the Apache Incubator, designed to deliver a versatile and scalable serverless environment compatible with any cloud provider or Kubernetes distribution. Built upon the robust Apache OpenWhisk framework, it aims to empower developers to create applications of any complexity, from simple forms to advanced AI-driven solutions.\nCurrently in its preview phase, Apache OpenServerless invites the community to provide feedback and contributions, accelerating its journey towards a stable release.\nKey Features of Apache OpenServerless Apache OpenServerless integrates three core components that collectively form a complete serverless ecosystem:\nServerless Engine Powered by Apache OpenWhisk At the heart of Apache OpenServerless lies Apache OpenWhisk, a distributed and scalable open-source platform for executing serverless functions. OpenWhisk enables dynamic execution of lightweight code snippets, or “Actions,” written in multiple programming languages. These Actions respond to events (via triggers) or HTTP requests, seamlessly adapting to various workloads.\nApplication Services To support various application needs, Apache OpenServerless provides a set of pre-configured services, including:\nan S3 compatible storage, a Redis compatible caching, MongoDB and PostgreSQL for both noSQL and SQL. Developer-Friendly Tools To streamline development, Apache OpenServerless offers:\nReady-to-use application templates - kickstarting projects for various use cases. Integrated Development Environments (IDEs) - the system offers a user-friendly CLI for seamless interaction with the serverless platform. Furthermore a VScode extension is available. Simplified deployment workflows - to build, test, and launch cloud-ready applications with ease. Installs everywhere and control data OpenServerless is trying to set new standards in the Function as a Service (FaaS) landscape. Built on Kubernetes and Apache OpenWhisk, OpenServerless offers an infrastructure-agnostic approach that can be installed on-premises or in public clouds. This flexibility ensures that data remains under the control of the organization, addressing key privacy concerns for industries with strict data governance requirements. By providing companies with the option to run their applications on their terms, OpenServerless aligns with the demand for transparent and secure data handling in a serverless environment.\nConclusion OpenServerless also benefits from the robust, scalable nature of Kubernetes, making it ideal for handling asynchronous, event-driven workloads that are core to modern serverless applications. With OpenWhisk’s powerful action-based execution model, it provides a straightforward framework for developers to deploy and manage functions seamlessly. The addition of observability tools allows developers to monitor performance, making it easy to optimize and troubleshoot.\nIn essence, OpenServerless is more than just a FaaS—it’s a privacy-focused, Kubernetes-native solution that empowers companies to innovate securely and effectively. With its unique approach to data control and its ability to support intensive workloads, OpenServerless is reshaping the serverless ecosystem and opening up exciting new applications for AI-powered, cloud-native solutions.\n","categories":"","description":"OpenServerless: Full-fledged open source FaaS, powered by Kubernetes and OpenWhisk  \n","excerpt":"OpenServerless: Full-fledged open source FaaS, powered by Kubernetes …","ref":"/blog/2024/11/16/apache-openserverless-a-faas-solution-with-privacy-and-power/","tags":"","title":"Apache OpenServerless: A FaaS Solution with Privacy and Power"},{"body":" OpenServerless is a complex project. It has a lot of moving parts and relies heavily on Kubernetes.\nThere are many subprojects, and each subproject has a complex set of dependencies. Setting up all those dependencies is usually complex and time consuming.\nI have worked in a project where it used to take literally a couple of days to get everything ready to code. Also, you were never sure that everything was set up correctly because the dependencies were constantly changing.\nFor this reason, we have made a special effort to provide an easy and consistent way to have a standardized development environment for OpenServerless.\nThe Development Virtual Machine We considered a few options for setting up the development environment.\nThe first option is of course a setup script, but since you may be working on Linux, Windows or Mac, this approach turns out to be difficult and fragile.\nThe second option is to use Docker, and indeed for a while we used a Docker image in DevContainer format as our development environment. We also set up a Kubernetes development cluster using Kind, that is, “Kubernetes-in-Docker”.\nHowever, this approach proved to be slow and with a number of problems related to Docker. So we gradually moved to using a full virtual machine. And this is the approach we are taking with OpenServerless.\nThe development environment is a virtual machine initialized with a cloud-init script. Cloud-init is a standard for initializing a virtual machine in the cloud.\nUsing this cloud-init script you can actually run a developmnt environment basically in any cloud provider, if you want a shared one.\nOr, if you want to use your local machine, assuming you have at least 16GB of memory, you can launch the VM and initialize it with Cloud-Init in Linux, Windows and Mac using multipass.\nTHe README of Apache OpenServerless is indeed entirely devoted to setup the development virtual machine with Multipass and Cloud-Init.\nWhat is in the development machine? Using this cloud-init script, you can actually run a development environment in basically any cloud provider if you want a shared one.\nOr if you want to use your local machine, assuming you have at least 16GB of memory, you can start the VM and initialize it with cloud-init in Linux, Windows and Mac using multipass.\nThe README for [Apache OpenServerless] (https://github.com/apache/openserverless) is actually entirely devoted to setting up the development virtual machine with Multipass and Cloud-Init.\nWhat is in the development machine? The development machine is actually packed with goodies. For a start, it includes Kubernetes in the form of K3S, a lightweight but full-featured version of Kubernetes. Well, technically, K3S is an API-compatible, work-alike sister re-implementation of Kubernetes, but for all practical purposes, it IS Kubernetes.\nBut we need more than Kubernetes. We have a number of subprojects, and for each one, there’s a different set of tools and programming languages that need to be set up. We used to have a script to setup these dependencies, but since it turned out to be tedious to update, we switched to using [the package manager Nix] (https://nixos.org/download/). This is a tool that allows you to set up development environments (actually any environment) declaratively by writing a script shell.nix, the Nix language that defines the development environment. The virtual machines also include nix, and also a tool called direnv to automatically configure nix, calling a different shell.nix every time you change a directory.\nLast but not least, we use VSCode as it provides remote development features and allows you to work in the virtual machine as if it were a local folder. Instructions for setting up VSCode to use the virtual machine are provided in the README.\nIt is also worth mentioning that since we use task a build tool everywhere, we included it in the VM. There is also a license manager license-eye to ensure that all files are properly licensed under the Apache license.\n","categories":"","description":"Our first code drop is available: the development environment!\n","excerpt":"Our first code drop is available: the development environment!\n","ref":"/blog/2024/07/12/assembling-the-lab-for-openserverless/","tags":"","title":"Assembling the lab for OpenServerless"},{"body":"The Apache OpenServerless project’s goal is to build a serverless distribution that runs in all major flavors of Kubernetes in public and private clouds, and in any virtual machine running Linux in any cloud. It is not just a serverless engine, but a complete set of integrated tools to easily build cloud-native applications, with a focus on building AI applications.\nSpecifically, we are building on top of Apache OpenWhisk, which includes Apache Kafka and Apache CouchDB as components, adding Apache APISix as an API gateway, and a set of custom runtimes.\nWe have a Kubernetes operator to manage all the components, and a rich CLI to support installation and development.\nWe have a strong focus on development tools: the system includes support for developing full-stack applications in web-based IDEs using the DevContainer standard, with built-in full-stack hot reload (both backend and front-end).\nWe will have a set of starters that support the development of AI applications based on LLM. Furthermore, since many AI applications are basically a coreography of functions, something well supported in the serverless world, we will have a workflow generator to easily develop applications.\nThe project is already running at the Apache Software Foundation and we are in the process of migrating the contributed code base.\nOur home is https://github.com/apache/openserverless\nJoin us by subscribing to our mailing list sending an email to\ndev-subscribe@openserverless.apache.org ","categories":"","description":"The project Apache OpenServerless is now active\n","excerpt":"The project Apache OpenServerless is now active\n","ref":"/blog/2024/07/09/apache-openserverless-started/","tags":"","title":"Apache OpenServerless started"},{"body":"We are in the process of submitting thr open source codebase of Nuvolaris Community, to the Apache Software Foundation as an Apache project, and our proposed name is Apache OpenServerless.\nThe name is excellent because it conveys what the project is: a complete serverless environment for running cloud-native applications anywhere.We have already written the proposal and found our champions and mentors.\nBut before we voted the project in the Incubator PMC, we wanted to make sure that the chosen name was available.There was some concern because the name “serverless” is already trademarked, although we found that combinations using the name “serverless” are disjointly trademarked, so it should work.\nTo resolve this, we initiated research with the Apache Trademark team to be sure the nome was usable. The research took some time, but the result was: approved!So now we are ready to vote and get the process approved by the community and start building the next standard in the open source world: Apache OpenServerless!\n","categories":"","description":"The name Apache OpenServerless has been approved by the Apache Software Foundation! \n","excerpt":"The name Apache OpenServerless has been approved by the Apache …","ref":"/blog/2024/06/20/the-name-openserverless-was-approved/","tags":"","title":"The Name OpenServerless Was Approved"},{"body":"It is official! Apache OpenServerless is now an incubating project at the Apache Software Foundation! The result of the vote was positive and this is the email announcing the result of the vote on the Incubator Mailing List.\nFrom: Jean-Baptiste Onofré Date: Tuesday 18 June 2024 16:20:06 BST Subject: [RESULT][VOTE] Accept OpenServerless into the ASF incubator Hi folks, this vote passed with the following result: +1 (binding): Francis Chuang, PJ Fanning, Yu Xiao, Duo Zhang, Bertrand Delacretaz, Zhongyi Tan, Zhang Yonglun, Charles Zhang, Enrico Olivelli, Dave Fisher, François Papon, Roman Shaposhnik, Yu Li, Calvin Kirs +1 (non binding): ZhangJian He, Nicolò Boschi, likeho Thanks all for your vote ! Regards JB ","categories":"","description":"OpenServerless is now incubating at the Apache Software Foundation!\n","excerpt":"OpenServerless is now incubating at the Apache Software Foundation!\n","ref":"/blog/2024/06/18/project-accepted-for-incubation/","tags":"","title":"Project Accepted for Incubation!"},{"body":"Hello everyone, we are happy to announce that we submitted the OpenServerless project to the Apache Software Foundation. We are going to develop our Nuvolaris Community into a worldwide open source project at the highest level.\nThe goal is to provide the open source foundation of our Nuvolaris Enterprise product as a vendor independent and stable project maintained by a community.\nTo achieve this goal, we have submitted the Apache OpenServerless proposal is the natual step. The link to the proposal can be found here.\nOur codebase is well tested and already has a number of paying and open source customers. We already have a network of contributors who have already contributed to the codebase and we have found the mentors for our project and the champion for the project.\nBut what is the Nuvolaris community (to become Apache OpenServerless)? There is already an open source serverless engine (Apache OpenWhisk) and I am one of the PMC of the project and also wrote an O’Reilly book about it: Learning Apache OpenWhisk.\nWhat is missing now is a complete distribution including integrated services to build a complete platform. We want the Apache OpenServerless project to fill this gap.\nWith Nuvolaris Community we provide storage, databases, caches, frontend, IDE, starters and even LLM support on top of OpenWhisk. We have made this available and running on all major cloud provider Kubernetes platforms (EKS, AKS, GKE, LKE) and also for the Kubernetes of all major Linux distributions (RedHat OpenShift, Ubuntu MicroK8S, SuSE K3S).\nSimply put, if OpenWhisk is Linux, then Nuvolaris is RedHat. The OpenServerless project aims to be the first complete open source distribution that makes it easy to build cloud-native applications with portability in mind.\nAnd we want to build the platform in the open, contributing our work to the Apache Software Foundation to make it widely available and get more vendors involved in supporting it.\n","categories":"","description":"We are submitting the OpenServerless project to the Apache Software Foundation\n","excerpt":"We are submitting the OpenServerless project to the Apache Software …","ref":"/blog/2024/06/10/openserverless-proposal-submitted/","tags":"","title":"OpenServerless Proposal Submitted"},{"body":" Apache OpenServerless A complete Serverless Development Environment for Any Cloud and Any Kubernetes\nManaged by a Kubernetes Operator Here are some of the operator’s strong points:\nThe first operator capable of configuring a complete OpenWhisk distribution on various versions of Kubernetes, both on cloud providers and on bare metal.\nThe operator takes care of resources setup and maintenance.\nAllows you to configure a set of resources to be used for the development / deployment of cloud native applications based on the OpenWhisk serverless engine: redis, postgresql, minio and much more!\nA super-powered CLI extensible with plugins The ops cli is more than a standard cli: infact it is…\nRICH - yes, it includes installation, system administration, debugging, developing tools and much much more!\nEXTENSIBLE - easily extendable by writing simple plugins in shell or javascript.\nWHISK-READY - it includes all openwhisk tools.\nBuilt around Apache OpenWhisk, a production-ready and widely deployed serverless engine providing all the patterns and best practices for scalable cloud-native applications.\nAvailable everywhere You can install OpenServerless everywhere: from your local Windows / Mac / Linux machine for development and testing, to powerful multi node Kubernetes cluster on premise or on your favorite Cloud Provider (AKS, AWS , GKS are fully supported)\n","categories":"","description":"","excerpt":" Apache OpenServerless A complete Serverless Development Environment …","ref":"/about/","tags":"","title":"About Apache OpenServerless"},{"body":"Synopsis In OpenServerless, users are namespaces. You can create namespaces and choose which services to enable.\nUsage: admin adduser \u003cusername\u003e \u003cemail\u003e \u003cpassword\u003e [--all] [--redis] [--mongodb] [--minio] [--postgres] [--milvus] [--storagequota=\u003cquota\u003e|auto] admin deleteuser \u003cusername\u003e admin listuser [\u003cusername\u003e] admin compact [--ttl=\u003cttl\u003e|10] admin usage [--debug] Commands admin adduser create a new user in OpenServerless with the username, email and password provided admin deleteuser delete a user from the OpenServerless installation via the username provided admin listuser list all the secrets of an user (default list all the users) admin compact create a one shot job which executes couchdb compact against all available dbs admin usage calculates and displays PVC disk usage statistics for bound volumes. Shows Total, Size and Available storage per PVC Options --all enable all services --redis enable redis --mongodb enable mongodb --minio enable minio --postgres enable postgres --milvus enable milvus vector db --storagequota=\u003cquota\u003e --ttl=\u003cseconds\u003e modify the job ttl after finished (defaults to 10 seconds) --debug enable debug logging ","categories":"","description":"Administer OpenServerless users.","excerpt":"Administer OpenServerless users.","ref":"/docs/reference/tasks/admin/","tags":"","title":"Admin"},{"body":"In this section, you can find advanced reference documentations here.\nPlease follow the links below.\n","categories":"","description":"Advanced documentation","excerpt":"Advanced documentation","ref":"/docs/reference/references/","tags":"","title":"Advanced Reference Guide"},{"body":"Synopsis Usage: aks config aks create aks delete aks kubeconfig aks lb aks status Commands config configure an Azure AKS kubernetes cluster create create an Azure AKS kubernetes cluster delete delete the current Azure AKS cluster kubeconfig extract the kubeconfig to access lb show the load balancer prereq check prerequisites status show the cluster status ","categories":"","description":"Create and Manage an Azure AKS cluster","excerpt":"Create and Manage an Azure AKS cluster","ref":"/docs/reference/tasks/cloud/aks/","tags":"","title":"Aks"},{"body":"Prerequisites to install OpenServerless in an Amazon EKS Cluster Amazon EKS is a pre-built Kubernetes cluster offered by the cloud provider Amazon Web Services.\nYou can create an EKS Cluster in Amazon AWS for installing using OpenServerless using ops as follows:\ninstall aws, the AWS CLI\nget Access and Secret Key\nconfigure EKS\nprovision EKS\noptionally, retrieve the load balancer address to configure a DNS name\nOnce you have EKS up and running you can proceed configuring and installing OpenServerless.\nInstalling the AWS CLI Our cli ops uses under the hood the AWS CLI version 2, so you need to dowload and install it following those instructions.\nOnce installed, ensure it is available on the terminal executing the following command:\naws --version you should receive something like this:\naws-cli/2.9.4 Python/3.9.11 Linux/5.19.0-1025-aws exe/x86_64.ubuntu.22 prompt/off Ensure the version is at least 2.\nGetting the Access and Secret key Next step is to retrieve credentials, in the form of an access key and a secret key.\nSo you need to: * access the AWS console following those instructions create an access key and secret key, * give to the credentials the minimum required permissions as described here to build an EKS cluster.\nYou will end up with a couple of string as follows:\nSample AWS Access Key ID: AKIAIOSFODNN7EXAMPLE Sample AWS Secret Access Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY Take note of them as you need them for configuring out CLI.\nConfiguring Amazon EKS Once you have the access and secret key you can configure EKS with the command ops config eks answering to all the questions, as in the following example:\n$ ops config eks *** Please, specify AWS Access Id and press enter. AKIAIOSFODNN7EXAMPLE *** Please, specify AWS Secret Key and press enter. wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY *** Please, specify AWS Region to use and press enter. To get a list of valid values use: aws ec2 describe-regions --output table Just press enter for default [us-east-2]: *** Please, specify AWS public SSH key and press enter. If you already have a public SSH key in AWS, provide its name here. If you do not have it, generate a key pair with the following command: ssh-keygen The public key defaults to ~/.ssh/id_rsa.pub and you can import with: aws ec2 import-key-pair --key-name nuvolaris-key --public-key-material --region=\u003cyour-region\u003e fileb://~/.ssh/id_rsa.pub Just press enter for default [nuvolaris-key]: *** Please, specify EKS Name for Cluster and Node Group and press enter. Just press enter for default [nuvolaris]: *** Please, specify EKS region and press enter. To get a list of valid values use: aws ec2 describe-regions --output table Just press enter for default [us-east-1]: *** Please, specify EKS number of worker nodes and press enter. Just press enter for default [3]: *** Please, specify EKS virtual machine type and press enter. To get a list of valid values, use: aws ec2 describe-instance-types --query 'InstanceTypes[].InstanceType' --output table Just press enter for default [m5.xlarge]: *** Please, specify EKS disk size in gigabyte and press enter. Just press enter for default [50]: *** Please, specify EKS Kubernetes Version and press enter. Just press enter for default [1.25]: Provisioning Amazon EKS Once you have configured it, you can create the EKS cluster with the command:\nops cloud eks create It will take around 20 minutes to be ready. Please be patient.\nAt the end of the process, you will have access directly to the created Kubernetes cluster for installation.\nRetrieving the Load Balancer DNS name Once the cluster is up and running, you need to retrieve the DNS name of the load balancer.\nYou can read this with the command:\nops cloud eks lb Take note of the result as it is required for configuring a dns name for your cluster.\nAdditional Commands You can delete the created cluster with: ops cloud eks delete\nYou can extract again the cluster configuration, if you lose it, reconfiguring the cluster and then using the command ops cloud eks kubeconfig.\n","categories":"","description":"Prerequisites for Amazon EKS","excerpt":"Prerequisites for Amazon EKS","ref":"/docs/installation/prereq/kubernetes/eks/","tags":"","title":"Amazon EKS"},{"body":" Welcome to Apache OpenServerless™ (incubating)! Learn More Download Upgrading Kubernetes to a Serverless powerhouse to build your cloud-native A.I. application! Apache OpenServerless™ is a distribution, running in any Kubernetes Clusters or even plain Linux Virtual Machine, straightforward to install and easy to use, deploying a Serverless Enviroment ready to use to build A.I. applications. Apache OpenServerless™ lets you stop worrying of building, deploying, configuring and orchestrating containers. You can focus on writing your A.I. code and run it anywere, production ready, without any vendor-lockin. Join our subreddit! A friendly place to discuss Apache OpenServerless™\nRead more\nContributions welcome! We accept Pull Request on GitHub. New contributors are always welcome!\nRead more\nFollow us on X.com! For announcement of latest features etc.\nRead more\nGet involved! Subscribe our mailing list\ndev-subscribe@openserverless.apache.org\nApache OpenServerless™ Architecture Overview\nPublic Cloud We support the major public cloud Kubernetes,\nincluding Amazon EKS, Azure AKS and Gcloud GKE\nPrivate Cloud We support the major private cloud Kubernetes,\nincluding RedHat OpenShift, Ubuntu MicroK8S and SuSE K3S\n","categories":"","description":"","excerpt":" Welcome to Apache OpenServerless™ (incubating)! Learn More Download …","ref":"/","tags":"","title":"Apache OpenServerless™"},{"body":"Synopsis Usage: aws vm-list aws vm-create \u003cname\u003e aws vm-delete \u003cname\u003e aws vm-getip \u003cname\u003e aws zone-create \u003czone\u003e aws zone-delete \u003czone\u003e aws zone-list [\u003czone\u003e] aws zone-update \u003czone\u003e (--host=\u003chost\u003e|--wildcard) (--vm=\u003cvm\u003e|--ip=\u003cip\u003e|--cname=\u003ccname\u003e) Commands Commands: vm-list lists the vm and their ips vm-create create a vm vm-getip get ip vm-delete delete the vm zone-create create a zone - you will have to delegate the zone from the parent zone assigning the nameservers zone-delete delete a zone zone-list list zones zone-update update a zone with an ip, a cname or the ip of a vm ","categories":"","description":"Create and Manage an Amazon Virtual Machines and Dns Zones","excerpt":"Create and Manage an Amazon Virtual Machines and Dns Zones","ref":"/docs/reference/tasks/cloud/aws/","tags":"","title":"Aws"},{"body":"Synopsis Usage: azcloud vm-list azcloud vm-ip \u003cname\u003e azcloud vm-create \u003cname\u003e azcloud vm-delete \u003cname\u003e azcloud vm-getip \u003cname\u003e azcloud zone-create \u003czone\u003e azcloud zone-delete \u003czone\u003e azcloud zone-list [\u003czone\u003e] azcloud zone-update \u003czone\u003e (--host=\u003chost\u003e|--wildcard) (--vm=\u003cvm\u003e|--ip=\u003cip\u003e|--cname=\u003ccname\u003e) Commands vm-ip create public ip vm-list lists the vm and their ips vm-create create a vm vm-getip get ip vm-delete delete the vm zone-create create a zone - you will have to delegate the zone from the parent zone assigning the nameservers zone-delete delete a zone zone-list list zones zone-update update a zone with an ip, a cname or the ip of a vm ","categories":"","description":"Manage Azure Virtual Machines and DNS Zones","excerpt":"Manage Azure Virtual Machines and DNS Zones","ref":"/docs/reference/tasks/cloud/azcloud/","tags":"","title":"Azcloud"},{"body":"Prerequisites to install OpenServerless in an Azure AKS Cluster Azure AKS is a pre-built Kubernetes cluster offered by the cloud provider Microsoft Azure.\nYou can create an AKS Cluster in Microsoft Azure for installing using OpenServerless using ops as follows:\ninstall az, the Azure CLI\nconfigure AKS\nprovision AKS\noptionally, retrieve the load balancer address to configure a DNS name\nOnce you have AKS up and running you can proceed configuring and installing OpenServerless.\nInstalling the Azure CLI Our CLI ops uses under the hood the Azure CLI, so you need to dowload and install it following those instructions.\nOnce installed, ensure it is available on the terminal executing the following command:\naz version you should receive something like this:\n{ \"azure-cli\": \"2.51.0\", \"azure-cli-core\": \"2.51.0\", \"azure-cli-telemetry\": \"1.1.0\", \"extensions\": {} } Configuring Azure AKS Before provisioning your AKS cluster you need to configure AKS with the command ops config aks answering to all the questions, as in the following example:\n$ ops config aks *** Please, specify AKS Name for Cluster and Resource Group and press enter. Just press enter for default [nuvolaris]: *** Please, specify AKS number of worker nodes and press enter. Just press enter for default [3]: *** Please, specify AKS location and press enter. To get a list of valid values use: az account list-locations -o table Just press enter for default [eastus]: *** Please, specify AKS virtual machine type and press enter. To get a list of valid values use: az vm list-sizes --location \u003clocation\u003e -o table where \u003clocation\u003e is your current location. Just press enter for default [Standard_B4ms]: *** Please, specify AKS disk size in gigabyte and press enter. Just press enter for default [50]: *** Please, specify AKS public SSH key in AWS and press enter. If you already have a public SSH key provide its path here. If you do not have it, generate a key pair with the following command: ssh-keygen The public key defaults to ~/.ssh/id_rsa.pub. Just press enter for default [~/.ssh/id_rsa.pub]: Provisioning Azure AKS Once you have configured it, you can create the AKS cluster with the command:\nops cloud aks create It will take around 10 minutes to be ready. Please be patient.\nAt the end of the process, you will have access directly to the created Kubernetes cluster for installation.\nRetrieving the Load Balancer DNS name Once the cluster is up and running, you need to retrieve the DNS name of the load balancer.\nYou can read this with the command:\nops cloud aks lb Take note of the result as it is required for configuring a dns name for your cluster.\nAdditional Commands You can delete the created cluster with: ops cloud aks delete\nYou can extract again the cluster configuration, if you lose it, reconfiguring the cluster and then using the command nuv cloud aks kubeconfig.\n","categories":"","description":"Prerequisites for Azure AKS","excerpt":"Prerequisites for Azure AKS","ref":"/docs/installation/prereq/kubernetes/aks/","tags":"","title":"Azure AKS"},{"body":"base64 utility acts as a base64 decoder when passed the --decode (or -d) flag and as a base64 encoder otherwise. As a decoder it only accepts raw base64 input and as an encoder it does not produce the framing lines.\nUsage: ops -base64 [options] \u003cstring\u003e Options -h, --help Display this help message -e, --encode \u003cstring\u003e Encode a string to base64 -d, --decode \u003cstring\u003e Decode a base64 string Examples Encoding ops -base64 -e \"OpenServerless is wonderful\" This will output:\nT3BlblNlcnZlcmxlc3MgaXMgd29uZGVyZnVs Decoding ops -base64 -d \"T3BlblNlcnZlcmxlc3MgaXMgd29uZGVyZnVs\" This will output:\nOpenServerless is wonderful ","categories":"","description":"","excerpt":"base64 utility acts as a base64 decoder when passed the --decode (or …","ref":"/docs/reference/tools/base64/","tags":"","title":"base64"},{"body":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the blog section. It has two categories: News and Releases. …","ref":"/blog/","tags":"","title":"Blog"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"OpenServerless Cloud Administration Tasks Administer deploy of various kubernetes cluster on different cloud providers or virtual machines or bare metal.\naks Azure AKS subcommands aws Amazon Web Services subcommands azcloud Azure Cloud subcommands eks Amazon Web Services - EKS subcommands gcloud Google Cloud subcommands gke Google Cloud - GKE subcommands k3s Rancher K3S subcommands mk8s Ubuntu MicroK8s subcommands osh RedHat OpenShift subcommands ","categories":"","description":"Administer cloud and baremetal infrastructure","excerpt":"Administer cloud and baremetal infrastructure","ref":"/docs/reference/tasks/cloud/","tags":"","title":"Cloud"},{"body":" ","categories":"","description":"","excerpt":" ","ref":"/community/","tags":"","title":"Community"},{"body":"Synopsis Usage: config (enable|disable) [--all] [--redis] [--mongodb] [--minio] [--cron] [--static] [--postgres] [--prometheus] [--slack] [--mail] [--affinity] [--tolerations] [--quota] [--milvus] config apihost (\u003capihost\u003e|auto) [--tls=\u003cemail\u003e] [--protocol=\u003chttp/https\u003e|auto] config runtimes [\u003cruntimesjson\u003e] config slack [--apiurl=\u003cslackapiurl\u003e] [--channel=\u003cslackchannel\u003e] config mail [--mailuser=\u003cmailuser\u003e] [--mailpwd=\u003cmailpwd\u003e] [--mailfrom=\u003cmailfrom\u003e] [--mailto=\u003cmailto\u003e] config volumes [--couchdb=\u003ccouchdb\u003e] [--kafka=\u003ckafka\u003e] [--pgvol=\u003cpostgres\u003e] [--storage=\u003cstorage\u003e] [--alerting=\u003calerting\u003e] [--zookeeper=\u003czookeeper\u003e] [--redisvol=\u003credis\u003e] [--mongodbvol=\u003cmongodb\u003e] [--etcdvol=\u003cetcd\u003e] [--mvvol=\u003cmilvus\u003e] [--mvzookvol=\u003cmilvuszook\u003e] [--pulsarjournalvol=\u003cpulsarjournal\u003e] [--pulsarledgelvol=\u003cpulsarledge\u003e] config controller [--javaopts=\u003cjavaopts\u003e] [--loglevel=\u003cloglevel\u003e] [--replicas=\u003creplicas\u003e] config invoker [--javaopts=\u003cjavaopts\u003e] [--poolmemory=\u003cpoolmemory\u003e] [--timeoutsrun=\u003ctimeoutsrun\u003e] [--timeoutslogs=\u003ctimeoutslogs\u003e] [--loglevel=\u003cloglevel\u003e] [--replicas=\u003creplicas\u003e] config limits [--time=\u003ctime\u003e] [--memory=\u003cmemory\u003e] [--sequencelength=\u003csequencelength\u003e] [--perminute=\u003cperminute\u003e] [--concurrent=\u003cconcurrent\u003e] [--triggerperminute=\u003ctriggerperminute\u003e] [--activation_max_payload=\u003cactivation_max_payload\u003e] config storage [--class=\u003cstorage_class\u003e] [--provisioner=\u003cstorage_provisioner\u003e] config postgres [--failover] [--backup] [--schedule=\u003ccron_expression\u003e] [--replicas=\u003creplicas\u003e] config minio [--s3] [--console] config milvus [--maxdbnum=\u003cmaxdbnum\u003e] config etcd [--replicas=\u003creplicas\u003e] [--quota_backend_bytes=\u003cbytes\u003e] [--auto_compaction_retention=\u003cretention_period\u003e] config aws [--access=\u003caccess\u003e] [--secret=\u003csecret\u003e] [--region=\u003cregion\u003e] [--image=\u003cimage\u003e] [--vm=\u003cvm\u003e] [--vmuser=\u003cvmuser\u003e] [--disk=\u003cdisk\u003e] [--key=\u003ckey\u003e] config eks [--project=\u003cproject\u003e] [--access=\u003caccess\u003e] [--secret=\u003csecret\u003e] [--region=\u003cregion\u003e] [--name=\u003cname\u003e] [--count=\u003ccount\u003e] [--vm=\u003cvm\u003e] [--disk=\u003cdisk\u003e] [--key=\u003ckey\u003e] [--kubever=\u003ckubever\u003e] config gcloud [--project=\u003cproject\u003e] [--region=\u003cregion\u003e] [--vm=\u003cvm\u003e] [--disk=\u003cdisk\u003e] [--key=\u003ckey\u003e] [--image=\u003cimage\u003e] config gke [--name=\u003cname\u003e] [--project=\u003cproject\u003e] [--region=\u003cregion\u003e] [--count=\u003ccount\u003e] [--vm=\u003cvm\u003e] [--disk=\u003cdisk\u003e] config azcloud [--project=\u003cproject\u003e] [--region=\u003cregion\u003e] [--vm=\u003cvm\u003e] [--disk=\u003cdisk\u003e] [--key=\u003ckey\u003e] [--image=\u003cimage\u003e] config aks [--project=\u003cproject\u003e] [--name=\u003cname\u003e] [--region=\u003cregion\u003e] [--count=\u003ccount\u003e] [--vm=\u003cvm\u003e] [--disk=\u003cdisk\u003e] [--key=\u003ckey\u003e] config (status|export|reset) config use [\u003cn\u003e] [--delete] [--rename=\u003crename\u003e] config minimal config slim Commands config apihost configure the apihost (auto: auto assign) and enable tls config runtime show the current runtime.json or import the \u003cruntime-json\u003e if provided config enable enable OpenServerless services to install config disable disable OpenServerless services to install config slack configure Alert Manager over a given slack channel config mail configure Alert Manager over a gmail account config volumes configure the volume size distinguished in 3 categories (openwhisk couchdb \u0026 kafka, database, minio storage, alerting, milvus) config controller configure Openwhisk enterprise controller java options config invoker configure Openwhisk enterprise invoker options config limits configure Openwhisk actions limits config storage allows to customize storage persistence class and provider config postgres allows to customize enterprise options for nuvolaris default postgres deployment config minio allows to customize MINIO options config milvus allows to customize MILVUS options config etcd allows to customize ETCD options config aws configure Amazon Web Service (AWS) credentials and parameters config gcloud configure Google Cloud credentials and parameters config eks configure Amazon EKS Kubernetes Cluster config azcloud configure Azure VM credentials and parameters config aks configure Azure AKS Kubernetes Cluster config gke configure Google Cloud GKE Kubernetes Cluster config reset reset configuration config status show current configuration config export export all the variables config use use a different kubernetes cluster among those you created config minimal shortcut for ops config enabling only redis,mongodb,minio,cron,static,postgres config slim shortcut for ops config slim, but adding lightweight milvus and other sizing improvements Options --all select all services --redis select redis --mongodb select mongodb (FerretDB Proxy) --minio select minio --cron select cron --static select static --postgres select postgres --tls=\u003cemail\u003e enable tls with let's encrypt, contact email required --access=\u003caccess\u003e specify access key --secret=\u003csecret\u003e specify secret key --name=\u003cname\u003e specify name --region=\u003cregion\u003e specify region (AWS) location (Azure) or zone (GKE) --count=\u003ccount\u003e specify node count --vm=\u003cvm\u003e specify vm type --disk=\u003cdisk\u003e specify disk size --key=\u003ckey\u003e specify ssh key name --kubever=\u003ckubever\u003e specify kubernetes version --delete delete the selected kubeconfig --image=\u003cimage\u003e specify gcp image type (default to ubuntu-minimal-2204-lts. Passing ubuntu-minimal-2204-lts-arm64 will create ARM based VM) --prometheus select monitoring via Prometheus --slack select alert manager module over Slack channel --mail select alert manager module over mail channel using a gmail account --affinity select pod affinity for multinode enterprise deployment. In such case load will be splitted between node labeled with nuvolaris-role in core or invoker --tolerations select pod tolerations for multinode enterprise deployment. --failover select failover support on components supporting it as postgres --backup select automatic backup on components support it as postgres --s3 activate s3 compatible ingress on components supporting it --console activate a s3 console ingress on components supporting it (Currently MINIO) --quota select quota checker module --milvus select MILVUS vector database ","categories":"","description":"Configure OpenServerless","excerpt":"Configure OpenServerless","ref":"/docs/reference/tasks/config/","tags":"","title":"Config"},{"body":"Print date with different formats. If no time stamp or date strings are given, uses current time\nUsage: ops -datefmt [options] [arguments] Options -h, --help\tprint this help info -t, --timestamp\tunix timestamp to format (default: current time) -s, --str date string to format --if\tinput format to use with input date string (via --str) -f, --of\toutput format to use (default: UnixDate) Possible formats (they follows the standard naming of go time formats, with the addition of ‘Millisecond’ and ‘ms’):\nLayout ANSIC UnixDate RubyDate RFC822 RFC822Z RFC850 RFC1123 RFC1123Z RFC3339 RFC3339Nano Kitchen Stamp StampMilli StampMicro StampNano DateTime DateOnly TimeOnly Milliseconds ms Example $ ops -datefmt -f DateTime 2024-08-11 03:00:34 ","categories":"","description":"","excerpt":"Print date with different formats. If no time stamp or date strings …","ref":"/docs/reference/tools/datefmt/","tags":"","title":"datefmt"},{"body":"Synopsis Usage: debug apihost debug certs debug config debug images debug ingress debug kube debug lb debug log debug route debug runtimes debug status debug watch debug operator:version Commands apihost show current apihost certs show certificates config show deployed configuration images show current images ingress show ingresses kube kubernetes support subcommand prefix lb show ingress load balancer log show logs route show openshift route runtimes show runtimes status show deployment status watch watch nodes and pod deployment operator:version show operator versions ","categories":"","description":"Debugging various parts of OpenServerless","excerpt":"Debugging various parts of OpenServerless","ref":"/docs/reference/tasks/debug/","tags":"","title":"Debug"},{"body":"The ops debug subcomand gives access to many useful debugging utilities as follow:\nYou need access to the Kubernetes cluster where OpenServerless is installed.\nops debug: available subcommands: * apihost: show current apihost * certs: show certificates * config: show deployed configuration * images: show current images * ingress: show ingresses * kube: kubernetes support subcommand prefix * lb: show ingress load balancer * log: show logs * route: show openshift route * runtimes: show runtimes * status: show deployment status * watch: watch nodes and pod deployment * operator:version: show operator versions The ops debug kube subcommand also gives detailed informations about the underlying Kubernetes cluster:\nops debug kube: available subcommands: * ctl: execute a kubectl command, specify with CMD=\u003ccommand\u003e * detect: detect the kind of kubernetes we are using * exec: exec bash in pod P=... * info: show info * nodes: show nodes * ns: show namespaces * operator: describe operator * pod: show pods and related * svc: show services, routes and ingresses * users: show openserverless users custom resources * wait: wait for a value matching the given jsonpath on the specific resources under the namespace openserverless ","categories":"","description":"Utilities to troubleshoot OpenServerless' cluster","excerpt":"Utilities to troubleshoot OpenServerless' cluster","ref":"/docs/cli/debug/","tags":"","title":"Debugging"},{"body":"Synopsis Usage: devel user devel apihost devel detect devel ferretdb devel minio devel psql devel redis Commands devel user login in openserverless devel apihost show apihost for current context devel detect detect if web and packages directory are in place for the current directory devel ferretdb ferretdb utilities devel minio minio utilities devel psql postgresql utilities devel redis redis utilities ","categories":"","description":"OpenServerless Development Utilities.","excerpt":"OpenServerless Development Utilities.","ref":"/docs/reference/tasks/devel/","tags":"","title":"Devel"},{"body":"Configuring DNS and SSL You can use OpenServerless as just as a serverless engine, and use the default IP or DNS provided when provisioned your server or cluster. If you do so, only http is avaialble, and it is not secure.\nIf you want your server or cluster is available with a well-known internet name, you can associate the IP address or the “ugly” default DNS name of serveres or clusters to a DNS name of your choice, to use it also to publish the static front-end of your server.\nFurthermore, once you decided for a DNS name for your server, you can enable the provisioning of an SSL certificate so you server will be accessible with https.\nIn order to configure the DNS and the SSL the steps are:\nretrieve the IP address or the the DNS name of your server or cluster\nregister a DNS name of your choice with your registration name provider\nconfigure OpenServerless so he knows of the DNS and SSL and can use it\nRetrieving the IP address or the DNS name If OpenServerless is installed in your local machine with Docker, cannot configure any DNS nor SSL, so you can proceed configuring the services.\nIf OpenServerless is installed in a single server, after you satisfied the server prerequisites you will know the IP address or DNS name of you server.\nIf OpenServerless is installed in a Kubernetes cluster, after you satisfied the server cluster prerequisites you know either the IP address or the DNS name of the load balancer.\nRegister a DNS name or wildcard Using the address of your server or cluster, you need either to configure a DNS name your already own or contact a domain name registrar to register a new DNS name dedicated to your server or cluster.\nYou need at least one DNS name in a domain you control, for example nuvolaris.example.com that points to you IP or address.\nNote that:\nIf you have an IP address to your load balancer you need to configure an A record mapping nuvolaris.example.com to the IP address of your server.\nIf you have a DNS name to your load balancer, you need to configure a CNAME record mapping nuvolaris.example.com to the DNS name of your server.\n💡 NOTE\nIf you are registering a dedicated domain name for your cluster, you are advised to register wildcard name (*) for every domain name in example.com will resolve to your server.\nRegistering a wildcard is required to get a different website for for multiple users.\nConfigure OpenServerless to use your DNS and and enable SSL Once you registrered a single DNS (for example openserverless.example.com) or a wildcard DNS name (for example *.example.com) you can communicate to the installer what is the main DNS name of your cluster or server, as it is not able to detect it automatically. We call this the \u003capihost\u003e\n💡 NOTE\nIf you have registered a single DNS name, like openserverless.example.com use this name as \u003capihost\u003e.\nIf you have registered a wildcard DNS name, you have to choose a DNS name to be used as \u003capihost\u003e.\nWe recommended you use a name starting with api since to avoid clashes, user and domain names starting with api are reserved. So if you have a *.example.com wildcard DNS available, use api.example.com as your \u003capihost\u003e\nOnce you decided what is your API host, you can configure this as follows:\nops config apihost \u003capihost\u003e This configuration will assign a well know DNS name as access point of your OpenServerless cluster. However note it does NOT enable SSL. Accessing to your cluster will happen using HTTP.\nSince requests contain sensitive information like security keys, this is highly insecure. You hence do this only for development or testing but never for production.\nOnce you have a DNS name, enabling https is pretty easy, since we can do it automatically using the free service Let's Encrypt. We have however to provide a valid email address \u003cemail\u003e.\nOnce you know your \u003capihost\u003e and the \u003cemail\u003e to receive communications from Let’s Encrypt (mostly, when a domain name is invalidated and needs to be renewed), you can configure your apihost and enable SSL as follows:\nops config apihost \u003capihost\u003e --tls=\u003cemail\u003e Of course, replace the \u003capihost\u003e with the actual DNS name you registered, and \u003cemail\u003e with your email address\n","categories":"","description":"Configuring DNS and SSL","excerpt":"Configuring DNS and SSL","ref":"/docs/installation/configure/dns/","tags":"","title":"DNS and SSL"},{"body":"echoif is a utility that echoes the value of \u003ca\u003e if the exit code of the previous command is 0, echoes the value of \u003cb\u003e otherwise\nUsage: ops -echoif \u003ca\u003e \u003cb\u003e Example $( exit 1 ); ops -echoif \"0\" \"1\" 1 or\n$( exit 0 ); ops -echoif \"0\" \"1\" 0 ","categories":"","description":"","excerpt":"echoif is a utility that echoes the value of \u003ca\u003e if the exit code of …","ref":"/docs/reference/tools/echoif/","tags":"","title":"echoif"},{"body":"echoifempty is a utility that echoes the value of \u003ca\u003e if \u003cstr\u003e is empty, echoes the value of \u003cb\u003e otherwise.\nUsage: ops -echoifempty \u003cstr\u003e \u003ca\u003e \u003cb\u003e Example ops -echoifempty \"not empty string\" \"string is empty\" \"string is not empty\" ","categories":"","description":"","excerpt":"echoifempty is a utility that echoes the value of \u003ca\u003e if \u003cstr\u003e is …","ref":"/docs/reference/tools/echoifempty/","tags":"","title":"echoifempty"},{"body":"echoifexists is a utility that echoes the value of \u003ca\u003e if \u003cfile\u003e exists, echoes the value of \u003cb\u003e otherwise.\nUsage: ops -echoifexists \u003cfile\u003e \u003ca\u003e \u003cb\u003e Example ops -echoifexists \"exists\" \"doesn't exists\" ","categories":"","description":"","excerpt":"echoifexists is a utility that echoes the value of \u003ca\u003e if \u003cfile\u003e …","ref":"/docs/reference/tools/echoifexists/","tags":"","title":"echoifexists"},{"body":"Synopsis Usage: eks config eks create eks delete eks kubeconfig eks lb eks status Commands config configure an Amazon EKS cluster create create an Amazon EKS cluster delete delete the current Amazon EKS cluster kubeconfig extract kubeconfig for connecting to the cluster lb show the load balancer hostname prereq check prerequisites status show the cluster status ","categories":"","description":"Create and Manage an Amazon EKS cluster","excerpt":"Create and Manage an Amazon EKS cluster","ref":"/docs/reference/tasks/cloud/eks/","tags":"","title":"Eks"},{"body":"empty creates an empty file - returns error if it already exists.\nUsage: ops -empty \u003cfilename\u003e ","categories":"","description":"","excerpt":"empty creates an empty file - returns error if it already exists. …","ref":"/docs/reference/tools/empty/","tags":"","title":"empty"},{"body":"Synopsis Usage: env add \u003cargs\u003e... env remove \u003cargs\u003e... env list [--format=table|raw|json] Commands - add add or change one or multiple env to user metadata. ops env add VARA=valuea VARB=valueb - remove remove one or multiple env from user metadata. ops env remove VARA VARB - list list envs from user metadata Options --format Output data as table, as raw env or as json. default is table ","categories":"","description":"OpenServerless Env Utilities","excerpt":"OpenServerless Env Utilities","ref":"/docs/reference/tasks/env/","tags":"","title":"Env"},{"body":"executable make a file executable: on Unix-like systems it will do a chmod u+x. On Windows systems it will rename the file to .exe if needed.\nUsage: ops -executable \u003cfilename\u003e Example ops -executable kind ","categories":"","description":"","excerpt":"executable make a file executable: on Unix-like systems it will do a …","ref":"/docs/reference/tools/executable/","tags":"","title":"executable"},{"body":"Extract one single file from a .zip .tar, .tgz, .tar.gz, tar.bz2, tar.gz.\nUsage: ops -extract file.(zip|tgz|tar[.gz|.bz2|.xz]) target Example Extract file named single.pdf from archive.zip archive.\nops -extract archive.zip single.pdf ","categories":"","description":"","excerpt":"Extract one single file from a .zip .tar, .tgz, .tar.gz, tar.bz2, …","ref":"/docs/reference/tools/extract/","tags":"","title":"extract"},{"body":"Synopsis Usage: ferretdb find \u003ccollection\u003e [--format=table|json] ferretdb submit \u003ccollection\u003e \u003cjsonfile\u003e ferretdb delete \u003ccollection\u003e ferretdb command [\u003cjsonfile\u003e] [--format=table|json] Commands ferretdb find search all elements in FerretDb/MongoDb collection ferretdb submit submit \u003cfile\u003e to a FerretDb/MongoDb collection ferretdb delete empty the FerretDb/MongoDb collection ferretdb command send a raw command from json file passed on stdin. See https://www.mongodb.com/docs/manual/reference/method/db.runCommand/#mongodb-method-db.runCommand Options --format Output data as table or json. default is json ","categories":"","description":"OpenServerless Ferret Db Development Utilities.","excerpt":"OpenServerless Ferret Db Development Utilities.","ref":"/docs/reference/tasks/devel/ferretdb/","tags":"","title":"Ferretdb"},{"body":"Show extension and MIME type of a file. Supported types are documented here\nUsage: ops -filetype [-h] [-e] [-m] FILE Options -h shows this help -e show file standard extension -m show file mime type Examples File Mime type ops -filetype -m `which ops` This will output the ops executable type: application/x-mach-binary or application/x-executable\n","categories":"","description":"","excerpt":"Show extension and MIME type of a file. Supported types are documented …","ref":"/docs/reference/tools/filetype/","tags":"","title":"filetype"},{"body":"Synopsis Usage: gcloud vm-list gcloud vm-create \u003cname\u003e gcloud vm-delete \u003cname\u003e gcloud vm-getip \u003cname\u003e Commands vm-list lists the vm and their ips vm-create create a vm vm-getip get ip vm-delete delete the vm ","categories":"","description":"Create and Manage Google Virtual Machines","excerpt":"Create and Manage Google Virtual Machines","ref":"/docs/reference/tasks/cloud/gcloud/","tags":"","title":"Gcloud"},{"body":"Kubernetes Cluster requirements OpenServerless installs in any Kubernetes cluster which satisfies the following requirements:\ncluster-admin access\nat least 3 worker nodes with 4GB of memory each\nsupport for block storage configured as default storage class\nsupport for LoadBalancer services\nthe nginx ingress already installed\nthe cert manager already installed\nOnce you have such a cluster, you need to retrieve the IP address of the Load Balancer associated with the Nginx Ingress. In the default installation, it is installed in the namespace nginx-ingress and it is called ingress-nginx-controller.\nIn the default installation you can read the IP address with the following command:\nkubectl -n ingress-nginx get svc ingress-nginx-controller If you have installed it in some other namespace or with another name, change the command accordingly.\nThe result should be something like this:\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.0.9.99 20.62.156.19 80:30898/TCP,443:31451/TCP 4d1h Take note of the value under EXTERNAL-IP as you need it in the next step of installation, configuring DNS.\n","categories":"","description":"Prerequisites for all Kubernetes","excerpt":"Prerequisites for all Kubernetes","ref":"/docs/installation/prereq/kubernetes/cluster/","tags":"","title":"Generic Kubernetes"},{"body":"Synopsis Usage: gke config gke create gke delete gke kubeconfig gke lb Commands config configure a Google Kubernetes Engine cluster create create a Google Kubernetes Engine cluster delete delete aks cluster kubeconfig extract kubeconfig to access lb show the load balancer ","categories":"","description":"Create and Manage Google Kubernetes Engine cluster","excerpt":"Create and Manage Google Kubernetes Engine cluster","ref":"/docs/reference/tasks/cloud/gke/","tags":"","title":"Gke"},{"body":"Synopsis Usage: ide login [\u003cusername\u003e] [\u003capihost\u003e] ide devel [--fast] [--dry-run] ide deploy [\u003caction\u003e] [--dry-run] ide undeploy [\u003caction\u003e] [--dry-run] ide clean ide setup ide serve ide poll ide shell ide kill ide python ide nodejs Commands ide login login in openserverless ide devel activate development mode ide deploy deploy everything or just one action ide undeploy undeploy everything or just one action ide clean clean the temporay files ide setup setup the ide ide serve serve web area ide kill kill current devel or deploy job ide poll poll for logs ide shell start a shell with current env ide python python subcommands ide nodejs nodejs subcommands Options --fast Skip the initial deployment step and go in incremental update mode --dry-run Simulates the execution without making any actual changes ","categories":"","description":"OpenServerless Ide Development Utilities.","excerpt":"OpenServerless Ide Development Utilities.","ref":"/docs/reference/tasks/ide/","tags":"","title":"Ide"},{"body":"Install MicroK8S in a server You can install OpenServerless as described here and you do not need to install any Kubernetes in it, as it is installed as part of the procedure. In this case it installs K3S.\nBut you can install MicroK8S instead, if you prefer. Check here for informations about MicroK8S.\nIf you install MicroK8S in your server, you can then proceed configuring and then installing OpenServerless as in any other Kubernetes cluster.\nInstalling MicroK8S in a server Before installing ensure you have satisfied the prerequisites, most notably:\nyou know the IP address or DNS name\nyou have passwordless access with ssh\nyou have an user with passwordless sudo rights\nyou have opened the port 16443 in the firewall\nFurthermore, since MicroK8S is installed using snap, you also need to install snap.\n💡 NOTE\nWhile snap is available for many linux distributions, it is typically pre-installed and well supported in in Ubuntu and its derivatives. So we recommend MicroK8S only if you are actually using an Ubuntu-like Linux distribution.\nIf you system is suitable to run MicroK8S you can use the following subcommand to install in the server:\nops cloud mk8s create SERVER=\u003cserver\u003e USERNAME=\u003cusername\u003e where \u003cserver\u003e is IP address or DNS name to access the server, and \u003cusername\u003e is the user you use to access the server.\nThose informations should have been provided when provisioning the server.\n❗ IMPORTANT\nIf you installed a Kubernetes cluster in the server in this way, you should proceed installing OpenServerless as in a Kubernetes cluster, not as a server.\nThe installation retrieves also a kubernets configuration file so you can proceed to installing it without any other step involved.\nAdditional Commands In addition to create you have available also the following subcommands:\nops cloud mk8s delete SERVER=\u003cserver\u003e USERNAME=\u003cusername\u003e: uninstall K3S from the server\nops cloud mk8s kubeconfig SERVER=\u003cserver\u003e USERNAME=\u003cusername\u003e: retrieve the kubeconfig from the MicroK8S server\nops cloud mk8s info: informations about the server\nops cloud mk8s status: status of the server\n","categories":"","description":"Prerequisites to install OpenServerless in K8S","excerpt":"Prerequisites to install OpenServerless in K8S","ref":"/docs/installation/prereq/server/mk8s/","tags":"","title":"Install MicroK8S"},{"body":"Synopsis Usage: k3s create \u003cserver\u003e [\u003cuser\u003e] k3s delete \u003cserver\u003e [\u003cuser\u003e] k3s info k3s kubeconfig \u003cserver\u003e [\u003cuser\u003e] k3s status Commands create create a k3s with ssh in \u003cserver\u003e using \u003cuser\u003e with sudo delete uninstall k3s with ssh in \u003cserver\u003e using \u003cusername\u003e with sudo info info on the server kubeconfig recover the kubeconfig from a k3s server \u003cserver\u003e with user \u003cusername\u003e status status of the server ","categories":"","description":"Create and Manage K3S cluster","excerpt":"Create and Manage K3S cluster","ref":"/docs/reference/tasks/cloud/k3s/","tags":"","title":"K3s"},{"body":"Synopsis Usage: minio ls [--format=table|json] minio lsb \u003cbucket\u003e [--format=table|raw|json] minio rm \u003cbucket\u003e \u003cfile\u003e minio mv \u003cbucket\u003e \u003cfile\u003e \u003cdest_bucket\u003e \u003cdest_file\u003e minio cp \u003cbucket\u003e \u003cfile\u003e \u003cdest_bucket\u003e \u003cdest_file\u003e minio put \u003clocalfile\u003e \u003cbucket\u003e \u003cfile\u003e minio get \u003cbucket\u003e \u003cfile\u003e minio clean \u003cbucket\u003e [\u003cregexp\u003e] [--dryrun] Commands ls retrieve the list of all the user buckets lsb retrieve the content of the specified bucket (recursively) rm remove the given file from the specified bucket mv move a file from a bucket to another cp copy a file from a bucket to another put upload a localfile into the bucket/file get download a bucket file locally clean removes matching files (default pattern is .*) from the specified bucket (recursively) Options --format Output data as table or as json. default is json ","categories":"","description":"OpenServerless Minio/S3 Development Utilities.","excerpt":"OpenServerless Minio/S3 Development Utilities.","ref":"/docs/reference/tasks/devel/minio/","tags":"","title":"Minio"},{"body":"Synopsis Usage: mk8s create \u003cserver\u003e [\u003cuser\u003e] mk8s delete \u003cserver\u003e [\u003cuser\u003e] mk8s info mk8s kubeconfig \u003cserver\u003e [\u003cuser\u003e] mk8s status Commands create create a mk8s with ssh in \u003cserver\u003e using \u003cuser\u003e with sudo delete uninstall microk8s with ssh in \u003cserver\u003e using \u003cuser\u003e with sudo info info on the server kubeconfig recover the kubeconfig from a server \u003cserver\u003e with microk8s status status of the server ","categories":"","description":"Create and Manage an mk8s kubernetes cluster","excerpt":"Create and Manage an mk8s kubernetes cluster","ref":"/docs/reference/tasks/cloud/mk8s/","tags":"","title":"Mk8s"},{"body":"Check if a semver version A \u003e semver version B. Exits with 0 if greater, 1 otherwise.\nUsage: ops -needupdate \u003cversionA\u003e \u003cversionB\u003e Options -h, --help\tprint this help info Examples Update is needed ops -needupdate 1.0.1 1.0.0; echo $? This will output:\n0 Update is not needed ops -needupdate 1.0.0 1.0.1; echo $? This will output:\n1 ","categories":"","description":"","excerpt":"Check if a semver version A \u003e semver version B. Exits with 0 if …","ref":"/docs/reference/tools/needupdate/","tags":"","title":"needupdate"},{"body":"Join a relative path to the path from where ops was executed. This command is useful when creating custom tasks ( e.g. an ops plugin).\nUsage: ops -opspath \u003cpath\u003e Options:\n-h, --help print this help info Examples You are executing in directory /home/user/my/custom/dir ops -opspath my-file.txt This will output:\n/home/user/my/custom/dir/my-file.txt ","categories":"","description":"","excerpt":"Join a relative path to the path from where ops was executed. This …","ref":"/docs/reference/tools/opspath/","tags":"","title":"opspath"},{"body":"Synopsis Usage: osh import \u003ckubeconfig\u003e osh test \u003ckubeconfig\u003e osh setup ","categories":"","description":"OpenShift configuration","excerpt":"OpenShift configuration","ref":"/docs/reference/tasks/cloud/osh/","tags":"","title":"Osh"},{"body":"Project An OpenServerless Project ⚠️ WARNING\nThis document is still 🚧 work in progress 🚧\nA project represents a logical unit of functionality whose boundaries are up to you. Your app can contain one or more projects. The folder structure of a project determines how the deployer finds and labels packages and actions, how it deploys static web content, and what it ignores.\nYou can detect and load entire projects into OpenServerless with a single command using the ops CLI tool.\nProject Detection When deploying a project, ops checks in the given path for 2 special folders:\nThe packages folder: contains sub-folders that are treated as OpenServerless packages and are assumed to contain actions in the form of either files or folders, which we refer to as Single File Actions (SFA) and Multi File Actions (MFA).\nThe web folder: contains static web content.\nAnything else is ignored. This lets you store things in the root folder that are not meant to be deployed on OpenServerless (such as build folders and project documentation).\nSingle File Actions A single file action is simply a file with specific extension (the supported ones: .js .py .php .go .java), whici is directly deployed as an action.\nMulti File Actions A multi-file action is a folder containing a main file and dependencies. The folder is bundled into a zip file and deployed as an action.\n","categories":"","description":"How to deal with OpenServerless projects","excerpt":"How to deal with OpenServerless projects","ref":"/docs/cli/project/","tags":"","title":"Project"},{"body":"Synopsis Usage: psql describe \u003ctable\u003e [--format=json|table] psql sql [\u003cfile\u003e] [--format=json|table] Commands describe perfoms a query to describe the given table if it exists in the user PostgresSQL database sql submits a SQL snippet (like SELECT *, CREATE TABLE etc) from stdin or as a file and print-out the corresponding results Options --format Output data as table or as json. default is json ","categories":"","description":"OpenServerless PostrgreSQL Utilities.","excerpt":"OpenServerless PostrgreSQL Utilities.","ref":"/docs/reference/tasks/devel/psql/","tags":"","title":"Psql"},{"body":"Generate random numbers, strings and uuids\nUsage: ops -random [options] Options -h, --help shows this help -u, --uuid generates a random uuid v4 --int \u003cmax\u003e [min] generates a random non-negative integer between min and max (default min=0) --str \u003clen\u003e [\u003ccharacters\u003e] generates an alphanumeric string of length \u003clen\u003e from the set of \u003ccharacters\u003e provided (default \u003ccharacters\u003e=a-zA-Z0-9) Examples Random uuid v4: ops -random -u This will output something like:\n5b2c45ef-7d15-4a15-84c6-29144393b621 Random integer between max and min ops -random --int 100 60 This will output something like:\n78 ","categories":"","description":"","excerpt":"Generate random numbers, strings and uuids\nUsage: ops -random …","ref":"/docs/reference/tools/random/","tags":"","title":"random"},{"body":"Synopsis Usage: redis prefix redis command \u003ccommand\u003e Commands prefix print the redis prefix to use when submitting REDIS command to persist/retrieves value from user REDIS reserved partition command execute a redis command (@see https://redis.io/commands/), eg 'SET prefix:key value' or 'GET prefix:key value'. Key names should always start with the user assigned prefix (@see ops devel redis prefix) ","categories":"","description":"OpenServerless Redis Development Utilities.","excerpt":"OpenServerless Redis Development Utilities.","ref":"/docs/reference/tasks/devel/redis/","tags":"","title":"Redis"},{"body":"Remove a file\nUsage: ops -remove \u003cfilename\u003e ","categories":"","description":"","excerpt":"Remove a file\nUsage: ops -remove \u003cfilename\u003e ","ref":"/docs/reference/tools/remove/","tags":"","title":"remove"},{"body":"Rename a file\nUsage: ops -rename \u003csource\u003e \u003cdestination\u003e ","categories":"","description":"","excerpt":"Rename a file\nUsage: ops -rename \u003csource\u003e \u003cdestination\u003e ","ref":"/docs/reference/tools/rename/","tags":"","title":"rename"},{"body":"Usage: ops -retry [options] task [task options] Options -h, --help\tPrint help message -t, --tries=#\tSet max retries: Default 10 -m, --max=secs\tMaximum time to run (set to 0 to disable): Default 60 seconds -v, --verbose\tVerbose output Example Retry two times to get the ops action list\nops -retry -t 2 ops action list ","categories":"","description":"","excerpt":"Usage: ops -retry [options] task [task options] Options -h, --help …","ref":"/docs/reference/tools/retry/","tags":"","title":"retry"},{"body":"Apache OpenServerless (OPS) Runtimes Explained Apache OpenServerless (OPS) is a serverless platform built on Apache OpenWhisk, designed to execute functions in a scalable, event-driven environment. OPS leverages OpenWhisk’s runtime model while extending its capabilities to support additional customization via Docker.\nOverview of OPS Runtimes A runtime in OPS is a preconfigured environment that executes a serverless function. Since serverless platforms allocate compute resources dynamically, a runtime ensures:\nPortability – Developers can write code in different languages without managing dependencies. Scalability – The system provisions and scales runtimes automatically based on demand. Isolation – Each Action runs within its own dedicated runtime environment, ensuring security and consistency. Resource Efficiency – The platform optimizes resource allocation by suspending inactive runtimes and reusing active ones when possible. OPS natively supports the following runtimes:\nPython Node.js PHP However, since OPS is built on OpenWhisk, it inherits compatibility with all OpenWhisk-supported runtimes (e.g., Java, Go) and allows users to define custom runtimes using Docker containers.\nFor greater flexibility, developers can also package their own runtime environments using Docker to create “black box” actions.\nHow OPS Runtimes Work 1. Runtime Lifecycle OPS follows OpenWhisk’s runtime model, where each function invocation occurs in an isolated container. The lifecycle includes:\nInitialization: A container is provisioned with the selected runtime. Execution: The function code runs within the container. Idle: The container is paused (but retained) for reuse (Warm Start). Destroying: Idle containers are garbage-collected after some time. 2. Cold vs. Warm Starts Cold Start: A new container is created, increasing latency. Warm Start: Reuses a paused container for faster execution. 3. Runtime Composition Each runtime includes:\nLanguage Interpreter/Compiler: (e.g., Python 3.12, Node.js 21). Action Interface: A proxy that implements a canonical protocol to integrate with the OpenWhisk platform. Dependencies: Preinstalled libraries (e.g., requests for Python). Actions Actions are the fundamental execution units in Apache OpenServerless. They are stateless functions that run on the OpenWhisk platform.\nAn action can be used to update a database, respond to an API call, communicate with another system, ecc.\nTo use a function as an action, it must conform to the following:\nThe function accepts a dictionary as input and produces a dictionary as output. The input and output dictionaries are key-value pairs, where the key is a string and the value is any valid JSON value. The dictionaries are canonically represented as JSON objects when interfacing to an action via the REST API or the ops CLI.\nThe function must be called main or exposed as main\n","categories":"","description":"","excerpt":"Apache OpenServerless (OPS) Runtimes Explained Apache OpenServerless …","ref":"/docs/reference/runtimes/","tags":"","title":"Runtimes"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"Configuring OpenServerless services After you satisfied the prerequisites and before you actually install OpenServerless, you have to select which services you want to install:\nStatic, publishing of static assets\nRedis, a storage service\nMinIO an object storage service\nPostgres a relational SQL database\nFerretDB A MongoDB-compatible adapter for Postgres\nYou can enable all the services with:\nops config enable --all or disable all of them with:\nops config disable --all Or select the services you want, as follows.\nStatic Asset Publishing The static service allows you to publish static asset.\n💡 NOTE\nyou need to setup a a wildcard DNS name to be able to access them from Internet.\nYou can enable the Static service with:\nops config enable --static and disable it with:\nops config disable --static Redis Redis, is a fast, in-memory key-value store, usually used as cache, but also in some cases as a (non-relational) database.\nEnable REDIS:\nops config enable --redis Disable REDIS:\nops config disable --redis MinIO MinIO is an object storage service\nEnable minio:\nops config enable --minio Disable minio:\nops config disable --minio Postgres Postgres is an SQL (relational) database.\nEnable postgres:\nops config enable --postgres Disable postgres:\nops config disable --postgres FerretDB FerretDB is a MongoDB-compatible adapter for Postgres. It created a document-oriented database service on top of Postgres.\n💡 NOTE\nSince FerretDB uses Postgres as its storage, if you enable it, also the service Postgresql will be enabled as it is required.\nEnable MongoDB api with FerretDB:\nops config enable --mongodb Disable MongoDB api with FerretDB:\nops config disable --mongodb ","categories":"","description":"Configure OpenServerless services","excerpt":"Configure OpenServerless services","ref":"/docs/installation/configure/services/","tags":"","title":"Services"},{"body":"Synopsis Usage: setup mini setup devcluster [--uninstall|--status|--skip-check-ports] setup cluster [\u003ccontext\u003e] [--uninstall|--status] setup server \u003cserver\u003e [\u003cuser\u003e] [--uninstall|--status] setup status setup uninstall setup prereq Commands setup mini deploy mini Apache OpenServerless, slim local installation available as http://devel.miniops.me setup cluster deploy Apache OpenServerless in the Kubernetes cluster using the \u003ccontext\u003e, default the current setup devcluster deploy Apache OpenServerless in a devcluster created locally you need Docker Desktop available with at least 6G of memory assigned setup server create a Kubernetes in server \u003cserver\u003e and deploy Apache OpenServerless the server must be accessible with ssh using the \u003cuser\u003e with sudo power, default root setup status show the status of the last installation setup uninstall uninstall the last installation setup prereq validate current configuration Options --uninstall execute an uninstall instead of an installation --status show the status instead of an installation --skip-check-ports ignore the check of already used ports Subtasks kubernetes: prepare kubernetes nuvolaris: install nuvolaris docker: prepare docker ","categories":"","description":"Manage installation","excerpt":"Manage installation","ref":"/docs/reference/tasks/setup/","tags":"","title":"Setup"},{"body":"sh is the mvdan shell using the ops environment.\nWithout args, starts an interactive shell. Otherwise execute the script specified on command line.\nUsage: ops -sh [\u003cscript\u003e|-h|--help] ","categories":"","description":"","excerpt":"sh is the mvdan shell using the ops environment.\nWithout args, starts …","ref":"/docs/reference/tools/sh/","tags":"","title":"sh"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":"OpenServerless Administration Tasks admin Manage additional users in OpenServerless config Manage the Apache OpenServerless configuration setup Setup the Apache OpenServerless platform on multiple environments debug Debug utilities for the Apache OpenServerless platform cloud OpenServerless setup utilities for supported Deployment models on Cloud Providers util Utilities OpenServerless Development Tasks ide OpenServerless Development Utilities OpenWhisk Tasks action Manage actions invoke Invoke an action (pass parameters with \u003ckey\u003e=\u003cvalue\u003e) url Get the url of an action activations Manage activations logs Show logs of activations result Show results of activations package Manage packages trigger Manage triggers rule Manage rules for triggers ","categories":"","description":"Type `ops \u003ctask\u003e` to see usage and subtasks.","excerpt":"Type `ops \u003ctask\u003e` to see usage and subtasks.","ref":"/docs/reference/tasks/","tags":"","title":"Tasks"},{"body":"Available tool (embedded commands) in ops:\n","categories":"","description":"","excerpt":"Available tool (embedded commands) in ops:\n","ref":"/docs/reference/tools/","tags":"","title":"Tools"},{"body":"Debug This document gives you hints for diagnostics and solving issues, using the (hidden) subcommand debug.\nNote it is technical and assumes you have some knowledge of how Kubernetes operates.\nWatching While installing, you can watch the installation (opening another terminal) with the command:\nops debug watch Check that no pods will go in error while deploying.\nConfiguration You can inspect the configuration with the ops debug subcommand\nAPI host: ops debug apihost\nStatic Configuration: ops debug config.\nCurrent Status: ops debug status\nRuntimes: ops debug runtimes\nLoad Balancer: ops debug lb\nImages: ops debug images\nLogs You can inspect logs with ops debug log subcommand. Logs you can show:\noperator: ops debug log operator (continuously: ops debug log foperator)\ncontroller: ops debug log controller (continuously: ops debug log fcontroller)\ndatabase: ops debug log couchdb (continuously: ops debug log fcouchdb)\ncertificate manager: ops debug log certman (continuously: ops debug log fcertmap)\nKubernetes You can detect which Kubernetes are you using with:\nops debug detect\nYou can then inspect Kubernetes objects with:\nnamespaces: ops debug kube ns\nnodes: ops debug kube nodes\npod: ops debug kube pod\nservices: ops debug kube svc\nusers: ops debug kube users\nYou can enter a pod by name (use kube pod to find the name) with:\nops debug kube exec P=\u003cpod-name\u003e Kubeconfig Usually, ops uses a hidden kubeconfig so does not override your Kubernetes configuration.\nIf you want to go more in-depth and you are knowledgeable of Kubernetes, you can export the kubeconfig with ops debug export F=\u003cfile\u003e.\nYou can overwrite your kubeconfig (be aware there is no backup) with ops debug export F=-.\n","categories":"","description":"How to diagnose and solve issues","excerpt":"How to diagnose and solve issues","ref":"/docs/installation/debug/","tags":"","title":"Troubleshooting"},{"body":"urlencode parameters using the default \u0026 separator (or a specific one using -s flag). Optionally, encode the values retrieving them from environment variables.\nUsage: ops -urlenc [-e] [-s \u003cstring\u003e] [parameters] Options -e Encode parameter values from environment variables -h Show help -s string Separator for concatenating the parameters (default \"\u0026\") Examples ops -urlenc a=1 b=2 This will output:\na%3D1\u0026b%3D2 ","categories":"","description":"","excerpt":"urlencode parameters using the default \u0026 separator (or a specific one …","ref":"/docs/reference/tools/urlenc/","tags":"","title":"urlenc"},{"body":"Synopsis Usage: util system util update-cli util check-operator-version \u003cversion\u003e util secrets util nosecrets util user-secrets \u003cusername\u003e util no-user-secrets \u003cusername\u003e util kubectl \u003cargs\u003e... util kubeconfig util config \u003cconfigjson\u003e [--override] [--showhelp] util clean util upload [\u003cfolder\u003e] [--batchsize=\u003cbatchsize\u003e] [--verbose] [--clean] util add-secret \u003cargs\u003e... util remove-secret \u003cargs\u003e... util list-secrets util ingress-type Commands - system system info (\u003cos\u003e-\u003carch\u003e in Go format) - update-cli update the cli downloading the binary - check-operator-version check if you need to update the operator - secrets generate system secrets - nosecrets remove system secrets - user-secrets generate user secrets for the given user - no-user-secrets remove user secrets for the given user - kubectl execute kubectl on current kubeconfig - kubeconfig export OVERWRITING current kubeconfig to ~/.kube/config - config update configuration file interactively - clean clean up the web bucket - upload uploads a folder to the web bucket in OpenServerless. - add-secret add one or multiple secrets to user metadata - remove-secret remove one or multiple secrets to user metadata - list-secrets list secrets from user metadata - ingress-type return the ingress type Options --showhelp Show configuration tool help. --override Override the current configuration. --verbose Provide more details. --clean Remove all files from the web bucket before upload. --batchsize=\u003cbatchsize\u003e Number of concurrent web uploads ","categories":"","description":"OpenServerless Utilities","excerpt":"OpenServerless Utilities","ref":"/docs/reference/tasks/util/","tags":"","title":"Util"},{"body":"Check if a value is valid according to the given constraints. If -e is specified, the value is retrieved from the environment variable with the given name.\nUsage: ops -validate [-e] [-m | -n | -r \u003cregex\u003e] \u003cvalue\u003e [\u003cmessage\u003e] Options -e Retrieve value from the environment variable with the given name. -h Print this help message. -m Check if the value is a valid email address. -n Check if the value is a number. -r string Check if the value matches the given regular expression. Examples Validate with regexp Validate email ops -validate -m example@gmail.com ops -validate -r '^[a-z]+$' abc ","categories":"","description":"","excerpt":"Check if a value is valid according to the given constraints. If -e is …","ref":"/docs/reference/tools/validate/","tags":"","title":"validate"},{"body":"Upload Web Assets The web folder in the root of a project is used to deploy static frontends. A static front-end is a collection of static asset under a given folder that will be published in a web server under a path.\nEvery uses has associated a web accessible static area where you can upload static assets.\nYou can upload a folder in this web area with\nops util upload \u003cfolder\u003e\nSynopsis: Subcommand: ops web Commands to upload and manage static content. Usage: util upload \u003cfolder\u003e [--quiet] [--clean] Commands: upload \u003cfolder\u003e Uploads a folder to the web bucket in OpenServerless. Options: --quiet Do not print anything to stdout. --clean Remove all files from the web bucket instead. ","categories":"","description":"How to handle frontend deployment","excerpt":"How to handle frontend deployment","ref":"/docs/cli/assets/","tags":"","title":"Web Assets"}]