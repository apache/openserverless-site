[{"body":"Quick Start This is a quick start guide to the installation process, targeting experienced users in a hurry.\nIt provides a high-level overview of the installation process, omitting advanced of details. The missing pieces are covered in the rest of the documentation.\nOf course, if this guide is not enough and things fail, you can always apply the rule: “if everything fails, read the manual”.\nPrerequisites Start ensuring the prerequsites are satisfied:\nDownload and install ops, the OpenServerless CLI, picking version suitable for your environment. We support 64-bit versions of recent Windows, MacOS and major Linux distributions.\nCheck that ops is correctly installed: open the terminal and write:\nops -info\nConfigure the services you want to enable. By default, OpenServerless will install only the serverless engine, accessible in http with no services enabled.\nIf you want to enable all the services, use:\nops config enable --all otherwise pick the services you want, among --redis, --mongodb, --minio, --cron, --postgres. Note that --mongodb is actually FerretDB and requires Postgres which is implicitly also enabled. More details here.\nNow, choose where to install OpenServerless.\nYour options are:\nlocally in your workstation;\nin a Linux server in your intranet\nin a Linux server available on Internet\nin a Kubernetes cluster in your intranet\nin cloud, where you can provision a Kubernetes cluster\nLocal Installation If you have a decent workstation (with at least 16GB of memory) running a recent 64-bit operating system, you can install Docker Desktop and then install OpenServerless in it. Once you have:\ninstalled the CLI\nconfigured the services\ninstalled Docker Desktop\nMake sure Docker Desktop its running before the next operation. You can install OpenServerless and its services in Docker with just this command:\nops setup devcluster Once it is installed, you can proceed to read the tutorial to learn how to code with it.\nNOTE: At least 16GB of memory is ideal, but if you know what you’re doing and can tolerate inefficiency, you can install with less using:\nexport PREFL_NO_MEM_CHECK=1 export PLEFL_NO_CPU_CHECK=1 Internet Server Configuration If you have access to a server on the Internet, you will know its IP address.\nMany cloud providers also give you a DNS name usually derived by the IP and very hard to remember such as ec2-12-34-56-78.us-west-2.compute.amazonaws.com.\nOnce you got the IP address and the DNS name, you can give to your server a bettername using a domain name provider. We cannot give here precise instructions as there are many DNS providers and each has different rules to do the setup. Check with your chosen domain name provider.\nIf you have this name, configure it and enable DNS with:\nops config apihost \u003cdns-name\u003e --tls=\u003cemail-address\u003e ❗ IMPORTANT\nReplace the \u003cdns-name\u003e with the actual DNS name, without using prefixes like http:// or suffixes like :443. Also, replace \u003cemail-address\u003e with your actual email address.\nthen proceed with the server installation.\nServer Installation Once you got access to a Linux server with:\nAn IP address or DNS name, referred to as \u003cserver\u003e\nPasswordless access with ssh to a Linux user \u003cuser\u003e\nAt least 8GB of memory and 50GB of disk space available\nThe user \u003cuser\u003e has passwordless sudo rights\nThe firewall that allows traffic to ports 80, 443 and 6443\nWithout any Docker or Kubernetes installed\nWithout any Web server or Web application installed\nthen you can install OpenServerless in it.\nThe server can be physical or virtual. We need Kubernetes in it but the installer takes care of installing also a flavor of Kubernetes, K3S, courtesy of K3Sup.\nTo install OpenServerless, first check you have access to the server with:\nssh \u003cuser\u003e@\u003cserver\u003e sudo hostname You should see no errors and read the internal hostname of your server.\nIf you do not receive errors, you can proceed to install OpenServerless with this command:\nops setup server \u003cserver\u003e \u003cuser\u003e ❗ IMPORTANT\nReplace in the commands \u003cserver\u003e with the address of your server, and \u003cuser\u003e with the actual user to use in your server. The \u003cserver\u003e can be the same as \u003cdns-name\u003e you have configured in the previous paragraph, if you did so, or simply the IP address of a server on your intranet\nNow wait until the installation completes. Once it is installed, you can proceed to read the tutorial to learn how to code with it.\nCloud Cluster Provisioning If you have access to a cloud provider, you can set up a Kubernetes cluster in it. The Kubernetes cluster needs to satisfy certain prerequisites to be able to install OpenServerless with no issues.\nWe provide the support to easily configure and install a compliant Kubernetes cluster for the following clouds:\nAmazon AWS\nMicrosoft Azure\nGoogle Cloud\nAt the end of the installation you will have available and accessible a Kubernetes Cluster able to install OpenServerless, so proceed with a cluster installation.\nAmazon AWS Configure and install an Amazon EKS cluster on Amazon AWS with:\nops config eks ops cloud eks create then install the cluster.\nAzure AKS Configure and install an Azure AKS cluster on Microsoft Azure with:\nops config aks ops cloud aks create then install the cluster.\nGoogle Cloud GKE Configure and install a Google Cloud GKE with:\nops config gke ops cloud gke create then install the cluster.\nCluster Install In short, if you have access to kubernetes cluster, you can install OpenServerless with:\nops setup cluster For a slightly longer discussion, checking prerequisites before installing, read on.\nPrerequisites to install If you have access to a Kubernetes cluster with:\nAccess to the cluster-admin role\nBlock storage configured as the default storage class\nThe nginx-ingress installed\nKnowledge of the IP address of your nginx-ingress controller\nyou can install OpenServerless in it. You can read more details here.\nYou can get this access either by provisioning a Kubernetes cluster in cloud or getting access to it from your system administrator.\nWhatever the way you get access to your Kubernetes cluster, you will end up with a configuration file which is usually stored in a file named .kube/config in your home directory. This file will give access to the Kubernetes cluster to install OpenServerless.\nPerforming the installation To install, first, verify you have actually access to the Kubernetes cluster, by running this command:\nops debug kube info You should get information about your cluster, something like this:\nKubernetes control plane is running at \\https://api.nuvolaris.osh.n9s.cc:6443\nNow you can finally install OpenServerless with the command:\nops setup cluster Wait until the process is complete and if there are no errors, OpenServerless is installed and ready to go.\nOnce it is installed, you can proceed to read the Tutorial to learn how to code with it.\n","categories":"","description":"Fast path to install a self-hosted OpenServerless","excerpt":"Fast path to install a self-hosted OpenServerless","ref":"/docs/installation/quickstart/","tags":"","title":"Quick Start"},{"body":"Actions Actions are stateless functions that run on the OpenWhisk and OpenServerless platform. For example, an action can be used to detect the faces in an image, respond to a database change, respond to an API call, or post a Tweet. In general, an action is invoked in response to an event and produces some observable output.\nAn action may be created from a function programmed using a number of supported languages and runtimes, or from a binary-compatible executable.\nThe OpenServerless CLI makes it easy to create and invoke actions. Instructions for configuring and using the CLI are available here.\nYou can also use the REST API.\nWhile the actual function code will be specific to a language and runtime, the operations to create, invoke and manage an action are the same regardless of the implementation choice.\nWe recommend that you review the cli and read the tutorial before moving on to advanced topics.\nWhat you need to know about actions Functions should be stateless, or idempotent. While the system does not enforce this property, there is no guarantee that any state maintained by an action will be available across invocations. In some cases, deliberately leaking state across invocations may be advantageous for performance, but also exposes some risks.\nAn action executes in a sandboxed environment, namely a container. At any given time, a single activation will execute inside the container. Subsequent invocations of the same action may reuse a previous container, and there may exist more than one container at any given time, each having its own state.\nInvocations of an action are not ordered. If the user invokes an action twice from the command line or the REST API, the second invocation might run before the first. If the actions have side effects, they might be observed in any order.\nThere is no guarantee that actions will execute atomically. Two actions can run concurrently and their side effects can be interleaved. OpenWhisk and OpenServerless does not ensure any particular concurrent consistency model for side effects. Any concurrency side effects will be implementation-dependent.\nActions have two phases: an initialization phase, and a run phase. During initialization, the function is loaded and prepared for execution. The run phase receives the action parameters provided at invocation time. Initialization is skipped if an action is dispatched to a previously initialized container — this is referred to as a warm start. You can tell if an invocation was a warm activation or a cold one requiring initialization by inspecting the activation record.\nAn action runs for a bounded amount of time. This limit can be configured per action, and applies to both the initialization and the execution separately. If the action time limit is exceeded during the initialization or run phase, the activation’s response status is action developer error.\nAccessing action metadata within the action body The action environment contains several properties that are specific to the running action. These allow the action to programmatically work with OpenWhisk and OpenServerless assets via the REST API, or set an internal alarm when the action is about to use up its allotted time budget. The properties are accessible via the system environment for all supported runtimes: Node.js, Python, Swift, Java and Docker actions when using the OpenWhisk and OpenServerless Docker skeleton.\n__OW_API_HOST the API host for the OpenWhisk and OpenServerless deployment running this action.\n__OW_API_KEY the API key for the subject invoking the action, this key may be a restricted API key. This property is absent unless requested with the annotation explicitly provide-api-key\n__OW_NAMESPACE the namespace for the activation (this may not be the same as the namespace for the action).\n__OW_ACTION_NAME the fully qualified name of the running action.\n__OW_ACTION_VERSION the internal version number of the running action.\n__OW_ACTIVATION_ID the activation id for this running action instance.\n__OW_DEADLINE the approximate time when this action will have consumed its entire duration quota (measured in epoch milliseconds).\n","categories":"","description":"What Actions are and how to create and execute them","excerpt":"What Actions are and how to create and execute them","ref":"/docs/reference/entities/actions/","tags":"","title":"Actions"},{"body":" Subscribe our mailing list sending an email to dev-subscribe@openserverless.apache.org\nDiscuss your contribution and get a ticket assigned in our [Issue Tracker](https://github.com/apache/openserverless/issues)\nsetup your virtual machine as described [here](https://github.com/apache/openserverless) .\nLearn about [git submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules) (we use them), and use the script update-tree.sh to update your source tree to the latest version of all the branches.\nFork the subrepo you want to contribute and code your contribution.\nDownload and sign the [ICLA](https://www.apache.org/licenses/icla.pdf) and send to secretary@apache.org before submitting any Pull Request\nSend a pull request to the relevant subrepo.\n","categories":"","description":"How to contribute to the Apache OpenServerless Project","excerpt":"How to contribute to the Apache OpenServerless Project","ref":"/contribution-guidelines/","tags":"","title":"Contribution Guidelines"},{"body":"Download and Install ops 🚧 PAGE UNDER CONSTRUCTION 🚧\nDownload links You can install OpenServerless using its Command Line Interface, ops.\nYou can download it for your system. It is available for the following operating systems, architectures and formats:\nPUT HERE THE DOWNLOADS Download your version from this page, then install it according to the procedures of your operating system.\nAfter the installation Once installed, in the first run ops will tell to update the tasks executing:\nops -update\nThis command updates the OpenServerless “tasks” (its internal logic) to the latest version. This command should be also executed frequently, as the tasks are continuously evolving and expanding.\nops will suggest when to update them (at least once a day).\nYou normally just need to update the tasks but sometimes you also need to update ops itself. The system will detect when it is the case and tell you what to do.\n","categories":"","description":"Download OpenServerless with ops CLI","excerpt":"Download OpenServerless with ops CLI","ref":"/docs/installation/download/","tags":"","title":"Download"},{"body":"Entities OpenServerless applications are composed by some “entities” that you can manipulate either using a command line interface or programmatically with code.\nThe command line interface is the ops command line tools, that can be used directly on the command line or automated through scripts. You can also a REST API crafted explicitly for OpenServerless.\nThe entities available in OpenServerless are:\nPackages: They serve as a means of grouping actions together, facilitating the sharing of parameters, annotations, etc. Additionally, they offer a base URL that can be utilized by web applications.\nActions: These are the fundamental components of a OpenServerless application, capable of being written in any programming language. Actions accept input and produce output, both formatted in JSON.\nActivations: Each action invocations produces an activation id that can be listed. Action output and results logged and are associated to activations and can be retrieved providing an activativation id.\nSequences: Actions can be interconnected, where the output of one action serves as the input for another, effectively forming a sequence.\nTriggers: Serving as entry points with distinct names, triggers are instrumental in activating multiple actions.\nRules: Rules establish an association between a trigger and an action. Consequently, when a trigger is fired, all associated actions are invoked accordingly.\nThe ops command Let’s now provide an overview of OpenServerless’ command line interface, focusing on the ops command.\nThe command can be dowloaded in precompile binary format for many platform following the Download button on https://www.nuvolaris.io/\nThe ops command is composed of many commands, each one with many subcommands. The general format is:\nops \u003centity\u003e \u003ccommand\u003e \u003cparameters\u003e \u003cflags\u003e Note that \u003cparameters\u003e and \u003cflags\u003e are different for each \u003ccommand\u003e, and for each \u003centity\u003e there are many subcommands.\nThe CLI shows documention in the form of help output if you do not provide enough parameters to it. Start with ops to get the list of the main commands. If you type the ops \u003centity\u003e get the help for that entity, and so on.\nFor example, let’s see ops output (showing the command) and the more frequently used command, action, also showing the more common subcommands, shared with many others:\n$ ops Welcome to Ops, the all-mighty OpenServerless Build Tool The top level commands all have subcommands. Just type ops \u003ccommand\u003e to see its subcommands. Commands: action work with actions activation work with activations invoke shorthand for action invoke (-r is the default) logs shorthand for activation logs package work with packages result shorthand for activation result rule work with rules trigger work with triggers url get the url of a web action$ wsk action There are many more sub commands used for aministrative purposes. In this documentation we only focus on the subcommands used to manage the main entities of OpenServerless.\nKeep in mind that commands represent entities, and their subcommands follow the CRUD model (Create, Retrieve via get/list, Update, Delete). This serves as a helpful mnemonic to understand the ops command’s functionality. While there are exceptions, these will be addressed throughout the chapter’s discussion. Note however that some subcommand may have some specific flags.\nNaming Entities Let’s see how entities are named.\nEach user also has a namespace, and everything a user creates, belongs to it.\nThe namespace is usually created by a system administrator.\nUnder a namespace you can create triggers, rules, actions and packages.\nThose entities will have a name like this:\n/mirella/demo-triggger\n/mirella/demo-rule\n/mirella/demo-package\n/mirella/demo-action\nWhen you create a package, you can put under it actions and feeds. Those entities are named\n/mirella/demo-package/demo-action\n/mirella/demo-package/demo-feed\n💡 NOTE\nIn the commands you do not require to specify a namespace. If your user is mirella, your namespace is /mirella, and You type demo-package to mean /mirella/demo-package, and demo-package/demo-action to mean /mirella/demo-package/demo-action.\n","categories":"","description":"The parts that OpenServerless applications are made of","excerpt":"The parts that OpenServerless applications are made of","ref":"/docs/cli/entities/","tags":"","title":"Entities"},{"body":"Getting started Build a sample Application Imagine we have a static website and need server logic to store contacts and validate data. This would require a server, a database and some code to glue it all together. With a serverless approach, we can just sprinkle little functions (that we call actions) on top of our static website and let OpenServerless take care of the rest. No more setting up VMs, backend web servers, databases, etc.\nIn this tutorial, we will see how you can take advantage of several services which are already part of a OpenServerless deployment and develop a contact form page for users to fill it with their emails and messages, which are then sent via email to us and stored in a database.\nOpenserverless CLI: Ops Serverless development is mostly performed on the CLI, and OpenServerless has its tool called ops. It’s a command line tool that allows you to deploy (and interact with) the platform seamlessly to the cloud, locally and in custom environments.\nOps is cross-platform and can be installed on Windows, Linux and MacOS. You can find it here: Ops Releases\nDeploy OpenServerless To start using OpenServerless you can refer to the Installation Guide. You can follow the local installation to quickly get started with OpenServerless deployed on your machine, or if you want to follow the tutorial on a deployment on cloud you can pick one of the many supported cloud provider. Once installed come back here!\nEnabling Services We also want to enable some extra services: a Postgres database, Static content with the Minio storage and a cron scheduler. We will use them shortly to upload frontend and store the data for our app! Let’s run in the terminal:\nops config enable --postgres --static --minio --cron Since you should already have a deployment running, we have to update it with the new services so they get deployed. Simply run:\nops update apply And with just that (when it finishes), we have everything we need ready to use!\nCleaning Up Once you are done and want to clean the services configuration, just run:\nops config disable --postgres --static --minio --cron ","categories":"","description":"Let's start building a sample application","excerpt":"Let's start building a sample application","ref":"/docs/tutorial/getting-started/","tags":"","title":"Getting started"},{"body":"Prerequisites to install OpenServerless with Docker You can install OpenServerless on your local machine using Docker. This page lists the prerequisits.\nFirst and before all you need a computer with at least 16 GB of memory and 30GB of available space.\n❗ IMPORTANT\n8GB are definitely not enough to run OpenServerless on your local machine.\nFurthermore, you need to install Docker. Let’s see the which one to install and configure if you have:\nWindows MacOS Linux Windows You require the 64 bit edition in Intel Architecture of a recent version of Windows (at least version 10). The installer nuv does not run on 32 bit versions nor in the ARM architecture.\nDownload and install Docker Desktop for Windows.\nOnce installed, you can proceed configuring OpenServerless for the installation.\nMacOS You require a recent version of MacOS (at least version 11.xb BigSur). The installer nuv is available both for Intel and ARM.\nDownload and install Docker Desktop for MacOS.\nSince MacOS uses a virtual machine for Docker with a constrained memory. you also need also to reserve at least 8GB.\n❗ IMPORTANT\nOn MacOS, the default 2GB and they are definitely not enough to run OpenServerless on your local machine.\nInstructions to increase the memory reserved to Docker Desktopo on MacOS:\nclick on the Docker Desktop icon in the menu\nselect Preferences\nclick on Resources\nincrease the reserved memory up to (at least) 8GB\nclick on Apply \u0026 Restart\nOnce installed, you can proceed configuring OpenServerless for the installation.\nLinux Docker Desktop is available also on Linux, however we advice to install instead the Server Docker Engine\nOn Linux, the Docker Engine for the server does not run in a virtual machine, so it is faster and uses less memory.\nOnce installed, you can proceed configuring OpenServerless for the installation.\n","categories":"","description":"Install OpenServerless with Docker locally","excerpt":"Install OpenServerless with Docker locally","ref":"/docs/installation/prereq/docker/","tags":"","title":"Local Docker"},{"body":"Local Installation This page describes how to install OpenServerless on your local machine. The services are limited and not accessible from the outside so it is an installation useful only for development purposes.\nPrerequisites Before installing, you need to:\ninstall Docker.\ninstall ops.\nconfigure the services you want\n💡 NOTE\nYou cannot have https and static publishing in a local installation. If you enable them, the configuration will be ignored.\nInstallation Run the command:\nops setup devcluster and wait until the command terminates.\nPost install Check the tutorial to learn how to use it.\nTo uninstall, execute the command:\nops setup devcluster --uninstall ","categories":"","description":"Install OpenServerless on a local machine","excerpt":"Install OpenServerless on a local machine","ref":"/docs/installation/install/local/","tags":"","title":"Local Machine"},{"body":"Packages OpenServerless groups actions and feeds in packages under a namespace. It is conceptually similar to a folder containing a group of related files.\nA package allows you to:\nGroup related actions together.\nShare parameters and annotations (each action sees the parameters assigned to the package).\nProvide web actions with a common prefix in the URL to invoke them.\nFor example, we can create a package demo-package and assign a parameter:\n$ ops package create demo-package -p email no-reply@nuvolaris.io ok: created package demo-package This command creates a new package with the specified name.\nPackage Creation, Update, and Deletion Let’s proceed with the commands to list, get information, update, and finally delete a package:\nFirst, let’s list our packages:\n$ ops package list packages /openserverless/demo-package/ private If you want to update a package by adding a parameter:\n$ ops package update demo-package -p email info@nuvolaris.io ok: updated package demo-package Let’s retrieve some package information:\n$ ops package get demo-package -s package /openserverless/demo-package/sample: (parameters: *email) Note the final -s, which means “summarize.”\nFinally, let’s delete a package:\n$ ops package delete demo-package ok: deleted package demo-package Adding Actions to the Package Actions can be added to a package using this command:\nops action create \u003cpackage-name\u003e/\u003caction-name\u003e This associates an existing action with the specified package.\nUsing Packages Once a package is created, actions within it can be invoked using their full path, with this schema: \u003cpackage-name\u003e/\u003caction-name\u003e. This allows organizing actions hierarchically and avoiding naming conflicts.\nConclusion Packages in OpenServerless provide a flexible and organized way to manage actions and their dependencies. Using the Ops CLI, you can efficiently create, add actions, and manage package dependencies, simplifying the development and management of serverless applications.\n","categories":"","description":"How to group actions and their related files","excerpt":"How to group actions and their related files","ref":"/docs/cli/entities/packages/","tags":"","title":"Packages"},{"body":"Configure a generic Linux server to install OpenServerless If you have access to a generic Linux server, to be able to install Nuvolaris it needs to:\nbe accessible without a password with ssh\nbe able to run root commands without a password with sudo\nopen the ports 80, 443 and 6443 or 16443\nIf your server does not already satisfy those requirements, read below for information how to create a sshkey, configure sudo and open the firewall\nInstalling a public SSH key To connect to a server without a password using openssh (used by the installer), you need a couple of files called ssh keys.\nYou can generate them on the command line using this command:\nssh-keygen It will create a couple of files, typically called:\n~/.ssh/id_rsa\n~/.ssh/id_rsa.pub\nwhere ~ is your home directory.\nYou have to keep secret the id_rsa file because it is the private key and contains the information to identify you uniquely. Think to is as your password.\nYou can copy the id_rsa.pub in the server or even share it publicly, as it is the public key. Think to it as your login name, and adding this file to the server adds you to the users who can login into it.\nOnce you have generated the public key, access your server, then edit the file ~/.ssh/authorized_keys adding the public key to it.\nIt is just one line, contained in the id_rsa.pub file.\nCreate the file if it does not exist. Append the line to the file (as a single line) if it already exists. Do not remove other lines if you do not want to remove access to other users.\nConfigure Sudo You normally access Linux servers using a user that is not root (the system administrator with unlimited power on the system).\nDepending on the system, the user to use to access be ubuntu, ec2-user, admin or something else entirely. However if you have access to the server, the information of which user to use should have been provided, including a way to access to the root user.\nYou need to give this user the right to execute commands as root without a password, and you do this by configuring the command sudo.\nYou usually have either access to root with the su command, or you can execute sudo with a password.\nType either su or sudo bash to become root and edit the file /etc/sudoers adding the following line:\n\u003cuser\u003e ALL=(ALL) NOPASSWD:ALL where \u003cuser\u003e is the user you use to log into the system.\nOpen the firewall You need to open the following ports in the firewall of the server:\n443 for HTTPS\n80 for HTTP and provisioning certificates\n6443 (K3S) or 16443 (MicroK8S) for Kubernetes\nFor information on how to open the firewall, please consult the documentation of your cloud provider or contact your system administrator, as there are no common procedures and they depends on the cloud provider.\n","categories":"","description":"General prerequisites to install OpenServerless","excerpt":"General prerequisites to install OpenServerless","ref":"/docs/installation/prereq/server/generic/","tags":"","title":"SSH and Sudo"},{"body":"Tutorial This tutorial walks you through developing a simple OpenServerless application using the Command Line Interface (CLI) and Javascript (but any supported language will do).\nIts purpose is to showcase serverless development in action by creating a contact form for a website. We will see the development process from start to finish, including the deployment of the platform and running the application.\n","categories":"","description":"Showcase serverless development in action","excerpt":"Showcase serverless development in action","ref":"/docs/tutorial/","tags":"","title":"Tutorial"},{"body":"Actions An action can generally be considered as a function, a snippet of code, or generally a method.\nThe ops action command is designed for managing actions, featuring frequently utilized CRUD operations such as list, create, update, and delete. We will illustrate these operations through examples using a basic hello action. Let’s assume we have the following file in the current directory:\nThe hello.js script with the following content:\nfunction main(args) { return { body: \"Hello\" } } Simple Action Deployment If we want to deploy this simple action in the package demo, let’s execute:\n$ ops package update demo ok: updated package demo $ ops action update demo/hello hello.js ok: update action demo/hello Note that we ensured the package exists before creating the action.\nWe can actually omit the package name. In this case, the package name is default, which always exists in a namespace. However, we advise always placing actions in some named package.\n💡 NOTE\nWe used update, but we could have used create if the action does not exist because update also creates the action if it does not exist and updates it if it is already there. Update here is similar to the patch concept in REST API. However, create generates an error if an action does not exist, while update does not, so it is practical to always use update instead of create (unless we really want an error for an existing action for some reason).\nHow to Invoke Actions Let’s try to run the action:\n$ ops invoke demo/hello { \"body\": \"Hello\" } Actually, the invoke command does not exist, or better, it’s just a handy shortcut for ops action invoke -r.\nIf you try to run ops action invoke demo/hello, you get:\n$ ops action invoke demo/hello ok: invoked /_/demo/hello with id fec047bc81ff40bc8047bc81ff10bc85 You may wonder where the result is. In reality, in OpenServerless, all actions are by default asynchronous, so what you usually get is the activation id to retrieve the result once the action is completed.\nTo block the execution until the action is completed and get the result, you can either use the flag -r or --result, or use ops invoke.\nNote, however, that we are using ops to invoke an action, which means all the requests are authenticated. You cannot invoke actions directly without logging into the system first.\nHowever, you can mark an action to be public by creating it with --web true (see below).\nPublic Actions If you want an action to be public, you can do:\n$ ops action update demo/hello hello.js --web true ok: updated action demo/hello $ ops url demo/hello https://nuvolaris.dev/api/v1/web/mirella/demo/hello and you can invoke it with:\n$ curl -sL https://nuvolaris.dev/api/v1/web/dashboard/demo/hello Hello Note that the output is only showing the value of the body field. This is because the web actions must follow a pattern to produce an output suitable for web output, so the output should be under the key body, and so on. Check the section on Web Actions for more information.\n💡 NOTE\nActually, ops url is a shortcut for ops action get --url. You can use ops action get to retrieve a more detailed description of an action in JSON format.\nAfter action create, action update, and action get (and the shortcuts invoke and url), we should mention action list and action delete.\nThe action list command obviously lists actions and allows us to delete them:\n$ ops action list /mirella/demo/hello private nodejs:18 $ ops action delete demo/hello ok: deleted action demo/hello Conclusion Actions are a core part of our entities. A ops action is a self-contained and executable unit of code deployed on the ops serverless computing platform.\n","categories":"","description":"Functions, the core of OpenServerless","excerpt":"Functions, the core of OpenServerless","ref":"/docs/cli/entities/actions/","tags":"","title":"Actions"},{"body":"Administration If you are the administrator and you have access to the Kubernetes cluster where OpenServerless is installed you can administer the system.\nYou have access to the ops admin subcommand with the following synopsis:\nSubcommand: ops admin\nUsage: admin adduser \u003cusername\u003e \u003cemail\u003e \u003cpassword\u003e [--all] [--redis] [--mongodb] [--minio] [--postgres] [--storagequota=\u003cquota\u003e|auto] admin deleteuser \u003cusername\u003e Commands: admin adduser create a new user in OpenServerless with the username, email and password provided admin deleteuser delete a user from the OpenServerless installation via the username provided Options: --all enable all services --redis enable redis --mongodb enable mongodb --minio enable minio --postgres enable postgres --storagequota=\u003cquota\u003e ","categories":"","description":"System administration","excerpt":"System administration","ref":"/docs/cli/admin/","tags":"","title":"Administration"},{"body":"About Apache OpenServerless Apache OpenServerless is an Open Source project, released under the Apache License 2.0 providing a portable and complete Serverless environment, allowing to build quickly and easily cloud-native applications.\nOur goal is to make OpenServerless ubitiquous, allowing it to easily run a complete and portable environment that runs in every Kubernetes.\nOpenServerless is based on Apache OpenWhisk, which provides a powerful, production-ready serverless engine.\nHowever, the serverless engine is just the beginning, because a serverless environment requires a set of integrated services.\nOpenServerless provides integrated with OpenWhisk several additional services such as databases, object storage, and a cron scheduler.\nFurthermore, we test it on many public cloud Kubernetes services and on-premises Kubernetes vendors.\nThe platform is paired with a powerful CLI tool, ops, which lets you deploy OpenServerless quickly and easily everywhere, and perform a lot of development tasks.\nOur goal is to build a complete distribution of a serverless environment with the following features:\nIt is easy to install and manage.\nIntegrates all the key services to build applications.\nIt is as portable as possible to run potentially in every Kubernetes.\nIt is however tested regularly against a set of supported Kubernetes environments.\nIf you want to know more about our goals, check our roadmap document.\n","categories":"","description":"","excerpt":"About Apache OpenServerless Apache OpenServerless is an Open Source …","ref":"/docs/","tags":"","title":"Docs"},{"body":"First steps Starting at the Front Right now, after a freshly installation, if we visit the \u003capihost\u003e you will see a very simple page with:\nWelcome to OpenServerless static content distributor landing page!!!\nThat’s because we’ve activated the static content, and by default it starts with this simple index.html page. We will instead have our own index page that shows the users a contact form powered by OpenServerless actions. Let’s write it now.\nLet’s create a folder that will contain all of our app code: contact_us_app.\nInside that create a new folder called web which will store our static frontend, and add there a index.html file with the following:\n\u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003clink href=\"//maxcdn.bootstrapcdn.com/bootstrap/3.3.0/css/bootstrap.min.css\" rel=\"stylesheet\" id=\"bootstrap-css\"\u003e \u003c/head\u003e \u003cbody\u003e \u003cdiv id=\"container\"\u003e \u003cdiv class=\"row\"\u003e \u003cdiv class=\"col-md-8 col-md-offset-2\"\u003e \u003ch4\u003eGet in Touch\u003c/h4\u003e \u003cform method=\"POST\"\u003e \u003cdiv class=\"form-group\"\u003e \u003cinput type=\"text\" name=\"name\" class=\"form-control\" placeholder=\"Name\"\u003e \u003c/div\u003e \u003cdiv class=\"form-group\"\u003e \u003cinput type=\"email\" name=\"email\" class=\"form-control\" placeholder=\"E-mail\"\u003e \u003c/div\u003e \u003cdiv class=\"form-group\"\u003e \u003cinput type=\"tel\" name=\"phone\" class=\"form-control\" placeholder=\"Phone\"\u003e \u003c/div\u003e \u003cdiv class=\"form-group\"\u003e \u003ctextarea name=\"message\" rows=\"3\" class=\"form-control\" placeholder=\"Message\"\u003e\u003c/textarea\u003e \u003c/div\u003e \u003cbutton class=\"btn btn-default\" type=\"submit\" name=\"button\"\u003e Send \u003c/button\u003e \u003c/form\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e Now we just have to upload it to our OpenServerless deployment. You could upload it using something like curl with a PUT to where your platform is deployed at, but there is an handy command that does it automatically for all files in a folder:\nops web upload web/ Pass to ops web upload the path to folder where the index.html is stored in (the web folder) and visit again \u003capihost\u003e.\nNow you should see the new index page:\nThe Contact Package The contact form we just uploaded does not do anything. To make it work let’s start by creating a new package to hold our actions. Moreover, we can bind to this package the database url, so the actions can directly access it!\nWith the debug command you can see what’s going on in your deployment. This time let’s use it to grab the “postgres_url” value:\nops -config -d | grep POSTGRES_URL Copy the Postgres URL (something like postgresql://...). Now we can create a new package for the application:\nops package create contact -p dbUri \u003cpostgres_url\u003e ok: created package contact The actions under this package will be able to access the “dbUri” variable from their args!\nTo follow the same structure for our action files, let’s create a folder packages and inside another folder contact to give our actions a nice, easy to find, home.\nTo manage and check out your packages, you can use the ops packages subcommands.\nops package list packages /openserverless/contact private /openserverless/hello private \u003c-- a default package created during deployment And to get specific information on a package:\nops package get contact ok: got package contact { \"namespace\": \"openserverless\", \"name\": \"contact\", \"version\": \"0.0.1\", \"publish\": false, \"parameters\": [ { \"key\": \"dbUri\", \"value\": \u003cpostgres_url\u003e } ], \"binding\": {}, \"updated\": 1696232618540 } ","categories":"","description":"Move your first steps on Apache Openserverless","excerpt":"Move your first steps on Apache Openserverless","ref":"/docs/tutorial/first-steps/","tags":"","title":"First steps"},{"body":"Server Installation This page describes how to install OpenServerless on a Linux server accessible with SSH.\nThis is a single node installation, so it is advisable only for development purposes.\nPrerequisites Before installing, you need to:\ninstall the OpenServerless CLI ops;\nprovision a server running a Linux operating system, either a virtual machine or a physical server, and you know its IP address or DNS name;\nconfigure it to have passwordless ssh access and sudo rights;\nopen the firewall to have access to ports 80, 443 and 6443 or 16443 from your client machine;\nconfigure the DNS name for the server and choose the services you want to enable;\nInstallation If the prerequisites are satisfied, execute the dommand:\nops setup server \u003cserver\u003e \u003cuser\u003e ❗ IMPORTANT\nReplace in the command before \u003cserver\u003e with the IP address or DNS name used to access the server, and \u003cuser\u003e with the username you have to use to access the server\nWait until the command completes and you will have OpenServerless up and running.\nPost Install Check the tutorial to learn how to use it.\nTo uninstall, execute the command:\nops setup server \u003cserver\u003e \u003cuser\u003e --uninstall ","categories":"","description":"Install on a Linux Server","excerpt":"Install on a Linux Server","ref":"/docs/installation/install/server/","tags":"","title":"Linux Server"},{"body":"Prerequisites to install OpenServerless in a Linux server You can install OpenServerless on any server either in your intranet or on in Internet running a Linux distribution, with the following requirements:\nYou know the IP address or DNS name of the server on Internet or in your Intranet.\nThe server requires at least 8GB of memory and 30GB of disk space available.\nIt should be running a Linux distribution supported by K3S.\nYou must open the firewall to access ports 80, 443 and 6443 (for K3S) or 16443 (for MicroK8S) from your machine.\nYou have to install a public ssh key to access it without a password.\nYou have to configure sudo to execute root commands without a password.\nYou can:\nget a server on any cloud provider or even install by yourself and then configure it\nprovision such a server with ops on Amazon Web Services\nprovision such a server with ops on on Google Cloud Platform\nOnce you have such a server you can optionally (it is not required) install K3S or MicroK8S in it.\nOnce you have configured you server, you can proceed configuring OpenServerless for the installation.\n","categories":"","description":"Install OpenServerless in a Linux server","excerpt":"Install OpenServerless in a Linux server","ref":"/docs/installation/prereq/server/","tags":"","title":"Linux Server"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/news/","tags":"","title":"News"},{"body":"Prerequisites to install OpenServerless This page lists the prerequisites to install OpenServerless in various environments.\nYou can install OpenServerless:\nfor development in a single node environment, either in your local machine or in a Linux server.\nfor production, in a multi node environment provided by a Kubernetes cluster.\nSingle Node development installation For development purposes, you can install a single node OpenServerless deployment in the following environments as soon as the following requirements are satisfied:\nTo install in your local machine, you need Docker Desktop\nTo install in a single node Linux server, you need a server with passwordless ssh access and sudo.\nOur installer can automatically install a Kubernetes environment, using K3S, but if you prefer you can install a single-node Kubernetes instance by yourself.\nIf you choose to install Kubernetes on your server, we provide support for:\nSuSE K3S\nCanonical MicroK8S\nMulti Node production installation For production purposes, you need a multi-node Kubernetes cluster that satisfies those requirements, accessible with its kubeconfig file.\nIf you have such a cluster, you can install OpenServerless in a Kubernetes cluster\nIf you do not have a cluster and you need to setup one, we provide support for provisioning a suitable cluster that satisfied our requirements for the following Kubernetes environments:\nEKS in Amazon AWS\nAKS in Microsoft Azure\nGKE in Google Cloud\nRedHat OpenShift\nOnce you have a suitable Kubernetes cluster, you can proceed installing OpenServerless.\n","categories":"","description":"","excerpt":"Prerequisites to install OpenServerless This page lists the …","ref":"/docs/installation/prereq/","tags":"","title":"Prerequisites"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/releases/","tags":"","title":"Releases"},{"body":"Provision a Linux server in Amazon Web Services You can provision a server suitable to install OpenServerless in cloud provider Amazon Web Services ops as follows:\ninstall aws, the AWS CLI\nget Access and Secret Key\nconfigure AWS\nprovision a server\nretrieve the ip address to configure a DNS name\nOnce you have a Linux server up and running you can proceed configuring and installing OpenServerless.\nInstalling the AWS CLI Our cli ops uses under the hood the AWS CLI version 2, so you need to dowload and install it following those instructions.\nOnce installed, ensure it is available on the terminal executing the following command:\naws --version you should receive something like this:\naws-cli/2.9.4 Python/3.9.11 Linux/5.19.0-1025-aws exe/x86_64.ubuntu.22 prompt/off Ensure the version is at least 2.\nGetting the Access and Secret key Next step is to retrieve credentials, in the form of an access key and a secret key.\nSo you need to:\naccess the AWS console following those instructions create an access key and secret key; give to the credentials the minimum required permissions as described here to build an EKS cluster. You will end up with a couple of string as follows:\nSample AWS Access Key ID: AKIAIOSFODNN7EXAMPLE Sample AWS Secret Access Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY Take note of them as you need them for configuring out CLI.\nConfigure AWS to provision a server Before you can provision a Linux server you have to configure AWS typing the command:\nops config aws The system will then ask the following questions:\n*** Please, specify AWS Access Id and press enter. AKIAIOSFODNN7EXAMPLE *** Please, specify AWS Secret Key and press enter. wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY *** Please, specify AWS Region to use and press enter. To get a list of valid values use: aws ec2 describe-regions --output table Just press enter for default [us-east-1]: *** Please, specify AWS public SSH key and press enter. If you already have a public SSH key in AWS, provide its name here. If you do not have it, generate a key pair with the following command: ssh-keygen The public key defaults to ~/.ssh/id_rsa.pub and you can import with: aws ec2 import-key-pair --key-name nuvolaris-key --public-key-material --region=\u003cyour-region\u003e fileb://~/.ssh/id_rsa.pub Just press enter for default [devkit-74s]: *** Please, specify AWS Image to use for VMs and press enter. The suggested image is an Ubuntu 22 valid only for us-east-1 Please check AWS website for alternative images in other zones Just press enter for default [ami-052efd3df9dad4825]: *** Please, specify AWS Default user for image to use for VMs and press enter. Default user to access the selected image. Just press enter for default [ubuntu]: *** Please, specify AWS Instance type to use for VMs and press enter. The suggested instance type has 8GB and 2vcp To get a list of valid values, use: aws ec2 describe-instance-types --query 'InstanceTypes[].InstanceType' --output table Just press enter for default [t3a.large]: *** Please, specify AWS Disk Size to use for VMs and press enter. Just press enter for default [100]: Provision a server You can provision one or more servers using ops. The servers will use the parameters you have just configured.\nYou can create a new server with:\nops cloud aws vm-create \u003cserver-name\u003e ❗ IMPORTANT\nReplace \u003cserver-name\u003e with a name you choose, for example ops-server\nThe command will create a new server in AWS with the parameters you specified in configuration.\nYou can also:\nlist servers you created with ops cloud aws vm-list\ndelete a server you created and you do not need anymore with ops cloud aws vm-delete \u003cserver-name\u003e\nRetrieve IP The server will be provisioned with an IP address assigned by AWS.\nYou can read the IP address of your server with\nops cloud aws vm-getip \u003cserver-name\u003e You need this IP when configuring a DNS name for the server.\n","categories":"","description":"Prerequisites to install OpenServerless in AWS","excerpt":"Prerequisites to install OpenServerless in AWS","ref":"/docs/installation/prereq/server/aws/","tags":"","title":"Server on AWS"},{"body":"Web Actions Web actions are OpenWhisk and Nuvolaris actions annotated to quickly enable you to build web based applications. This allows you to program backend logic which your web application can access anonymously without requiring an OpenWhisk and Nuvolaris authentication key. It is up to the action developer to implement their own desired authentication and authorization (i.e. OAuth flow).\nWeb action activations will be associated with the user that created the action. This actions defers the cost of an action activation from the caller to the owner of the action.\nLet’s take the following JavaScript action hello.js,\n$ cat hello.js function main({name}) { var msg = 'you did not tell me who you are.'; if (name) { msg = `hello ${name}!` } return {body: `\u003chtml\u003e\u003cbody\u003e\u003ch3\u003e${msg}\u003c/h3\u003e\u003c/body\u003e\u003c/html\u003e`} } You may create a web action hello in the package demo for the namespace guest using the CLI’s --web flag with a value of true or yes:\n$ nuv package create demo ok: created package demo $ nuv action create demo/hello hello.js --web true ok: created action demo/hello $ nuv action get demo/hello --url ok: got action hello https://${APIHOST}/api/v1/web/guest/demo/hello Using the --web flag with a value of true or yes allows an action to be accessible via REST interface without the need for credentials. A web action can be invoked using a URL that is structured as follows:\nhttps://{APIHOST}/api/v1/web/{QUALIFIED ACTION NAME}.{EXT}` The fully qualified name of an action consists of three parts: the namespace, the package name, and the action name.\nThe fully qualified name of the action must include its package name, which is default if the action is not in a named package.\nAn example is guest/demo/hello. The last part of the URI called the extension which is typically .http although other values are permitted as described later. The web action API path may be used with curl or wget without an API key. It may even be entered directly in your browser.\nTry opening:\nhttps://${APIHOST}/api/v1/web/guest/demo/hello.http?name=Jane in your web browser. Or try invoking the action via curl:\ncurl https://${APIHOST}/api/v1/web/guest/demo/hello.http?name=Jane Here is an example of a web action that performs an HTTP redirect:\nfunction main() { return { headers: { location: 'http://openwhisk.org' }, statusCode: 302 } } Or sets a cookie:\nfunction main() { return { headers: { 'Set-Cookie': 'UserID=Jane; Max-Age=3600; Version=', 'Content-Type': 'text/html' }, statusCode: 200, body: '\u003chtml\u003e\u003cbody\u003e\u003ch3\u003ehello\u003c/h3\u003e\u003c/body\u003e\u003c/html\u003e' } } Or sets multiple cookies:\nfunction main() { return { headers: { 'Set-Cookie': [ 'UserID=Jane; Max-Age=3600; Version=', 'SessionID=asdfgh123456; Path = /' ], 'Content-Type': 'text/html' }, statusCode: 200, body: '\u003chtml\u003e\u003cbody\u003e\u003ch3\u003ehello\u003c/h3\u003e\u003c/body\u003e\u003c/html\u003e' } } Or returns an image/png:\nfunction main() { let png = \u003cbase 64 encoded string\u003e return { headers: { 'Content-Type': 'image/png' }, statusCode: 200, body: png }; } Or returns application/json:\nfunction main(params) { return { statusCode: 200, headers: { 'Content-Type': 'application/json' }, body: params }; } The default content-type for an HTTP response is application/json and the body may be any allowed JSON value. The default content-type may be omitted from the headers.\nIt is important to be aware of the response size limit for actions since a response that exceeds the predefined system limits will fail. Large objects should not be sent inline through OpenWhisk and Nuvolaris, but instead deferred to an object store, for example.\nHandling HTTP requests with actions An OpenWhisk and Nuvolaris action that is not a web action requires both authentication and must respond with a JSON object. In contrast, web actions may be invoked without authentication, and may be used to implement HTTP handlers that respond with headers, statusCode, and body content of different types. The web action must still return a JSON object, but the OpenWhisk and Nuvolaris system (namely the controller) will treat a web action differently if its result includes one or more of the following as top level JSON properties:\nheaders: a JSON object where the keys are header-names and the values are string, number, or boolean values for those headers (default is no headers). To send multiple values for a single header, the header’s value should be a JSON array of values.\nstatusCode: a valid HTTP status code (default is 200 OK if body is not empty otherwise 204 No Content).\nbody: a string which is either plain text, JSON object or array, or a base64 encoded string for binary data (default is empty response).\nThe body is considered empty if it is null, the empty string \"\" or undefined.\nThe controller will pass along the action-specified headers, if any, to the HTTP client when terminating the request/response. Similarly the controller will respond with the given status code when present. Lastly, the body is passed along as the body of the response. If a content-type header is not declared in the action result’s headers, the body is interpreted as application/json for non-string values, and text/html otherwise. When the content-type is defined, the controller will determine if the response is binary data or plain text and decode the string using a base64 decoder as needed. Should the body fail to decoded correctly, an error is returned to the caller.\nHTTP Context All web actions, when invoked, receives additional HTTP request details as parameters to the action input argument. They are:\n__ow_method (type: string): the HTTP method of the request.\n__ow_headers (type: map string to string): the request headers.\n__ow_path (type: string): the unmatched path of the request (matching stops after consuming the action extension).\n__ow_user (type: string): the namespace identifying the OpenWhisk and Nuvolaris authenticated subject.\n__ow_body (type: string): the request body entity, as a base64 encoded string when content is binary or JSON object/array, or plain string otherwise.\n__ow_query (type: string): the query parameters from the request as an unparsed string.\nA request may not override any of the named __ow_ parameters above; doing so will result in a failed request with status equal to 400 Bad Request.\nThe __ow_user is only present when the web action is annotated to require authentication and allows a web action to implement its own authorization policy. The __ow_query is available only when a web action elects to handle the “raw” HTTP request. It is a string containing the query parameters parsed from the URI (separated by \u0026). The __ow_body property is present either when handling “raw” HTTP requests, or when the HTTP request entity is not a JSON object or form data. Web actions otherwise receive query and body parameters as first class properties in the action arguments with body parameters taking precedence over query parameters, which in turn take precedence over action and package parameters.\nAdditional features Web actions bring some additional features that include:\nContent extensions: the request must specify its desired content type as one of .json, .html, .http, .svg or .text. This is done by adding an extension to the action name in the URI, so that an action /guest/demo/hello is referenced as /guest/demo/hello.http for example to receive an HTTP response back. For convenience, the .http extension is assumed when no extension is detected.\nQuery and body parameters as input: the action receives query parameters as well as parameters in the request body. The precedence order for merging parameters is: package parameters, binding parameters, action parameters, query parameter, body parameters with each of these overriding any previous values in case of overlap . As an example /guest/demo/hello.http?name=Jane will pass the argument {name: \"Jane\"} to the action.\nForm data: in addition to the standard application/json, web actions may receive URL encoded from data application/x-www-form-urlencoded data as input.\nActivation via multiple HTTP verbs: a web action may be invoked via any of these HTTP methods: GET, POST, PUT, PATCH, and DELETE, as well as HEAD and OPTIONS.\nNon JSON body and raw HTTP entity handling: A web action may accept an HTTP request body other than a JSON object, and may elect to always receive such values as opaque values (plain text when not binary, or base64 encoded string otherwise).\nThe example below briefly sketches how you might use these features in a web action. Consider an action /guest/demo/hello with the following body:\nfunction main(params) { return { response: params }; } This is an example of invoking the web action using the .json extension, indicating a JSON response.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json { \"response\": { \"__ow_method\": \"get\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } You can supply query parameters.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json?name=Jane { \"response\": { \"name\": \"Jane\", \"__ow_method\": \"get\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } You may use form data as input.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json -d \"name\":\"Jane\" { \"response\": { \"name\": \"Jane\", \"__ow_method\": \"post\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"content-length\": \"10\", \"content-type\": \"application/x-www-form-urlencoded\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } You may also invoke the action with a JSON object.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json -H 'Content-Type: application/json' -d '{\"name\":\"Jane\"}' { \"response\": { \"name\": \"Jane\", \"__ow_method\": \"post\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"content-length\": \"15\", \"content-type\": \"application/json\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } You see above that for convenience, query parameters, form data, and JSON object body entities are all treated as dictionaries, and their values are directly accessible as action input properties. This is not the case for web actions which opt to instead handle HTTP request entities more directly, or when the web action receives an entity that is not a JSON object.\nHere is an example of using a “text” content-type with the same example shown above.\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json -H 'Content-Type: text/plain' -d \"Jane\" { \"response\": { \"__ow_method\": \"post\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"content-length\": \"4\", \"content-type\": \"text/plain\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\", \"__ow_body\": \"Jane\" } } Content extensions A content extension is generally required when invoking a web action; the absence of an extension assumes .http as the default. The fully qualified name of the action must include its package name, which is default if the action is not in a named package.\nProtected parameters Action parameters are protected and treated as immutable. Parameters are automatically finalized when enabling web actions.\n$ nuv action create /guest/demo/hello hello.js \\ --parameter name Jane \\ --web true The result of these changes is that the name is bound to Jane and may not be overridden by query or body parameters because of the final annotation. This secures the action against query or body parameters that try to change this value whether by accident or intentionally.\nSecuring web actions By default, a web action can be invoked by anyone having the web action’s invocation URL. Use the require-whisk-auth web action annotation to secure the web action. When the require-whisk-auth annotation is set to true, the action will authenticate the invocation request’s Basic Authorization credentials to confirm they represent a valid OpenWhisk and Nuvolaris identity. When set to a number or a case-sensitive string, the action’s invocation request must include a X-Require-Whisk-Auth header having this same value. Secured web actions will return a Not Authorized when credential validation fails.\nAlternatively, use the --web-secure flag to automatically set the require-whisk-auth annotation. When set to true a random number is generated as the require-whisk-auth annotation value. When set to false the require-whisk-auth annotation is removed. When set to any other value, that value is used as the require-whisk-auth annotation value.\nnuv action update /guest/demo/hello hello.js --web true --web-secure my-secret or\nnuv action update /guest/demo/hello hello.js --web true -a require-whisk-auth my-secret curl https://${APIHOST}/api/v1/web/guest/demo/hello.json?name=Jane -X GET -H \"X-Require-Whisk-Auth: my-secret\" It’s important to note that the owner of the web action owns all of the web action’s activations records and will incur the cost of running the action in the system regardless of how the action was invoked.\nDisabling web actions To disable a web action from being invoked via web API (https://APIHOST/api/v1/web/), pass a value of false or no to the --web flag while updating an action with the CLI.\nnuv action update /guest/demo/hello hello.js --web false Raw HTTP handling A web action may elect to interpret and process an incoming HTTP body directly, without the promotion of a JSON object to first class properties available to the action input (e.g., args.name vs parsing args.__ow_query). This is done via a raw-http annotation. Using the same example show earlier, but now as a “raw” HTTP web action receiving name both as a query parameters and as JSON value in the HTTP request body:\n$ curl https://${APIHOST}/api/v1/web/guest/demo/hello.json?name=Jane -X POST -H \"Content-Type: application/json\" -d '{\"name\":\"Jane\"}' { \"response\": { \"__ow_method\": \"post\", \"__ow_query\": \"name=Jane\", \"__ow_body\": \"eyJuYW1lIjoiSmFuZSJ9\", \"__ow_headers\": { \"accept\": \"*/*\", \"connection\": \"close\", \"content-length\": \"15\", \"content-type\": \"application/json\", \"host\": \"172.17.0.1\", \"user-agent\": \"curl/7.43.0\" }, \"__ow_path\": \"\" } } Enabling raw HTTP handling Raw HTTP web actions are enabled via the --web flag using a value of raw.\nnuv action create /guest/demo/hello hello.js --web raw Disabling raw HTTP handling Disabling raw HTTP can be accomplished by passing a value of false or no to the --web flag.\nnuv update create /guest/demo/hello hello.js --web false Decoding binary body content from Base64 When using raw HTTP handling, the __ow_body content will be encoded in Base64 when the request content-type is binary. Below are functions demonstrating how to decode the body content in Node, Python, and PHP. Simply save a method shown below to file, create a raw HTTP web action utilizing the saved artifact, and invoke the web action.\nNode function main(args) { decoded = new Buffer(args.__ow_body, 'base64').toString('utf-8') return {body: decoded} } Python def main(args): try: decoded = args['__ow_body'].decode('base64').strip() return {\"body\": decoded} except: return {\"body\": \"Could not decode body from Base64.\"} PHP \u003c?php function main(array $args) : array { $decoded = base64_decode($args['__ow_body']); return [\"body\" =\u003e $decoded]; } As an example, save the Node function as decode.js and execute the following commands:\n$ nuv action create decode decode.js --web raw ok: created action decode $ curl -k -H \"content-type: application\" -X POST -d \"Decoded body\" https://${APIHOST}/api/v1/web/guest/default/decodeNode.json { \"body\": \"Decoded body\" } Options Requests By default, an OPTIONS request made to a web action will result in CORS headers being automatically added to the response headers. These headers allow all origins and the options, get, delete, post, put, head, and patch HTTP verbs. In addition, the header Access-Control-Request-Headers is echoed back as the header Access-Control-Allow-Headers if it is present in the HTTP request. Otherwise, a default value is generated as shown below.\nAccess-Control-Allow-Origin: * Access-Control-Allow-Methods: OPTIONS, GET, DELETE, POST, PUT, HEAD, PATCH Access-Control-Allow-Headers: Authorization, Origin, X-Requested-With, Content-Type, Accept, User-Agent Alternatively, OPTIONS requests can be handled manually by a web action. To enable this option add a web-custom-options annotation with a value of true to a web action. When this feature is enabled, CORS headers will not automatically be added to the request response. Instead, it is the developer’s responsibility to append their desired headers programmatically. Below is an example of creating custom responses to OPTIONS requests.\nfunction main(params) { if (params.__ow_method == \"options\") { return { headers: { 'Access-Control-Allow-Methods': 'OPTIONS, GET', 'Access-Control-Allow-Origin': 'example.com' }, statusCode: 200 } } } Save the above function to custom-options.js and execute the following commands:\n$ nuv action create custom-option custom-options.js --web true -a web-custom-options true $ curl https://${APIHOST}/api/v1/web/guest/default/custom-options.http -kvX OPTIONS \u003c HTTP/1.1 200 OK \u003c Server: nginx/1.11.13 \u003c Content-Length: 0 \u003c Connection: keep-alive \u003c Access-Control-Allow-Methods: OPTIONS, GET \u003c Access-Control-Allow-Origin: example.com Web Actions in Shared Packages A web action in a shared (i.e., public) package is accessible as a web action either directly via the package’s fully qualified name, or via a package binding. It is important to note that a web action in a public package will be accessible for all bindings of the package even if the binding is private. This is because the web action annotation is carried on the action and cannot be overridden. If you do not wish to expose a web action through your package bindings, then you should clone-and-own the package instead.\nAction parameters are inherited from its package, and the binding if there is one. You can make package parameters immutable by defining their values through a package binding.\nError Handling When an OpenWhisk and Nuvolaris action fails, there are two different failure modes. The first is known as an application error and is analogous to a caught exception: the action returns a JSON object containing a top level error property. The second is a developer error which occurs when the action fails catastrophically and does not produce a response (this is similar to an uncaught exception). For web actions, the controller handles application errors as follows:\nThe controller projects an error property from the response object.\nThe controller applies the content handling implied by the action extension to the value of the error property.\nDevelopers should be aware of how web actions might be used and generate error responses accordingly. For example, a web action that is used with the .http extension should return an HTTP response, for example: {error: { statusCode: 400 }. Failing to do so will in a mismatch between the implied content-type from the extension and the action content-type in the error response. Special consideration must be given to web actions that are sequences, so that components that make up a sequence can generate adequate errors when necessary.\n","categories":"","description":"","excerpt":"Web Actions Web actions are OpenWhisk and Nuvolaris actions annotated …","ref":"/docs/reference/entities/webactions/","tags":"","title":"Web Actions"},{"body":"Activations When an event occurs that triggers a function, ops creates an activation record, which contains information about the function execution, such as input parameters, output results, and any metadata associated with the activation. It’s something similar to the classic concept of log.\nHow activations work When invoking an action with ops action invoke, you’ll receive only an invocation id as an answer.\nThis invocation id allows you to read results and outputs produced by the execution of an action.\nLet’s demonstrate how it works by modifying the hello.js file to add a command to log some output.\nfunction main(args) { console.log(\"Hello\") return { \"body\": \"Hello\" } } Now, let’s deploy and invoke it (with a parameter hello=world) to get the activation id:\n$ ops action update demo/hello hello.js ok: updated action demo/hello $ ops action invoke demo/hello ok: invoked /_/demo/hello with id 0367e39ba7c74268a7e39ba7c7126846 Associated with every invocation, there is an activation id (in the example, it is 0367e39ba7c74268a7e39ba7c7126846).\nWe use this id to retrieve the results of the invocation with ops activation result or its shortcut, just ops result, and we can retrieve the logs using ops activation logs or just ops logs.\n$ ops result 0367e39ba7c74268a7e39ba7c7126846 { \"body\": \"Hello\" } $ ops logs 0367e39ba7c74268a7e39ba7c7126846 2024-02-17T20:01:31.901124753Z stdout: Hello List of activations You can list the activations with ops activation list and limit the number with --limit if you are interested in a subset.\n$ ops activation list --limit 5 Datetime Activation ID Kind Start Duration Status Entity 2024-02-17 20:01:31 0367e39ba7c74268a7e39ba7c7126846 nodejs:18 warm 8ms success dashboard/hello:0.0.1 2024-02-17 20:00:00 f4f82ee713444028b82ee71344b0287d nodejs:18 warm 5ms success dashboard/hello:0.0.1 2024-02-17 19:59:54 98d19fe130da4e93919fe130da7e93cb nodejs:18 cold 33ms success dashboard/hello:0.0.1 2024-02-17 17:40:53 f25e1f8bc24f4f269e1f8bc24f1f2681 python:3 warm 3ms success dashboard/index:0.0.2 2024-02-17 17:35:12 bed3213547cc4aed93213547cc8aed8e python:3 warm 2ms success dashboard/index:0.0.2 Note also the --since option, which is useful to show activations from a given timestamp (you can obtain a timestamp with date +%s).\nSince it can be quite annoying to keep track of the activation id, there are two useful alternatives.\nWith ops result --last and ops logs --last, you can retrieve just the last result or log.\nPolling activations With ops activation poll, the CLI starts a loop and displays all the activations as they happen.\n$ ops activation poll Enter Ctrl-c to exit. Polling for activation logs Conclusion Activations provide a way to monitor and track the execution of functions, enabling understanding of how code behaves in response to different events and allowing for debugging and optimizing serverless applications.\n","categories":"","description":"Detailed records of action executions","excerpt":"Detailed records of action executions","ref":"/docs/cli/entities/activations/","tags":"","title":"Activations"},{"body":"OpenServerless CLI The ops command is the command line interface to OpenServerless\nIt let’s you to install and manipulate the components of the system.\nIf it is not already included in the development environment provided you can download the CLI suitable for your platform from here, and install it\nLogin into the system To start working with you have to login in some OpenServerless installation.\nThe administrator should have provided with username, password and the URL to access the system.\nFor example, let’s assume you are the user mirella and the system is available on https://nuvolaris.dev.\nIn order to login type the following command and enter you password.\nops -login https://nuvolaris.dev mirella Enter Password: If the password is correct you are logged in the system and you can use the commands described below.\nNext Steps Once logged in, you can:\nlearn how to manage OpenServerless entities\nlearn how to deploy projects and web assets\nlearn how to administer the system and debug the system\n","categories":"","description":"An handy command line to interact with all parts of OpenServerless","excerpt":"An handy command line to interact with all parts of OpenServerless","ref":"/docs/cli/","tags":"","title":"CLI"},{"body":"Configuring OpenServerless Installation This section guides configuring the OpenServerless installation.\nNote that you can also skip this configuration, and install OpenServerless without any configuration.\nOnce you configure the installation, you can proceed to Install OpenServerless.\nYou can then reconfigure the system later.\nMinimal Configuration Without any configuration, you get a minimal OpenServerless:\nonly the serverless engine, no extra services\naccessible is only in http\nYou can:\nconfigure a DNS name or wildcard for your server or cluster, thus enabling SSL and static publishing.\nenable some or all of the integrated services:\nStatic, publishing of static content\nREDIS, a powerful key-value store\nMinIO, an object storage\nPostgres, a powerful SQL database\nFerretDB a NO-SQL, MongoDB compatible adapter for Postgres\n","categories":"","description":"","excerpt":"Configuring OpenServerless Installation This section guides …","ref":"/docs/installation/configure/","tags":"","title":"Configure OpenServerless"},{"body":"Form validation Now that we have a contact form and a package for our actions, we have to handle the submission. We can do that by adding a new action that will be called when the form is submitted. Let’s create a submit.js file in our packages/contact folder.\nfunction main(args) { let message = [] let errors = [] // TODO: Form Validation // TODO: Returning the Result } This action is a bit more complex. It takes the input object (called args) which will contain the form data (accessible via args.name, args.email, etc.). With that. we will do some validation and then return the result.\nValidation Let’s start filling out the “Form Validation” part by checking the name:\n// validate the name if(args.name) { message.push(\"name: \"+args.name) } else { errors.push(\"No name provided\") } Then the email by using a regular expression:\n// validate the email var re = /\\S+@\\S+\\.\\S+/; if(args.email \u0026\u0026 re.test(args.email)) { message.push(\"email: \"+args.email) } else { errors.push(\"Email missing or incorrect.\") } The phone, by checking that it’s at least 10 digits:\n// validate the phone if(args.phone \u0026\u0026 args.phone.match(/\\d/g).length \u003e= 10) { message.push(\"phone: \"+args.phone) } else { errors.push(\"Phone number missing or incorrect.\") } Finally, the message text, if present:\n// validate the message if(args.message) { message.push(\"message:\" +args.message) } Submission With the validation phase, we added to the “errors” array all the errors we found, and to the “message” array all the data we want to show to the user. So if there are errors, we have to show them, otherwise, we store the message and return a “thank you” page.\n// return the result if(errors.length) { var errs = \"\u003cul\u003e\u003cli\u003e\"+errors.join(\"\u003c/li\u003e\u003cli\u003e\")+\"\u003c/li\u003e\u003c/ul\u003e\" return { body: \"\u003ch1\u003eErrors!\u003c/h1\u003e\"+ errs + '\u003cbr\u003e\u003ca href=\"javascript:window.history.back()\"\u003eBack\u003c/a\u003e' } } else { var data = \"\u003cpre\u003e\"+message.join(\"\\n\")+\"\u003c/pre\u003e\" return { body: \"\u003ch1\u003eThank you!\u003c/h1\u003e\"+ data, name: args.name, email: args.email, phone: args.phone, message: args.message } } Note how this action is returning HTML code. Actions can return a { body: \u003chtml\u003e } kind of response and have their own url so they can be invoked via a browser and display some content.\nThe HTML code to display is always returned in the body field, but we can also return other stuff. In this case we added a a field for each of the form fields. This gives us the possibility to invoke in a sequence another action that can act just on those fields to store the data in the database.\nLet’s start deploying the action:\nops action create contact/submit submit.js --web true ok: created action contact/submit The --web true specifies it is a web action. We are creating a submit action in the contact package, that’s why we are passing contact/submit.\nYou can retrieve the url with:\nops url contact/submit $ \u003capihost\u003e/api/v1/web/openserverless/contact/submit If you click on it you will see the Error page with a list of errors, that’s because we just invoked the submit logic for the contact form directly, without passing in any args. This is meant to be used via the contact form page!\nWe need to wire it into the index.html. So let’s open it again and add a couple of attributes to the form:\n--- \u003cform method=\"POST\"\u003e \u003c-- old +++ \u003cform method=\"POST\" action=\"/api/v1/web/openserverless/contact/submit\" enctype=\"application/x-www-form-urlencoded\"\u003e \u003c-- new Upload the web folder again with the new changes:\nops web upload web/ Now if you go to the contact form page the send button should work. It will invoke the submit action which in turn will return some html.\nIf you fill it correctly, you should see the “Thank you” page.\nNote how only the HTML from the body field is displayed, the other fields are ignored in this case.\nThe ops action command can be used for many more things besides creating actions. For example, you can use it to list all available actions:\nops action list actions /openserverless/contact/submit private nodejs:18 And you can also get info on a specific action:\nops action get contact/submit { \"namespace\": \"openserverless/contact\", \"name\": \"submit\", \"version\": \"0.0.1\", \"exec\": { \"kind\": \"nodejs:18\", \"binary\": false }, ... } These commands can come in handy when you need to debug your actions.\nHere is the complete the submit.js action:\nfunction main(args) { let message = [] let errors = [] // validate the name if (args.name) { message.push(\"name: \" + args.name) } else { errors.push(\"No name provided\") } // validate the email var re = /\\S+@\\S+\\.\\S+/; if (args.email \u0026\u0026 re.test(args.email)) { message.push(\"email: \" + args.email) } else { errors.push(\"Email missing or incorrect.\") } // validate the phone if (args.phone \u0026\u0026 args.phone.match(/\\d/g).length \u003e= 10) { message.push(\"phone: \" + args.phone) } else { errors.push(\"Phone number missing or incorrect.\") } // validate the message if (args.message) { message.push(\"message:\" + args.message) } // return the result if (errors.length) { var errs = \"\u003cul\u003e\u003cli\u003e\" + errors.join(\"\u003c/li\u003e\u003cli\u003e\") + \"\u003c/li\u003e\u003c/ul\u003e\" return { body: \"\u003ch1\u003eErrors!\u003c/h1\u003e\" + errs + '\u003cbr\u003e\u003ca href=\"javascript:window.history.back()\"\u003eBack\u003c/a\u003e' } } else { var data = \"\u003cpre\u003e\" + message.join(\"\\n\") + \"\u003c/pre\u003e\" return { body: \"\u003ch1\u003eThank you!\u003c/h1\u003e\" + data, name: args.name, email: args.email, phone: args.phone, message: args.message } } } ","categories":"","description":"Learn how to add form validation from front to back-end","excerpt":"Learn how to add form validation from front to back-end","ref":"/docs/tutorial/form-validation/","tags":"","title":"Form validation"},{"body":"Installation Overview This page provides an overview of the installation process.\nBefore installation Please ensure you have:\ndownloaded the installer satisfied the prerequisites configured your installation Core Installation Once you have completed the preparation steps, you can proceed with:\na local installation on your local machine a single server installation on a Linux server a clustered installation on a Kubernetes cluster. 💡 NOTE\nThe install process will notify nuvolaris creators with the type of installation (for example: clustered or server installation), no other info will be submitted. If you want to disable the notification, you can execute the following command before the setup command:\nops -config DO_NOT_NOTIFY_NUVOLARIS=1 Post installation After the installation, you can consult the development guide for informations how to reconfigure and update the system.\nSupport If something goes wrong, you can check:\nthe Troubleshooting page our online Forum ","categories":"","description":"","excerpt":"Installation Overview This page provides an overview of the …","ref":"/docs/installation/install/","tags":"","title":"Install OpenServerless"},{"body":"Cluster Installation This section describes how to install OpenServerless on a Kubernetes Cluster\nPrerequisites Before installing, you need to:\nProvision a Kubernetes Cluster\nConfigure the installation\ninstall Download and install OpenServerless CLI, ops.\nInstallation If you have a Kubernetes cluster directly accessible with its configuration, or you provisioned a cluster in some cloud using ops embedded tools, you just need to type:\nops setup cluster Sometimes the kubeconfig includes access to multiple Kubernetes instances, each one identified by a different \u003ccontext\u003e name. You can install the OpenServerless cluster in a specified \u003ccontext\u003e with:\nops setup cluster \u003ccontext\u003e Post Install Check the tutorial to learn how to use it.\nTo uninstall, execute the command:\nops setup cluster --uninstall ","categories":"","description":"Install OpenServerless on a Kubernetes Cluster","excerpt":"Install OpenServerless on a Kubernetes Cluster","ref":"/docs/installation/install/cluster/","tags":"","title":"Kubernetes cluster"},{"body":"Prerequisites to install OpenServerless in a Kubernetes cluster You can install OpenServerless in any Kubernetes cluster which satisfy some requirements.\nKubernetes clusters are available pre-built from a variety of cloud providers. We provide with our ops tool the commands to install a Kubernetes cluster ready for OpenServerless in the following environments:\nAmazon EKS\nAzure AKS\nGoogle GKE\nRedHat OpenShift\nYou can also provision a suitable cluster by yourself, in any cloud or on premises, ensuring the prerequites are satisfied.\nOnce provisioned, you will receive a configuration file to access the cluster, called kubeconfig.\nThis file should be placed in ~/.kube/config to give access to the cluster\nIf you have this file, you can check if you have access to the cluster with the command:\nops debug kube info You should see something like this:\nKubernetes control plane is running at https://xxxxxx.yyy.us-east-1.eks.amazonaws.com Once you have got access to the Kubernetes cluster, either installing one with out commands or provisioning one by yourself, you can proceed configuring the installation and then installing OpenServerless in the cluster.\n","categories":"","description":"Install OpenServerless in a Kubernetes cluster","excerpt":"Install OpenServerless in a Kubernetes cluster","ref":"/docs/installation/prereq/kubernetes/","tags":"","title":"Kubernetes Cluster"},{"body":"When working with serverless actions, data is supplied by adding parameters to the actions; these are in the parameter declared as an argument to the main serverless function. All data arrives this way and the values can be set in a few different ways. The first option is to supply parameters when an action or package is created (or updated). This approach is useful for data that stays the same on every execution, equivalent to environment variables on other platforms, or for default values that might be overridden at invocation time. The second option is to supply parameters when the action is invoked - and this approach will override any parameters already set.\nThis page outlines how to configure parameters when deploying packages and actions, and how to supply parameters when invoking an action. There is also information on how to use a file to store the parameters and pass the filename, rather than supplying each parameter individually on the command-line.\nPassing parameters to an action at invoke time Parameters can be passed to the action when it is invoked. These examples use JavaScript but all the other languages work the same way.\nUse parameters in the action. For example, create ‘hello.js’ file with the following content: function main(params) { return {payload: 'Hello, ' + params.name + ' from ' + params.place}; } The input parameters are passed as a JSON object parameter to the main function. Notice how the name and place parameters are retrieved from the params object in this example.\nUpdate the action so it is ready to use: nuv action update hello hello.js Parameters can be provided explicitly on the command-line, or by supplying a file containing the desired parameters To pass parameters directly through the command-line, supply a key/value pair to the --param flag: nuv action invoke --result hello --param name Dorothy --param place Kansas\nThis produces the result:\n{ \"payload\": \"Hello, Dorothy from Kansas\" } Notice the use of the --result option: it implies a blocking invocation where the CLI waits for the activation to complete and then displays only the result. For convenience, this option may be used without --blocking which is automatically inferred.\nAdditionally, if parameter values specified on the command-line are valid JSON, then they will be parsed and sent to your action as a structured object. For example, if we update our hello action to:\nfunction main(params) { return {payload: 'Hello, ' + params.person.name + ' from ' + params.person.place}; } Now the action expects a single person parameter to have fields name and place. If we invoke the action with a single person parameter that is valid JSON:\nnuv action invoke --result hello -p person '{\"name\": \"Dorothy\", \"place\": \"Kansas\"}' The result is the same because the CLI automatically parses the person parameter value into the structured object that the action now expects: json { \"payload\": \"Hello, Dorothy from Kansas\" }\nSetting default parameters on an action Actions can be invoked with multiple named parameters. Recall that the hello action from the previous example expects two parameters: the name of a person, and the place where they’re from.\nRather than pass all the parameters to an action every time, you can bind certain parameters. The following example binds the place parameter so that the action defaults to the place “Kansas”:\nUpdate the action by using the --param option to bind parameter values, or by passing a file that contains the parameters to --param-file (for examples of using files, see the section on working with parameter files). To specify default parameters explicitly on the command-line, provide a key/value pair to the param flag:\nnuv action update hello --param place Kansas Invoke the action, passing only the name parameter this time. nuv action invoke --result hello --param name Dorothy { \"payload\": \"Hello, Dorothy from Kansas\" } Notice that you did not need to specify the place parameter when you invoked the action. Bound parameters can still be overwritten by specifying the parameter value at invocation time.\nInvoke the action, passing both name and place values, and observe the output: nuv action invoke --result hello --param name Dorothy --param place \"Washington, DC\" { \"payload\": \"Hello, Dorothy from Washington, DC\" } Despite a parameter set on the action when it was created/updated, this is overridden by a parameter that was supplied when invoking the action.\nSetting default parameters on a package Parameters can be set at the package level, and these will serve as default parameters for actions unless:\nThe action itself has a default parameter.\nThe action has a parameter supplied at invoke time, which will always be the “winner” where more than one parameter is available.\nThe following example sets a default parameter of name on the MyApp package and shows an action making use of it.\nCreate a package with a parameter set: nuv package update MyApp --param name World Create an action in this package: function main(params) { return {payload: \"Hello, \" + params.name}; } nuv action update MyApp/hello hello.js Invoke the action, and observe the default package parameter in use: nuv action invoke --result MyApp/hello { \"payload\": \"Hello, World\" } # Working with parameter files\nIt’s also possible to put parameters into a file in JSON format, and then pass the parameters in by supplying the filename with the param-file flag. This works for both packages and actions when creating/updating them, and when invoking actions.\nAs an example, consider the very simple hello example from earlier. Using hello.js with this content: function main(params) { return {payload: 'Hello, ' + params.name + ' from ' + params.place}; } Update the action with the updated contents of hello.js: nuv action update hello hello.js Create a parameter file called parameters.json containing JSON-formatted parameters: { \"name\": \"Dorothy\", \"place\": \"Kansas\" } Use the parameters.json filename when invoking the action, and observe the output nuv action invoke --result hello --param-file parameters.json { \"payload\": \"Hello, Dorothy from Kansas\" } ","categories":"","description":"","excerpt":"When working with serverless actions, data is supplied by adding …","ref":"/docs/reference/entities/parameters/","tags":"","title":"Parameters"},{"body":"Provision a Linux Server in Google Cloud You can provision a server suitable to install OpenServerless in cloud provider Google Cloud Platform (GCP) as follows:\ninstall the GCloud CLI\nEnable Gcloud services\nconfigure GKE\nprovision a server\nretrieve the IP address to configure a DNS name\nOnce you have Linux server up and running you can proceed configuring and installing OpenServerless.\nInstalling the GCloud CLI Our cli ops uses under the hood the GCloud CLI version 2, so you need to dowload and install it following those instructions.\nOnce installed, ensure it is available on the terminal executing the following command:\ngcloud version you should receive something like this:\nGoogle Cloud SDK 443.0.0 beta 2023.08.11 bq 2.0.96 bundled-python3-unix 3.9.16 core 2023.08.11 gcloud-crc32c 1.0.0 gke-gcloud-auth-plugin 0.5.5 gsutil 5.25 Enabling gcloud services You need to enable the following permissions for Google Cloud\ngcloud services enable cloudresourcemanager.googleapis.com gcloud services enable dns.googleapis.com gcloud services enable iamcredentials.googleapis.com gcloud services enable iam.googleapis.com gcloud services enable servicemanagement.googleapis.com gcloud services enable serviceusage.googleapis.com gcloud services enable storage-api.googleapis.com gcloud services enable storage-component.googleapis.com gcloud services enable deploymentmanager.googleapis.com gcloud services enable resourcemanager.projects.delete Configuring GKE to provision a server Before you can provision a Linux server you have to configure AWS typing the command:\nops config gcloud The system will then ask the following questions:\n*** Please, specify GCloud Project Id and press enter. nuvolaris *** Please, specify GCloud Zone and press enter. To get a list of valid values use: gcloud compute zones list Just press enter for default [us-east1-d]: *** Please, specify GCloud virtual machine type and press enter. To get a list of valid values, use: gcloud compute machine-types list Just press enter for default [n2-standard-4]: *** Please, specify GCloud disk size in gigabyte and press enter. Just press enter for default [200]: *** Please, specify GCloud public SSH key and press enter. If you already have a public SSH key provide its path here. If you do not have it, generate a key pair with the following command: ssh-keygen The public key defaults to ~/.ssh/id_rsa.pub. Just press enter for default [/home/ubuntu/.ssh/id_rsa.pub]: Provision a server You can provision one or more servers using ops. The servers will use the parameters you have just configured.\nYou can create a new server with:\nops cloud gcloud vm-create \u003cserver-name\u003e ❗ IMPORTANT\nReplace \u003cserver-name\u003e with a name you choose, for example ops-server\nThe command will create a new server in Google Cloud with the parameters you specified in configuration.\nYou can also:\nlist servers you created with ops cloud gcloud vm-list\ndelete a server you created and you do not need anymore with ops cloud gcloud vm-delete \u003cserver-name\u003e\nRetrieve IP The server will be provisioned with an IP address assigned by Google Cloud.\nYou can read the IP address of your server with\nops cloud gcloud vm-getip \u003cserver-name\u003e You need this IP when configuring a DNS name for the server.\n","categories":"","description":"Prerequisites to install OpenServerless in Google Cloud","excerpt":"Prerequisites to install OpenServerless in Google Cloud","ref":"/docs/installation/prereq/server/gcp/","tags":"","title":"Server on GCP"},{"body":"Install K3S in a server You can install OpenServerless as described here, and you do not need to install any Kubernetes in it, as it is installed as part of the procedure. In this case it installs K3S.\nOr you can install K3S in advance, and then proceed configuring and then installing OpenServerless as in any other Kubernetes cluster.\nInstalling K3S in a server Before installing ensure you have satified the prerequisites, most notably:\nyou know the IP address or DNS name\nyour server operating system satisfies the K3S requirements\nyou have passwordless access with ssh\nyou have a user with passwordless sudo rights\nyou have opened the port 6443 in the firewall\nThen you can use the following subcommand to install in the server:\nops cloud k3s create SERVER=\u003cserver\u003e USERNAME=\u003cusername\u003e where \u003cserver\u003e is the IP address or DNS name to access the server, and \u003cusername\u003e is the user you use to access the server.\nThose pieces of information should have been provided when provisioning the server.\n❗ IMPORTANT\nIf you installed a Kubernetes cluster in the server this way, you should proceed installing OpenServerless as in a Kubernetes cluster, not as a server.\nThe installation retrieves also a Kubernetes configuration file, so you can proceed to installing it without any other step involved.\nAdditional Commands In addition to create the following subcommands are also available:\nops cloud k3s delete SERVER=\u003cserver\u003e USERNAME=\u003cusername\u003e: uninstall K3S from the server\nops cloud k3s kubeconfig SERVER=\u003cserver\u003e USERNAME=\u003cusername\u003e: retrieve the kubeconfig from the K3S server\nops cloud k3s info: some information about the server\nops cloud k3s status: status of the server\n","categories":"","description":"Prerequisites to install OpenServerless in K3S","excerpt":"Prerequisites to install OpenServerless in K3S","ref":"/docs/installation/prereq/server/k3s/","tags":"","title":"Install K3S"},{"body":"Welcome to Nuvolaris Developer guide.\nNuvolaris is based on Apache OpenWhisk and the documentation in this section is derived for the official OpenWhisk documentation.\nIn this sections we mostly document how to write actions (functions), the building blocks of OpenWhisk and Nuvolaris applications. There are also a few related entities for managing actions (packages, parameters etc) you also need to know.\nYou can write actions in a number of programming languages. Nuvolaris supports directly this list of programming languages. The list is expanding over the time.\nSee below for documentation related to:\nNuvolaris and OpenWhisk Entities\nNuvolaris Runtimes\nAdvanced Reference Documentation\nThere is also a tutorial and a development kit to build your own runtime for your favorite programming language.\n","categories":"","description":"OpenServerless Developer Guide","excerpt":"OpenServerless Developer Guide","ref":"/docs/reference/","tags":"","title":"Reference"},{"body":"Sequences You can combine actions into sequences and invoke them as a single action. Therefore, a sequence represents a logical junction between two or more actions, where each action is invoked in a specific order.\nCombine actions sequentially Suppose we want to describe an algorithm for preparing a pizza. We could prepare everything in a single action, creating it all in one go, from preparing the dough to adding all the ingredients and cooking it.\nWhat if you would like to edit only a specific part of your algorithm, like adding fresh tomato instead of classic, or reducing the amount of water in your pizza dough? Every time, you have to edit your main action to modify only a part.\nAgain, what if before returning a pizza you’d like to invoke a new action like “add basil,” or if you decide to refrigerate the pizza dough after preparing it but before cooking it?\nThis is where sequences come into play.\nCreate a file called preparePizzaDough.js\nfunction main(args) { let persons = args.howManyPerson; let flour = persons * 180; // grams let water = persons * 120; // ml let yeast = (flour + water) * 0.02; let pizzaDough = \"Mix \" + flour + \" grams of flour with \" + water + \" ml of water and add \" + yeast + \" grams of brewer's yeast\"; return { pizzaDough: pizzaDough, whichPizza: args.whichPizza, }; } Now, in a file cookPizza.js\nfunction main(args) { let pizzaDough = args.pizzaDough; let whichPizza = args.whichPizza; let baseIngredients = \"tomato and mozzarella\"; if (whichPizza === \"Margherita\") { return { result: \"Cook \" + pizzaDough + \" topped with \" + baseIngredients + \" for 3 minutes at 380°C\", }; } else if (whichPizza === \"Sausage\") { baseIngredients += \"plus sausage\"; return { result: \"Cook \" + pizzaDough + \" topped with \" + baseIngredients + \". Cook for 3 minutes at 380°C\", }; } } We have now split our code to prepare pizza into two different actions. When we need to edit only one action without editing everything, we can do it! Otherwise, we can now add new actions that can be invoked or not before cooking pizza (or after).\nLet’s try it.\nTesting the sequence First, create our two actions\nops action create preparePizzaDough preparePizzaDough.js ops action create cookPizza cookPizza.js Now, we can create the sequence:\nops action create pizzaSequence --sequence preparePizzaDough,cookPizza Finally, let’s invoke it\nops action invoke --result pizzaSequence -p howManyPerson 4 -p whichPizza \"Margherita\" { \"result\": \"Cook Mix 720 grams of flour with 480 ml of water and add 24 grams of brewer's yeast topped with tomato and mozzarella for 3 minutes at 380°C\" } Conclusion Now, thanks to sequences, our code is split correctly, and we are able to scale it more easily!\n","categories":"","description":"Combine actions in sequences","excerpt":"Combine actions in sequences","ref":"/docs/cli/entities/sequences/","tags":"","title":"Sequences"},{"body":"Use database Storing the Message in the Database We are ready to use the database that we enabled at the beginning of the tutorial.\nSince we are using a relational database, we need to create a table to store the contact data. We can do that by creating a new action called create-table.js in the packages/contact folder:\nconst { Client } = require('pg') async function main(args) { const client = new Client({ connectionString: args.dbUri }); const createTable = ` CREATE TABLE IF NOT EXISTS contacts ( id serial PRIMARY KEY, name varchar(50), email varchar(50), phone varchar(50), message varchar(300) ); ` // Connect to database server await client.connect(); console.log('Connected to database'); try { await client.query(createTable); console.log('Contact table created'); } catch (e) { console.log(e); throw e; } finally { client.end(); } } We just need to run this once, therefore it doesn’t need to be a web action. Here we can take advantage of the cron service we enabled! There are also a couple of console logs that we can check out.\nWith the cron scheduler you can annotate an action with 2 kinds of labels. One to make OpenServerless periodically invoke the action, the other to automatically execute an action once, on creation.\nLet’s create the action with the latter, which means annotating the action with autoexec true:\nops action create contact/create-table create-table.js -a autoexec true ok: created action contact/create-table With -a you can add “annotations” to an action. OpenServerless will invoke this action as soon as possible, so we can go on.\nIn OpenServerless an action invocation is called an activation. You can keep track, retrieve information and check logs from an action with ops activation. For example, with:\nops activation list You can retrieve the list of invocations. For caching reasons the first time you run the command the list might be empty. Just run it again and you will see the latest invocations (probably some hello actions from the deployment).\nIf we want to make sure create-table was invoked, we can do it with this command. The cron scheduler can take up to 1 minute to run an autoexec action, so let’s wait a bit and run ops activation list again.\nops activation list Datetime Activation ID Kind Start Duration Status Entity 2023-10-02 09:52:01 1f02d3ef5c32493682d3ef5c32b936da nodejs:18 cold 312ms success openserverless/create-table:0.0.1 .. Or we could run ops activation poll to listen for new logs.\nops activation poll Enter Ctrl-c to exit. Polling for activation logs When the logs from the create-table action appear, we can stop the command with Ctrl-c.\nEach activation has an Activation ID which can be used with other ops activation subcommands or with the ops logs command.\nWe can also check out the logs with either ops logs \u003cactivation-id\u003e or ops logs --last to quickly grab the last activation’s logs:\nops logs --last 2023-10-15T14:41:01.230674546Z stdout: Connected to database 2023-10-15T14:41:01.238457338Z stdout: Contact table created The Action to Store the Data We could just write the code to insert data into the table in the submit.js action, but it’s better to have a separate action for that.\nLet’s create a new file called write.js in the packages/contact folder:\nconst { Client } = require('pg') async function main(args) { const client = new Client({ connectionString: args.dbUri }); // Connect to database server await client.connect(); const { name, email, phone, message } = args; try { let res = await client.query( 'INSERT INTO contacts(name,email,phone,message) VALUES($1,$2,$3,$4)', [name, email, phone, message] ); console.log(res); } catch (e) { console.log(e); throw e; } finally { client.end(); } return { body: args.body, name, email, phone, message }; } Very similar to the create table action, but this time we are inserting data into the table by passing the values as parameters. There is also a console.log on the response in case we want to check some logs again.\nLet’s deploy it:\nops action create contact/write write.js ok: created action contact/write Finalizing the Submit Alright, we are almost done. We just need to create a pipeline of submit → write actions. The submit action returns the 4 form fields together with the HTML body. The write action expects those 4 fields to store them. Let’s put them together into a sequence:\nops action create contact/submit-write --sequence contact/submit,contact/write --web true ok: created action contact/submit-write With this command we created a new action called submit-write that is a sequence of submit and write. This means that OpenServerless will call in a sequence submit first, then get its output and use it as input to call write.\nNow the pipeline is complete, and we can test it by submitting the form again. This time the data will be stored in the database.\nNote that write passes on the HTML body so we can still see the thank you message. If we want to hide it, we can just remove the body property from the return value of write. We are still returning the other 4 fields, so another action can use them (spoiler: it will happen next chapter).\nLet’s check out again the action list:\nops action list actions /openserverless/contact/submit-write private sequence /openserverless/contact/write private nodejs:18 /openserverless/contact/create-table private nodejs:18 /openserverless/contact/submit private nodejs:18 You probably have something similar. Note the submit-write is managed as an action, but it’s actually a sequence of 2 actions. This is a very powerful feature of OpenServerless, as it allows you to create complex pipelines of actions that can be managed as a single unit.\nTrying the Sequence As before, we have to update our index.html to use the new action. First let’s get the URL of the submit-write action:\nops url contact/submit-write \u003capihost\u003e/api/v1/web/openserverless/contact/submit-write Then we can update the index.html file:\n--- \u003cform method=\"POST\" action=\"/api/v1/web/openserverless/contact/submit\" enctype=\"application/x-www-form-urlencoded\"\u003e \u003c-- old +++ \u003cform method=\"POST\" action=\"/api/v1/web/openserverless/contact/submit-write\" enctype=\"application/x-www-form-urlencoded\"\u003e \u003c-- new We just need to add -write to the action name.\nTry again to fill the contact form (with correct data) and submit it. This time the data will be stored in the database.\nIf you want to retrive info from you database, ops provides several utilities under the ops devel command. They are useful to interact with the integrated services, such as the database we are using.\nFor instance, let’s run:\nops devel psql sql \"SELECT * FROM CONTACTS\" [{'id': 1, 'name': 'OpenServerless', 'email': 'info@nuvolaris.io', 'phone': '5551233210', 'message': 'This is awesome!'}] ","categories":"","description":"Store data into a relational database","excerpt":"Store data into a relational database","ref":"/docs/tutorial/use-database/","tags":"","title":"Use database"},{"body":"Installation Overview If you are in hurry and you think this guide is TL;DR (too long, don’t read), please read at least our Quick Start single page installation guide.\nIt gives you an overview of the installation process, omitting some more advanced details. It can be enough to get you started and install OpenServerless.\nOnce you want to know more, you can come back.\nIf you instead want the read the full documentation first, please read on.\nSteps to follow OpenServerless can be installed in many environments, using our powerful command line interface ops.\nSo you should start downloading the CLI from this page.\nOnce you installed ops, before installing you need to check the prerequisites for the installation, and satisfy them\nIf the the prerequisites are OK, you can make your choices of what you want to Configure your OpenServerless installation.\nFinally, once you have:\ndownloaded ops\nsatisfied the prerequisites\nconfigured your installation\nyou can choose where to install, either:\nin your Local machine\nin a Linux server\nin a Kubernetes cluster\nPost Installation After the installation, you can change later the configuration and update the system.\nSupport If you have issues, please check:\nthe Troubleshooting page\nour Discussion forum\n","categories":"","description":"How to and where install OpenServerless","excerpt":"How to and where install OpenServerless","ref":"/docs/installation/","tags":"","title":"Installation"},{"body":"Using and creating packages In OpenWhisk and Nuvolaris, you can use packages to bundle together a set of related actions, and share them with others.\nA package can include actions and feeds. - An action is a piece of code that runs on OpenWhisk and Nuvolaris. For example, the Cloudant package includes actions to read and write records to a Cloudant database. - A feed is used to configure an external event source to fire trigger events. For example, the Alarm package includes a feed that can fire a trigger at a specified frequency.\nEvery OpenWhisk and Nuvolaris entity, including packages, belongs in a namespace, and the fully qualified name of an entity is /namespaceName[/packageName]/entityName. Refer to the naming guidelines for more information.\nThe following sections describe how to browse packages and use the triggers and feeds in them. In addition, if you are interested in contributing your own packages to the catalog, read the sections on creating and sharing packages.\nBrowsing packages Several packages are registered with OpenWhisk and Nuvolaris. You can get a list of packages in a namespace, list the entities in a package, and get a description of the individual entities in a package.\nGet a list of packages in the /nuvolaris namespace. $ nuv package list /nuvolaris packages /nuvolaris/openai private /nuvolaris/mastrogpt private /nuvolaris/examples private Get a list of entities in the /nuvolaris/openai package. $ nuv package get --summary /nuvolaris/openai package /nuvolaris/openai (parameters: none defined) action /nuvolaris/openai/models (parameters: none defined) action /nuvolaris/openai/chat (parameters: none defined) Note: Parameters listed under the package with a prefix * are predefined, bound parameters. Parameters without a * are those listed under the annotations for each entity. Furthermore, any parameters with the prefix ** are finalized bound parameters. This means that they are immutable, and cannot be changed by the user. Any entity listed under a package inherits specific bound parameters from the package. To view the list of known parameters of an entity belonging to a package, you will need to run a get --summary of the individual entity.\nGet a description of the /nuvolaris/openai/chat action. $ nuv action get --summary /nuvolaris/openai/chat action /nuvolaris/openai/chat: Returns a result based on parameters OPENAI_API_HOST and OPENAI_API_KEY (parameters: **OPENAI_API_HOST, **OPENAI_API_KEY) NOTE: Notice that the parameters listed for the action read were expanded upon from the action summary compared to the package summary above. To see the official bound parameters for actions and triggers listed under packages, run an individual get summary for the particular entity.\nCreating a package A package is used to organize a set of related actions and feeds. It also allows for parameters to be shared across all entities in the package.\nTo create a custom package with a simple action in it, try the following example:\nCreate a package called custom. $ nuv package create custom ok: created package custom Get a summary of the package. $ nuv package get --summary custom package /myNamespace/custom (parameters: none defined) Notice that the package is empty.\nCreate a file called identity.js that contains the following action code. This action returns all input parameters. function main(args) { return args; } Create an identity action in the custom package. $ nuv action create custom/identity identity.js ok: created action custom/identity Creating an action in a package requires that you prefix the action name with a package name. Package nesting is not allowed. A package can contain only actions and can’t contain another package.\nGet a summary of the package again. $ nuv package get --summary custom package /myNamespace/custom (parameters: none defined) action /myNamespace/custom/identity (parameters: none defined) You can see the custom/identity action in your namespace now.\nInvoke the action in the package. $ nuv action invoke --result custom/identity {} You can set default parameters for all the entities in a package. You do this by setting package-level parameters that are inherited by all actions in the package. To see how this works, try the following example:\nUpdate the custom package with two parameters: city and country. $ nuv package update custom --param city Austin --param country USA ok: updated package custom Display the parameters in the package and action, and see how the identity action in the package inherits parameters from the package. $ nuv package get custom ok: got package custom ... \"parameters\": [ { \"key\": \"city\", \"value\": \"Austin\" }, { \"key\": \"country\", \"value\": \"USA\" } ] ... $ nuv action get custom/identity ok: got action custom/identity ... \"parameters\": [ { \"key\": \"city\", \"value\": \"Austin\" }, { \"key\": \"country\", \"value\": \"USA\" } ] ... Invoke the identity action without any parameters to verify that the action indeed inherits the parameters. $ nuv action invoke --result custom/identity { \"city\": \"Austin\", \"country\": \"USA\" } Invoke the identity action with some parameters. Invocation parameters are merged with the package parameters; the invocation parameters override the package parameters. $ nuv action invoke --result custom/identity --param city Dallas --param state Texas { \"city\": \"Dallas\", \"country\": \"USA\", \"state\": \"Texas\" } Sharing a package After the actions and feeds that comprise a package are debugged and tested, the package can be shared with all OpenWhisk and Nuvolaris users. Sharing the package makes it possible for the users to bind the package, invoke actions in the package, and author OpenWhisk and Nuvolaris rules and sequence actions.\nShare the package with all users: $ nuv package update custom --shared yes ok: updated package custom Display the publish property of the package to verify that it is now true. $ nuv package get custom ok: got package custom ... \"publish\": true, ... Others can now use your custom package, including binding to the package or directly invoking an action in it. Other users must know the fully qualified names of the package to bind it or invoke actions in it. Actions and feeds within a shared package are public. If the package is private, then all of its contents are also private.\nGet a description of the package to show the fully qualified names of the package and action. $ nuv package get --summary custom package /myNamespace/custom: Returns a result based on parameters city and country (parameters: *city, *country) action /myNamespace/custom/identity (parameters: none defined) In the previous example, you’re working with the myNamespace namespace, and this namespace appears in the fully qualified name.\n","categories":"","description":"","excerpt":"Using and creating packages In OpenWhisk and Nuvolaris, you can use …","ref":"/docs/reference/entities/packages/","tags":"","title":"Packages"},{"body":"Sending notifications Contact notification It would be great if we receive a notification when an user tries to contact us. For this tutorial we will pick slack to receive a message when it happens.\nWe need to:\nhave a slack workspace where we can send messages;\ncreate a slack app that will be added to the workspace;\nactivate a webhook for the app that we can trigger from an action;\nCheck out the following scheme for the steps:\nOnce we have a webhook we can use to send messages we can proceed to create a new action called notify.js (in the packages/contact folder):\n// notify.js function main(args) { const { name, email, phone, message } = args; let text = `New contact request from ${name} (${email}, ${phone}):\\n${message}`; console.log(\"Built message\", text); return fetch(args.notifications, { method: 'POST', headers: { 'Content-Type': 'application/json', }, body: JSON.stringify({ text }), }) .then(response =\u003e { if (!response.ok) { console.log(\"Error sending message. Status code:\", response.status); } else { console.log(\"Message sent successfully\"); } return { body: args.body, }; }) .catch(error =\u003e { console.log(\"Error sending message\", error); return { body: error, }; }); } This action has the args.notifications parameter, which is the webhook. It also has the usual 4 form fields parameters that receives in input, used to build the text of the message. The action will return the body of the response from the webhook.\nWe’ve also put some logs that we can use for debugging purposes.\nLet’s first set up the action:\nops action create contact/notify notify.js -p notifications \u003cyour webhook\u003e ok: created action contact/notify We are already setting the notifications parameter on action creation, which is the webhook. The other one is the text that the submit action will give in input at every invocation.\nCreating Another Action Sequence We have developed an action that can send a Slack message as a standalone action, but we designed it to take the output of the submit action and return it as is. Time to extend the previous sequence!\nNote that it will send messages for every submission, even for incorrect inputs, so we will know if someone is trying to use the form without providing all the information. But we will only store the fully validated data in the database.\nLet’s create the sequence, and then test it:\nops action create contact/submit-notify --sequence contact/submit-write,contact/notify --web true ok: created action contact/submit-notify We just created a new sequence submit-notify from the previous sequence submit-write and the new notify.\nIf you want to get more info about this sequence, you can use the ops action get command:\nops action get contact/submit-notify { \"namespace\": \"openserverless/contact\", \"name\": \"submit-notify\", \"version\": \"0.0.1\", \"exec\": { \"kind\": \"sequence\", \"components\": [ \"/openserverless/contact/submit-write\", \"/openserverless/contact/notify\" ] }, ... } See how the exec key has a kind of sequence and a list of components that are the actions that compose the sequence.\nNow to start using this sequence instead of using the submit action, we need to update the web/index.html page to invoke the new sequence.\nAs before let’s grab the url:\nops url contact/submit-notify \u003capihost\u003e/api/v1/web/openserverless/contact/submit-notify And update the index.html:\n--- \u003cform method=\"POST\" action=\"/api/v1/web/openserverless/contact/submit-write\" enctype=\"application/x-www-form-urlencoded\"\u003e \u003c-- old +++ \u003cform method=\"POST\" action=\"/api/v1/web/openserverless/contact/submit-notify\" enctype=\"application/x-www-form-urlencoded\"\u003e \u003c-- new Don’t forget to re-upload the web folder with ops web upload web/.\nNow try to fill out the form again and press send! It will execute the sequence and you will receive the message from your Slack App.\nThe tutorial introduced you to some utilities to retrieve information and to the concept of activation. Let’s use some more commands to check out the logs and see if the message was really sent.\nThe easiest way to check for all the activations that happen in this app with all their logs is:\nops activation poll Enter Ctrl-c to exit. Polling for activation logs This command polls continuously for log messages. If you go ahead and submit a message in the app, all the actions will show up here together with their log messages.\nTo also check if there are some problems with your actions, run a couple of times ops activation list and check the Status of the activations. If you see some developer error or any other errors, just grab the activation ID and run ops logs \u003cactivation ID\u003e.\n","categories":"","description":"Sending notifications on user interaction","excerpt":"Sending notifications on user interaction","ref":"/docs/tutorial/notify-message/","tags":"","title":"Sending notifications"},{"body":"Triggers Now let’s see what a trigger is and how to use it.\nWe can define a trigger as an object representing an event source that triggers the execution of actions. When activated by an event, associated actions are executed.\nIn other words, a trigger is a mechanism that listens for specific events or conditions and initiates actions in response to those events. It acts as the starting point for a workflow.\nExample: Sending Slack Notifications Let’s consider a scenario where we want to send Slack notifications when users visit specific pages and submit a contact form.\nStep 1: Define the Trigger We create a trigger named “PageVisitTrigger” that listens for events related to user visits on our website. To create it, you can use the following command:\nops trigger create PageVisitTrigger Once the trigger is created, you can update it to add parameters, such as the page parameter:\nops trigger update PageVisitTrigger --param page homepage 💡 NOTE\nOf course, there are not only create and update, but also delete, and they work as expected, updating and deleting triggers. In the next paragraph, we will also see the fire command, which requires you to first create rules to do something useful.\nStep 2: Associate the Trigger with an Action Next, we create an action named “SendSlackNotification” that sends a notification to Slack when invoked. Then, we associate this action with our “PageVisitTrigger” trigger, specifying that it should be triggered when users visit certain pages.\nTo associate the trigger with an action, you can use the following command:\nops rule create TriggerRule PageVisitTrigger SendSlackNotification We’ll have a better understanding of this aspect in Rules\nIn this example, whenever a user visits either the homepage or the contact page, the “SendSlackNotification” action will be triggered, resulting in a Slack notification being sent.\nConclusion Triggers provide a flexible and scalable way to automate workflows based on various events. By defining triggers and associating them with actions, you can create powerful applications that respond dynamically to user interactions, system events, or any other specified conditions.\n","categories":"","description":"Event source that triggers an action execution","excerpt":"Event source that triggers an action execution","ref":"/docs/cli/entities/triggers/","tags":"","title":"Triggers"},{"body":"App Deployment Packaging the App With OpenServerless you can write a manifest file (in YAML) to have an easy way to deploy applications.\nIn this last chapter of the tutorial we will package the code to easily deploy the app, both frontend and actions.\nStart The Manifest File Let’s create a “manifest.yaml” file in the packages directory which will be used to describe the actions to deploy:\npackages: contact: actions: notify: function: contacts/notify.js web: true inputs: notifications: value: $NOTIFICATIONS This is the basic manifest file with just the notify action. At the top level we have the standard packages keyword, under which we can define the packages we want. Until now we created all of our actions in the contact package so we add it under packages.\nThen under each package, the actions keyword is needed so we can add our action custom names with the path to the code (with function). Finally we also add web: true which is equivalent to --web true when creating the action manually.\nFinally we used the inputs keyword to define the parameters to inject in the function.\nIf we apply this manifest file (we will see how soon), it will be the same as the previous ops action create contact/notify \u003cpath-to-notify.js\u003e -p notifications $NOTIFICATIONS --web true. You need to have the webhooks url in the NOTIFICATIONS environment variable.\nThe Submit Action The submit action is quite straightforward:\npackages: contact: actions: ... submit: function: contact/submit.js web: true The Database Actions Similarly to the notify and submit actions, let’s add to the manifest file the two actions for the database. We also need to pass as a package parameter the DB url, so we will use inputs key as before, but at the package level:\npackages: contact: inputs: dbUri: type: string value: $POSTGRES_URL actions: ... write: function: contact/write.js web: true create-table: function: contact/create-table.js annotations: autoexec: true Note the create-table action does not have the web set to true as it is not needed to be exposed to the world. Instead it just has the annotation for cron scheduler.\nThe Sequences Lastly, we created a sequence with submit and notify that we have to specify it in the manifest file as well.\npackages: contact: inputs: ... actions: ... sequences: submit-write: actions: submit, write web: true submit-notify: actions: submit-write, notify web: true We just have to add the sequences key at the contact level (next to actions) and define the sequences we want with the available actions.\nDeployment The final version of the manifest file is:\npackages: contact: inputs: dbUri: type: string value: $POSTGRES_URL actions: notify: function: contact/notify.js web: true inputs: notifications: value: $NOTIFICATIONS submit: function: contact/submit.js web: true write: function: contact/write.js web: true create-table: function: contact/create-table.js annotations: autoexec: true sequences: submit-write: actions: submit, write web: true submit-notify: actions: submit-write, notify web: true ops comes equipped with a handy command to deploy an app: ops project deploy.\nIt checks if there is a packages folder with inside a manifest file and deploys all the specified actions. Then it checks if there is a web folder and uploads it to the platform.\nIt does all what we did manually until now in one command.\nSo, from the top level directory of our app, let’s run (to also set the input env var):\nexport POSTGRES_URL=\u003cyour-postgres-url\u003e export NOTIFICATIONS=\u003cthe-webhook\u003e ops project deploy Packages and web directory present. Success: Deployment completed successfully. Found web directory. Uploading.. With just this command you deployed all the actions (and sequences) and uploaded the frontend (from the web folder).\n","categories":"","description":"Learn how to deploy your app on Apache Openserverless","excerpt":"Learn how to deploy your app on Apache Openserverless","ref":"/docs/tutorial/packaging/","tags":"","title":"App Deployment"},{"body":"Implementing feeds OpenWhisk and Nuvolaris support an open API, where any user can expose an event producer service as a feed in a package. This section describes architectural and implementation options for providing your own feed.\nThis material is intended for advanced OpenWhisk and Nuvolaris users who intend to publish their own feeds. Most OpenWhisk and Nuvolaris users can safely skip this section.\nFeed Architecture There are at least 3 architectural patterns for creating a feed: Hooks, Polling and Connections.\nHooks In the Hooks pattern, we set up a feed using a webhook facility exposed by another service. In this strategy, we configure a webhook on an external service to POST directly to a URL to fire a trigger. This is by far the easiest and most attractive option for implementing low-frequency feeds.\nPolling In the Polling pattern, we arrange for an OpenWhisk and Nuvolaris action to poll an endpoint periodically to fetch new data. This pattern is relatively easy to build, but the frequency of events will of course be limited by the polling interval.\nConnections In the Connections pattern, we stand up a separate service somewhere that maintains a persistent connection to a feed source. The connection based implementation might interact with a service endpoint via long polling, or to set up a push notification.\nDifference between Feed and Trigger Feeds and triggers are closely related, but technically distinct concepts.\nOpenWhisk and Nuvolaris process events which flow into the system.\nA trigger is technically a name for a class of events. Each event belongs to exactly one trigger; by analogy, a trigger resembles a topic in topic-based pub-sub systems. A rule T → A means “whenever an event from trigger T arrives, invoke action A with the trigger payload.\nA feed is a stream of events which all belong to some trigger T. A feed is controlled by a feed action which handles creating, deleting, pausing, and resuming the stream of events which comprise a feed. The feed action typically interacts with external services which produce the events, via a REST API that manages notifications.\nImplementing Feed Actions The feed action is a normal OpenWhisk and Nuvolaris action, but it should accept the following parameters: * lifecycleEvent: one of ‘CREATE’, ‘READ’, ‘UPDATE’, ‘DELETE’, ‘PAUSE’, or ‘UNPAUSE’. * triggerName: the fully-qualified name of the trigger which contains events produced from this feed. * authKey: the Basic auth credentials of the OpenWhisk and Nuvolaris user who owns the trigger just mentioned.\nThe feed action can also accept any other parameters it needs to manage the feed. For example the cloudant changes feed action expects to receive parameters including `dbname’, `username’, etc.\nWhen the user creates a trigger from the CLI with the –feed parameter, the system automatically invokes the feed action with the appropriate parameters.\nFor example, assume the user has created a mycloudant binding for the cloudant package with their username and password as bound parameters. When the user issues the following command from the CLI:\nnuv trigger create T --feed mycloudant/changes -p dbName myTable\nthen under the covers the system will do something equivalent to:\nnuv action invoke mycloudant/changes -p lifecycleEvent CREATE -p triggerName T -p authKey \u003cuserAuthKey\u003e -p password \u003cpassword value from mycloudant binding\u003e -p username \u003cusername value from mycloudant binding\u003e -p dbName mytype\nThe feed action named changes takes these parameters, and is expected to take whatever action is necessary to set up a stream of events from Cloudant, with the appropriate configuration, directed to the trigger T.\nFor the Cloudant changes feed, the action happens to talk directly to a cloudant trigger service we’ve implemented with a connection-based architecture. We’ll discuss the other architectures below.\nA similar feed action protocol occurs for nuv trigger delete, nuv trigger update and nuv trigger get.\nImplementing Feeds with Hooks It is easy to set up a feed via a hook if the event producer supports a webhook/callback facility.\nWith this method there is no need to stand up any persistent service outside of OpenWhisk and Nuvolaris. All feed management happens naturally though stateless OpenWhisk and Nuvolaris feed actions, which negotiate directly with a third part webhook API.\nWhen invoked with CREATE, the feed action simply installs a webhook for some other service, asking the remote service to POST notifications to the appropriate fireTrigger URL in OpenWhisk and Nuvolaris.\nThe webhook should be directed to send notifications to a URL such as:\nPOST /namespaces/{namespace}/triggers/{triggerName} The form with the POST request will be interpreted as a JSON document defining parameters on the trigger event. OpenWhisk and Nuvolaris rules pass these trigger parameters to any actions to fire as a result of the event.\nImplementing Feeds with Polling It is possible to set up an OpenWhisk and Nuvolaris action to poll a feed source entirely within OpenWhisk and Nuvolaris, without the need to stand up any persistent connections or external service.\nFor feeds where a webhook is not available, but do not need high-volume or low latency response times, polling is an attractive option.\nTo set up a polling-based feed, the feed action takes the following steps when called for CREATE:\nThe feed action sets up a periodic trigger (T) with the desired frequency, using the whisk.system/alarms feed.\nThe feed developer creates a pollMyService action which simply polls the remote service and returns any new events.\nThe feed action sets up a rule T → pollMyService.\nThis procedure implements a polling-based trigger entirely using OpenWhisk and Nuvolaris actions, without any need for a separate service.\nImplementing Feeds via Connections The previous 2 architectural choices are simple and easy to implement. However, if you want a high-performance feed, there is no substitute for persistent connections and long-polling or similar techniques.\nSince OpenWhisk and Nuvolaris actions must be short-running, an action cannot maintain a persistent connection to a third party . Instead, we must stand up a separate service (outside of OpenWhisk and Nuvolaris) that runs all the time. We call these provider services. A provider service can maintain connections to third party event sources that support long polling or other connection-based notifications.\nThe provider service should provide a REST API that allows the OpenWhisk and Nuvolaris feed action to control the feed. The provider service acts as a proxy between the event provider and OpenWhisk and Nuvolaris – when it receives events from the third party, it sends them on to OpenWhisk and Nuvolaris by firing a trigger.\nThe connection-based architecture is the highest performance option, but imposes more overhead on operations compared to the polling and hook architectures.\n","categories":"","description":"","excerpt":"Implementing feeds OpenWhisk and Nuvolaris support an open API, where …","ref":"/docs/reference/entities/feeds/","tags":"","title":"Feeds"},{"body":"Rules Once we have a trigger and some actions, we can create rules for the trigger. A rule connects the trigger with an action, so if you fire the trigger, it will invoke the action. Let’s see this in practice in the next listing.\nCreate data First of all, create a file called alert.js.\nfunction main() { console.log(\"Suspicious activity!\"); return { result: \"Suspicious activity!\" }; } Then, create a OpenServerless action for this file:\nops action create alert alert.js Now, create a trigger that we’ll call notifyAlert:\nops trigger create notifyAlert Now, all is ready, and now we can create our rule! The syntax follows this pattern: “ops rule create {ruleName} {triggerName} {actionName}”.\nops rule create alertRule notifyAlert alert Test your rule Our environment can now be alerted if something suspicious occurs! Before starting, let’s open another terminal window and enable polling (with the command ops activation poll) to see what happens.\n$ ops activation poll Enter Ctrl-c to exit. Polling for activation logs It’s time to fire the trigger!\n$ ops trigger fire notifyAlert ok: triggered /notifyAlert with id 86b8d33f64b845f8b8d33f64b8f5f887 Now, go to see the result! Check the terminal where you are polling activations now!\nEnter Ctrl-c to exit. Polling for activation logs Activation: 'alert' (dfb43932d304483db43932d304383dcf) [ \"2024-02-20T03:15.15472494535Z stdout: Suspicious activity!\" ] Conclusion 💡 NOTE\nAs with all the other commands, you can execute list, update, and delete by name.\nA trigger can enable multiple rules, so firing one trigger actually activates multiple actions. Rules can also be enabled and disabled without removing them. As in the last example, let’s try to disable the first rule and fire the trigger again to see what happens.\n$ ops rule disable alertRule ok: disabled rule alertRule $ ops trigger fire notifyAlert ok: triggered /_/notifyAlert with id 0f4fa69d910f4c738fa69d910f9c73af Disabling the rule.\nFiring the trigger again.\nIn the activation polling window, we can see that no action is executed now. Of course, we can enable the rule again with:\nops rule enable alertRule ","categories":"","description":"Connection rules between triggers and actions","excerpt":"Connection rules between triggers and actions","ref":"/docs/cli/entities/rules/","tags":"","title":"Rules"},{"body":" OpenServerless is a complex project. It has a lot of moving parts and relies heavily on Kubernetes.\nThere are many subprojects, and each subproject has a complex set of dependencies. Setting up all those dependencies is usually complex and time consuming.\nI have worked in a project where it used to take literally a couple of days to get everything ready to code. Also, you were never sure that everything was set up correctly because the dependencies were constantly changing.\nFor this reason, we have made a special effort to provide an easy and consistent way to have a standardized development environment for OpenServerless.\nThe Development Virtual Machine We considered a few options for setting up the development environment.\nThe first option is of course a setup script, but since you may be working on Linux, Windows or Mac, this approach turns out to be difficult and fragile.\nThe second option is to use Docker, and indeed for a while we used a Docker image in DevContainer format as our development environment. We also set up a Kubernetes development cluster using Kind, that is, “Kubernetes-in-Docker”.\nHowever, this approach proved to be slow and with a number of problems related to Docker. So we gradually moved to using a full virtual machine. And this is the approach we are taking with OpenServerless.\nThe development environment is a virtual machine initialized with a cloud-init script. Cloud-init is a standard for initializing a virtual machine in the cloud.\nUsing this cloud-init script you can actually run a developmnt environment basically in any cloud provider, if you want a shared one.\nOr, if you want to use your local machine, assuming you have at least 16GB of memory, you can launch the VM and initialize it with Cloud-Init in Linux, Windows and Mac using multipass.\nTHe README of Apache OpenServerless is indeed entirely devoted to setup the development virtual machine with Multipass and Cloud-Init.\nWhat is in the development machine? Using this cloud-init script, you can actually run a development environment in basically any cloud provider if you want a shared one.\nOr if you want to use your local machine, assuming you have at least 16GB of memory, you can start the VM and initialize it with cloud-init in Linux, Windows and Mac using multipass.\nThe README for [Apache OpenServerless] (https://github.com/apache/openserverless) is actually entirely devoted to setting up the development virtual machine with Multipass and Cloud-Init.\nWhat is in the development machine? The development machine is actually packed with goodies. For a start, it includes Kubernetes in the form of K3S, a lightweight but full-featured version of Kubernetes. Well, technically, K3S is an API-compatible, work-alike sister re-implementation of Kubernetes, but for all practical purposes, it IS Kubernetes.\nBut we need more than Kubernetes. We have a number of subprojects, and for each one, there’s a different set of tools and programming languages that need to be set up. We used to have a script to setup these dependencies, but since it turned out to be tedious to update, we switched to using [the package manager Nix] (https://nixos.org/download/). This is a tool that allows you to set up development environments (actually any environment) declaratively by writing a script shell.nix, the Nix language that defines the development environment. The virtual machines also include nix, and also a tool called direnv to automatically configure nix, calling a different shell.nix every time you change a directory.\nLast but not least, we use VSCode as it provides remote development features and allows you to work in the virtual machine as if it were a local folder. Instructions for setting up VSCode to use the virtual machine are provided in the README.\nIt is also worth mentioning that since we use task a build tool everywhere, we included it in the VM. There is also a license manager license-eye to ensure that all files are properly licensed under the Apache license.\n","categories":"","description":"Our first code drop is available: the development environment!\n","excerpt":"Our first code drop is available: the development environment!\n","ref":"/blog/2024/07/12/assembling-the-lab-for-openserverless/","tags":"","title":"Assembling the lab for OpenServerless"},{"body":"The Apache OpenServerless project’s goal is to build a serverless distribution that runs in all major flavors of Kubernetes in public and private clouds, and in any virtual machine running Linux in any cloud. It is not just a serverless engine, but a complete set of integrated tools to easily build cloud-native applications, with a focus on building AI applications.\nSpecifically, we are building on top of Apache OpenWhisk, which includes Apache Kafka and Apache CouchDB as components, adding Apache APISix as an API gateway, and a set of custom runtimes.\nWe have a Kubernetes operator to manage all the components, and a rich CLI to support installation and development.\nWe have a strong focus on development tools: the system includes support for developing full-stack applications in web-based IDEs using the DevContainer standard, with built-in full-stack hot reload (both backend and front-end).\nWe will have a set of starters that support the development of AI applications based on LLM. Furthermore, since many AI applications are basically a coreography of functions, something well supported in the serverless world, we will have a workflow generator to easily develop applications.\nThe project is already running at the Apache Software Foundation and we are in the process of migrating the contributed code base.\nOur home is https://github.com/apache/openserverless\nJoin us by subscribing to our mailing list sending an email to\ndev-subscribe@openserverless.apache.org ","categories":"","description":"The project Apache OpenServerless is now active\n","excerpt":"The project Apache OpenServerless is now active\n","ref":"/blog/2024/07/09/apache-openserverless-started/","tags":"","title":"Apache OpenServerless started"},{"body":"We are in the process of submitting thr open source codebase of Nuvolaris Community, to the Apache Software Foundation as an Apache project, and our proposed name is Apache OpenServerless.\nThe name is excellent because it conveys what the project is: a complete serverless environment for running cloud-native applications anywhere.We have already written the proposal and found our champions and mentors.\nBut before we voted the project in the Incubator PMC, we wanted to make sure that the chosen name was available.There was some concern because the name “serverless” is already trademarked, although we found that combinations using the name “serverless” are disjointly trademarked, so it should work.\nTo resolve this, we initiated research with the Apache Trademark team to be sure the nome was usable. The research took some time, but the result was: approved!So now we are ready to vote and get the process approved by the community and start building the next standard in the open source world: Apache OpenServerless!\n","categories":"","description":"The name Apache OpenServerless has been approved by the Apache Software Foundation! \n","excerpt":"The name Apache OpenServerless has been approved by the Apache …","ref":"/blog/2024/06/20/the-name-openserverless-was-approved/","tags":"","title":"The Name OpenServerless Was Approved"},{"body":"It is official! Apache OpenServerless is now an incubating project at the Apache Software Foundation! The result of the vote was positive and this is the email announcing the result of the vote on the Incubator Mailing List.\nFrom: Jean-Baptiste Onofré Date: Tuesday 18 June 2024 16:20:06 BST Subject: [RESULT][VOTE] Accept OpenServerless into the ASF incubator Hi folks, this vote passed with the following result: +1 (binding): Francis Chuang, PJ Fanning, Yu Xiao, Duo Zhang, Bertrand Delacretaz, Zhongyi Tan, Zhang Yonglun, Charles Zhang, Enrico Olivelli, Dave Fisher, François Papon, Roman Shaposhnik, Yu Li, Calvin Kirs +1 (non binding): ZhangJian He, Nicolò Boschi, likeho Thanks all for your vote ! Regards JB ","categories":"","description":"OpenServerless is now incubating at the Apache Software Foundation!\n","excerpt":"OpenServerless is now incubating at the Apache Software Foundation!\n","ref":"/blog/2024/06/18/project-accepted-for-incubation/","tags":"","title":"Project Accepted for Incubation!"},{"body":"Hello everyone, we are happy to announce that we submitted the OpenServerless project to the Apache Software Foundation. We are going to develop our Nuvolaris Community into a worldwide open source project at the highest level.\nThe goal is to provide the open source foundation of our Nuvolaris Enterprise product as a vendor independent and stable project maintained by a community.\nTo achieve this goal, we have submitted the Apache OpenServerless proposal is the natual step. The link to the proposal can be found here.\nOur codebase is well tested and already has a number of paying and open source customers. We already have a network of contributors who have already contributed to the codebase and we have found the mentors for our project and the champion for the project.\nBut what is the Nuvolaris community (to become Apache OpenServerless)? There is already an open source serverless engine (Apache OpenWhisk) and I am one of the PMC of the project and also wrote an O’Reilly book about it: Learning Apache OpenWhisk.\nWhat is missing now is a complete distribution including integrated services to build a complete platform. We want the Apache OpenServerless project to fill this gap.\nWith Nuvolaris Community we provide storage, databases, caches, frontend, IDE, starters and even LLM support on top of OpenWhisk. We have made this available and running on all major cloud provider Kubernetes platforms (EKS, AKS, GKE, LKE) and also for the Kubernetes of all major Linux distributions (RedHat OpenShift, Ubuntu MicroK8S, SuSE K3S).\nSimply put, if OpenWhisk is Linux, then Nuvolaris is RedHat. The OpenServerless project aims to be the first complete open source distribution that makes it easy to build cloud-native applications with portability in mind.\nAnd we want to build the platform in the open, contributing our work to the Apache Software Foundation to make it widely available and get more vendors involved in supporting it.\n","categories":"","description":"We are submitting the OpenServerless project to the Apache Software Foundation\n","excerpt":"We are submitting the OpenServerless project to the Apache Software …","ref":"/blog/2024/06/10/openserverless-proposal-submitted/","tags":"","title":"OpenServerless Proposal Submitted"},{"body":" About Apache OpenServerless A complete Serverless Development Environment for Any Cloud and Any Kubernetes\nManaged by a Kubernetes Operator\nA super-powered CLI extensible with plugins\nBuilt around Apache OpenWhisk, a production-ready and widely deployed serverless engine providing all the patterns and best practices for scalable cloud-native applications. Available everywhere\n","categories":"","description":"","excerpt":" About Apache OpenServerless A complete Serverless Development …","ref":"/about/","tags":"","title":"About Apache OpenServerless"},{"body":"Nuvolaris CLI Nuvolaris offers a powerful command line interface named nuv which extends and embeds the OpenWhisk wsk.\nYou can download it from here.\nWe can see here some advanced uses of nuv.\nNuvolaris access is usually configure logging into it with the nuv -login.\nYou can also configure access directly using the nuv -wsk command.\nThere are two required properties to configure:\nAPI host (name or IP address) for the OpenWhisk and Nuvolaris deployment you want to use.\nAuthorization key (username and password) which grants you access to the OpenWhisk and Nuvolaris API.\nThe API host ia the installationj host, the one you configure in installation with nuv config apihost\nnuv -wsk property set --apihost \u003copenwhisk_baseurl\u003e If you know your authorization key, you can configure the CLI to use it. Otherwise, you will need to obtain an authorization key for most CLI operations. The API key is visible in the file ~/.wskprops after you perform a nuv -login. This file can be sourced to be read as environment variables.\nsource ~/.wskprops nuv -wsk property set --auth $AUTH Tip: The OpenWhisk and Nuvolaris CLI stores properties in the ~/.wskprops configuration file by default. The location of this file can be altered by setting the WSK_CONFIG_FILE environment variable.\nThe required properties described above have the following keys in the .wskprops file:\nAPIHOST - Required key for the API host value.\nAUTH - Required key for the Authorization key.\nTo verify your CLI setup, try nuv action list.\nConfigure the CLI to use an HTTPS proxy The CLI can be setup to use an HTTPS proxy. To setup an HTTPS proxy, an environment variable called HTTPS_PROXY must be created. The variable must be set to the address of the HTTPS proxy, and its port using the following format: {PROXY IP}:{PROXY PORT}.\nConfigure the CLI to use client certificate The CLI has an extra level of security from client to apihost, system provides default client certificate configuration which deployment process generated, then you can refer to below steps to use client certificate:\nnuv -wsk property set --cert \u003cclient_cert_path\u003e --key \u003cclient_key_path\u003e ","categories":"","description":"","excerpt":"Nuvolaris CLI Nuvolaris offers a powerful command line interface named …","ref":"/docs/reference/references/advanced-cli/","tags":"","title":"Advanced CLI"},{"body":"Prerequisites to install OpenServerless in an Amazon EKS Cluster Amazon EKS is a pre-built Kubernetes cluster offered by the cloud provider Amazon Web Services.\nYou can create an EKS Cluster in Amazon AWS for installing using OpenServerless using ops as follows:\ninstall aws, the AWS CLI\nget Access and Secret Key\nconfigure EKS\nprovision EKS\noptionally, retrieve the load balancer address to configure a DNS name\nOnce you have EKS up and running you can proceed configuring and installing OpenServerless.\nInstalling the AWS CLI Our cli ops uses under the hood the AWS CLI version 2, so you need to dowload and install it following those instructions.\nOnce installed, ensure it is available on the terminal executing the following command:\naws --version you should receive something like this:\naws-cli/2.9.4 Python/3.9.11 Linux/5.19.0-1025-aws exe/x86_64.ubuntu.22 prompt/off Ensure the version is at least 2.\nGetting the Access and Secret key Next step is to retrieve credentials, in the form of an access key and a secret key.\nSo you need to: * access the AWS console following those instructions create an access key and secret key, * give to the credentials the minimum required permissions as described here to build an EKS cluster.\nYou will end up with a couple of string as follows:\nSample AWS Access Key ID: AKIAIOSFODNN7EXAMPLE Sample AWS Secret Access Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY Take note of them as you need them for configuring out CLI.\nConfiguring Amazon EKS Once you have the access and secret key you can configure EKS with the command ops config eks answering to all the questions, as in the following example:\n$ ops config eks *** Please, specify AWS Access Id and press enter. AKIAIOSFODNN7EXAMPLE *** Please, specify AWS Secret Key and press enter. wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY *** Please, specify AWS Region to use and press enter. To get a list of valid values use: aws ec2 describe-regions --output table Just press enter for default [us-east-2]: *** Please, specify AWS public SSH key and press enter. If you already have a public SSH key in AWS, provide its name here. If you do not have it, generate a key pair with the following command: ssh-keygen The public key defaults to ~/.ssh/id_rsa.pub and you can import with: aws ec2 import-key-pair --key-name nuvolaris-key --public-key-material --region=\u003cyour-region\u003e fileb://~/.ssh/id_rsa.pub Just press enter for default [nuvolaris-key]: *** Please, specify EKS Name for Cluster and Node Group and press enter. Just press enter for default [nuvolaris]: *** Please, specify EKS region and press enter. To get a list of valid values use: aws ec2 describe-regions --output table Just press enter for default [us-east-1]: *** Please, specify EKS number of worker nodes and press enter. Just press enter for default [3]: *** Please, specify EKS virtual machine type and press enter. To get a list of valid values, use: aws ec2 describe-instance-types --query 'InstanceTypes[].InstanceType' --output table Just press enter for default [m5.xlarge]: *** Please, specify EKS disk size in gigabyte and press enter. Just press enter for default [50]: *** Please, specify EKS Kubernetes Version and press enter. Just press enter for default [1.25]: Provisioning Amazon EKS Once you have configured it, you can create the EKS cluster with the command:\nops cloud eks create It will take around 20 minutes to be ready. Please be patient.\nAt the end of the process, you will have access directly to the created Kubernetes cluster for installation.\nRetrieving the Load Balancer DNS name Once the cluster is up and running, you need to retrieve the DNS name of the load balancer.\nYou can read this with the command:\nops cloud eks lb Take note of the result as it is required for configuring a dns name for your cluster.\nAdditional Commands You can delete the created cluster with: ops cloud eks delete\nYou can extract again the cluster configuration, if you lose it, reconfiguring the cluster and then using the command ops cloud eks kubeconfig.\n","categories":"","description":"Prerequisites for Amazon EKS","excerpt":"Prerequisites for Amazon EKS","ref":"/docs/installation/prereq/kubernetes/eks/","tags":"","title":"Amazon EKS"},{"body":"Annotations OpenWhisk and Nuvolaris actions, triggers, rules and packages (collectively referred to as assets) may be decorated with annotations. Annotations are attached to assets just like parameters with a key that defines a name and value that defines the value. It is convenient to set them from the command line interface (CLI) via --annotation or -a for short.\nRationale: Annotations were added to OpenWhisk and Nuvolaris to allow for experimentation without making changes to the underlying asset schema. We had, until the writing of this document, deliberately not defined what annotations are permitted. However as we start to use annotations more heavily to impart semantic changes, it’s important that we finally start to document them.\nThe most prevalent use of annotations to date is to document actions and packages. You’ll see many of the packages in the OpenWhisk and Nuvolaris catalog carry annotations such as a description of the functionality offered by their actions, which parameters are required at package binding time, and which are invoke-time parameters, whether a parameter is a “secret” (e.g., password), or not. We have invented these as needed, for example to allow for UI integration.\nHere is a sample set of annotations for an echo action which returns its input arguments unmodified (e.g., function main(args) { return args }). This action may be useful for logging input parameters for example as part of a sequence or rule.\nnuv action create echo echo.js \\ -a description 'An action which returns its input. Useful for logging input to enable debug/replay.' \\ -a parameters '[{ \"required\":false, \"description\": \"Any JSON entity\" }]' \\ -a sampleInput '{ \"msg\": \"Five fuzzy felines\"}' \\ -a sampleOutput '{ \"msg\": \"Five fuzzy felines\"}' The annotations we have used for describing packages are:\ndescription: a pithy description of the package\nparameters: an array describing parameters that are scoped to the package (described further below)\nSimilarly, for actions:\ndescription: a pithy description of the action\nparameters: an array describing actions that are required to execute the action\nsampleInput: an example showing the input schema with typical values\nsampleOutput: an example showing the output schema, usually for the sampleInput\nThe annotations we have used for describing parameters include:\nname: the name of the parameter\ndescription: a pithy description of the parameter\ndoclink: a link to further documentation for parameter (useful for OAuth tokens for example)\nrequired: true for required parameters and false for optional ones\nbindTime: true if the parameter should be specified when a package is bound\ntype: the type of the parameter, one of password, array (but may be used more broadly)\nThe annotations are not checked. So while it is conceivable to use the annotations to infer if a composition of two actions into a sequence is legal, for example, the system does not yet do that.\nThe following annotations on an action are available.\nprovide-api-key: This annotation may be attached to actions which require an API key, for example to make REST API calls to the OpenWhisk and Nuvolaris host. For newly created actions, if not specified, it defaults to a false value. For existing actions, the absence of this annotation, or its presence with a value that is not falsy (i.e., a value that is different from zero, null, false, and the empty string) will cause an API key to be present in the action execution context. Annotations specific to web actions Web actions are enabled with explicit annotations which decorate individual actions. The annotations only apply to the web actions API, and must be present and explicitly set to true to have an affect. The annotations have no meaning otherwise in the system. The annotations are:\nweb-export: Makes its corresponding action accessible to REST calls without authentication. We call these web actions because they allow one to use OpenWhisk and Nuvolaris actions from a browser for example. It is important to note that the owner of the web action incurs the cost of running them in the system (i.e., the owner of the action also owns the activations record). The rest of the annotations described below have no effect on the action unless this annotation is also set.\nfinal: Makes all of the action parameters that are already defined immutable. A parameter of an action carrying the annotation may not be overridden by invoke-time parameters once the parameter has a value defined through its enclosing package or the action definition.\nraw-http: When set, the HTTP request query and body parameters are passed to the action as reserved properties.\nweb-custom-options: When set, this annotation enables a web action to respond to OPTIONS requests with customized headers, otherwise a default CORS response applies.\nrequire-whisk-auth: This annotation protects the web action so that it is only invoked by requests that provide appropriate authentication credentials. When set to a boolean value, it controls whether or not the request’s Basic Authentication value (i.e. Whisk auth key) will be authenticated - a value of true will authenticate the credentials, a value of false will invoke the action without any authentication. When set to a number or a string, this value must match the request’s X-Require-Whisk-Auth header value. In both cases, it is important to note that the owner of the web action will still incur the cost of running them in the system (i.e., the owner of the action also owns the activations record).\nAnnotations specific to activations The system decorates activation records with annotations as well. They are:\npath: the fully qualified path name of the action that generated the activation. Note that if this activation was the result of an action in a package binding, the path refers to the parent package.\nbinding: the entity path of the package binding. Note that this is only present for actions in a package binding.\nkind: the kind of action executed, and one of the support OpenWhisk and Nuvolaris runtime kinds.\nlimits: the time, memory and log limits that this activation were subject to.\nAdditionally for sequence related activations, the system will generate the following annotations:\ntopmost: this is only present for an outermost sequence action.\ncausedBy: this is only present for actions that are contained in a sequence.\nLastly, and in order to provide you with some performance transparency, activations also record:\nwaitTime: the time spent waiting in the internal OpenWhisk and Nuvolaris system. This is roughly the time spent between the controller receiving the activation request and when the invoker provisioned a container for the action.\ninitTime: the time spent initializing the function. If this value is present, the action required initialization and represents a cold start. A warm activation will skip initialization, and in this case, the annotation is not generated.\nAn example of these annotations as they would appear in an activation record is shown below.\n\"annotations\": [ { \"key\": \"path\", \"value\": \"guest/echo\" }, { \"key\": \"waitTime\", \"value\": 66 }, { \"key\": \"kind\", \"value\": \"nodejs:6\" }, { \"key\": \"initTime\", \"value\": 50 }, { \"key\": \"limits\", \"value\": { \"logs\": 10, \"memory\": 256, \"timeout\": 60000 } } ] ","categories":"","description":"","excerpt":"Annotations OpenWhisk and Nuvolaris actions, triggers, rules and …","ref":"/docs/reference/entities/annotations/","tags":"","title":"Annotations"},{"body":" COMING SOON ","categories":"","description":"","excerpt":" COMING SOON ","ref":"/","tags":"","title":"Apache OpenServerless"},{"body":"Prerequisites to install OpenServerless in an Azure AKS Cluster Azure AKS is a pre-built Kubernetes cluster offered by the cloud provider Microsoft Azure.\nYou can create an AKS Cluster in Microsoft Azure for installing using OpenServerless using ops as follows:\ninstall az, the Azure CLI\nconfigure AKS\nprovision AKS\noptionally, retrieve the load balancer address to configure a DNS name\nOnce you have AKS up and running you can proceed configuring and installing OpenServerless.\nInstalling the Azure CLI Our CLI ops uses under the hood the Azure CLI, so you need to dowload and install it following those instructions.\nOnce installed, ensure it is available on the terminal executing the following command:\naz version you should receive something like this:\n{ \"azure-cli\": \"2.51.0\", \"azure-cli-core\": \"2.51.0\", \"azure-cli-telemetry\": \"1.1.0\", \"extensions\": {} } Configuring Azure AKS Before provisioning your AKS cluster you need to configure AKS with the command ops config aks answering to all the questions, as in the following example:\n$ ops config aks *** Please, specify AKS Name for Cluster and Resource Group and press enter. Just press enter for default [nuvolaris]: *** Please, specify AKS number of worker nodes and press enter. Just press enter for default [3]: *** Please, specify AKS location and press enter. To get a list of valid values use: az account list-locations -o table Just press enter for default [eastus]: *** Please, specify AKS virtual machine type and press enter. To get a list of valid values use: az vm list-sizes --location \u003clocation\u003e -o table where \u003clocation\u003e is your current location. Just press enter for default [Standard_B4ms]: *** Please, specify AKS disk size in gigabyte and press enter. Just press enter for default [50]: *** Please, specify AKS public SSH key in AWS and press enter. If you already have a public SSH key provide its path here. If you do not have it, generate a key pair with the following command: ssh-keygen The public key defaults to ~/.ssh/id_rsa.pub. Just press enter for default [~/.ssh/id_rsa.pub]: Provisioning Azure AKS Once you have configured it, you can create the AKS cluster with the command:\nops cloud aks create It will take around 10 minutes to be ready. Please be patient.\nAt the end of the process, you will have access directly to the created Kubernetes cluster for installation.\nRetrieving the Load Balancer DNS name Once the cluster is up and running, you need to retrieve the DNS name of the load balancer.\nYou can read this with the command:\nops cloud aks lb Take note of the result as it is required for configuring a dns name for your cluster.\nAdditional Commands You can delete the created cluster with: ops cloud aks delete\nYou can extract again the cluster configuration, if you lose it, reconfiguring the cluster and then using the command nuv cloud aks kubeconfig.\n","categories":"","description":"Prerequisites for Azure AKS","excerpt":"Prerequisites for Azure AKS","ref":"/docs/installation/prereq/kubernetes/aks/","tags":"","title":"Azure AKS"},{"body":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the blog section. It has two categories: News and Releases. …","ref":"/blog/","tags":"","title":"Blog"},{"body":"Developing a new Runtime with the ActionLoop proxy The OpenWhisk and Nuvolaris runtime specification defines the expected behavior of an OpenWhisk and Nuvolaris runtime; you can choose to implement a new runtime from scratch by just following this specification. However, the fastest way to develop a new, compliant runtime is by reusing the ActionLoop proxy which already implements most of the specification and requires you to write code for just a few hooks to get a fully functional (and fast) runtime in a few hours or less.\nWhat is the ActionLoop proxy The ActionLoop proxy is a runtime “engine”, written in the Go programming language, originally developed specifically to support the OpenWhisk and Nuvolaris Go language runtime. However, it was written in a generic way such that it has since been adopted to implement OpenWhisk and Nuvolaris runtimes for Swift, PHP, Python, Rust, Java, Ruby and Crystal. Even though it was developed with compiled languages in mind it works equally well with scripting languages.\nUsing it, you can develop a new runtime in a fraction of the time needed for authoring a full-fledged runtime from scratch. This is due to the fact that you have only to write a command line protocol and not a fully-featured web server (with a small amount of corner cases to consider). The results should also produce a runtime that is fairly fast and responsive. In fact, the ActionLoop proxy has also been adopted to improve the performance of existing runtimes like Python, Ruby, PHP, and Java where performance has improved by a factor between 2x to 20x.\nPrecompilation of OpenWhisk and Nuvolaris Actions In addition to being the basis for new runtime development, ActionLoop runtimes can also support offline “precompilation” of OpenWhisk and Nuvolaris Action source files into a ZIP file that contains only the compiled binaries which are very fast to start once deployed. More information on this approach can be found here: Precompiling Go Sources Offline which describes how to do this for the Go language, but the approach applies to any language supported by ActionLoop.\nTutorial - How to write a new runtime with the ActionLoop Proxy This section contains a stepwise tutorial which will take you through the process of developing a new ActionLoop runtime using the Ruby language as the example.\nGeneral development process The general procedure for authoring a runtime with the ActionLoop proxy requires the following steps:\nbuilding a docker image containing your target language compiler and the ActionLoop runtime.\nwriting a simple line-oriented protocol in your target language.\nwriting a compilation script for your target language.\nwriting some mandatory tests for your language.\nActionLoop Starter Kit To facilitate the process, there is an actionloop-starter-kit in the openwhisk-devtools GitHub repository, that implements a fully working runtime for Python. It contains a stripped-down version of the real Python runtime (with some advanced features removed) along with guided, step-by-step instructions on how to translate it to a different target runtime language using Ruby as an example.\nIn short, the starter kit provides templates you can adapt in creating an ActionLoop runtime for each of the steps listed above, these include :\n-checking out the actionloop-starter-kit from the openwhisk-devtools repository -editing the Dockerfile to create the target environment for your target language. -converting (rewrite) the launcher.py script to an equivalent for script for your target language. -editing the compile script to compile your action in your target language. -writing the mandatory tests for your target language, by adapting the ActionLoopPythonBasicTests.scala file.\nAs a starting language, we chose Python since it is one of the more human-readable languages (can be treated as pseudo-code). Do not worry, you should only need just enough Python knowledge to be able to rewrite launcher.py and edit the compile script for your target language.\nFinally, you will need to update the ActionLoopPythonBasicTests.scala test file which, although written in the Scala language, only serves as a wrapper that you will use to embed your target language tests into.\nNotation In each step of this tutorial, we typically show snippets of either terminal transcripts (i.e., commands and results) or “diffs” of changes to existing code files.\nWithin terminal transcript snippets, comments are prefixed with # character and commands are prefixed by the $ character. Lines that follow commands may include sample output (from their execution) which can be used to verify against results in your local environment.\nWhen snippets show changes to existing source files, lines without a prefix should be left “as is”, lines with - should be removed and lines with + should be added.\nPrerequisites Docker engine - please have a valid docker engine installed that supports multi-stage builds (i.e., Docker 17.05 or higher) and assure the Docker daemon is running. # Verify docker version $ docker --version Docker version 18.09.3 # Verify docker is running $ docker ps # The result should be a valid response listing running processes Setup the development directory So let’s start to create our own actionloop-demo-ruby-2.6 runtime. First, check out the devtools repository to access the starter kit, then move it in your home directory to work on it.\ngit clone https://github.com/apache/openwhisk-devtools mv openwhisk-devtools/actionloop-starter-kit ~/actionloop-demo-ruby-v2.6 Now, take the directory python3.7 and rename it to ruby2.6 and use sed to fix the directory name references in the Gradle build files.\ncd ~/actionloop-demo-ruby-v2.6 mv python3.7 ruby2.6 sed -i.bak -e 's/python3.7/ruby2.6/' settings.gradle sed -i.bak -e 's/actionloop-demo-python-v3.7/actionloop-demo-ruby-v2.6/' ruby2.6/build.gradle Let’s check everything is fine building the image.\n# building the image $ ./gradlew distDocker # ... intermediate output omitted ... BUILD SUCCESSFUL in 1s 2 actionable tasks: 2 executed # checking the image is available $ docker images actionloop-demo-ruby-v2.6 REPOSITORY TAG IMAGE ID CREATED SIZE actionloop-demo-ruby-v2.6 latest df3e77c9cd8f 2 minutes ago 94.3MB At this point, we have built a new image named actionloop-demo-ruby-v2.6. However, despite having Ruby in the name, internally it still is a Python language runtime which we will need to change to one supporting Ruby as we continue in this tutorial.\nPreparing the Docker environment Our language runtime’s Dockerfile has the task of preparing an environment for executing OpenWhisk and Nuvolaris Actions. Using the ActionLoop approach, we use a multistage Docker build to\nderive our OpenWhisk and Nuvolaris language runtime from an existing Docker image that has all the target language’s tools and libraries for running functions authored in that language.\nIn our case, we will reference the ruby:2.6.2-alpine3.9 image from the Official Docker Images for Ruby on Docker Hub. leverage the existing openwhisk/actionlooop-v2 image on Docker Hub from which we will “extract” the ActionLoop proxy (i.e. copy /bin/proxy binary) our runtime will use to process Activation requests from the OpenWhisk and Nuvolaris platform and execute Actions by using the language’s tools and libraries from step #1.\nRepurpose the renamed Python Dockerfile for Ruby builds Let’s edit the ruby2.6/Dockerfile to use the official Ruby image on Docker Hub as our base image, instead of a Python image, and add our our Ruby launcher script:\nFROM openwhisk/actionloop-v2:latest as builder -FROM python:3.7-alpine +FROM ruby:2.6.2-alpine3.9 RUN mkdir -p /proxy/bin /proxy/lib /proxy/action WORKDIR /proxy COPY --from=builder /bin/proxy /bin/proxy -ADD lib/launcher.py /proxy/lib/launcher.py +ADD lib/launcher.rb /proxy/lib/launcher.rb ADD bin/compile /proxy/bin/compile +RUN apk update \u0026\u0026 apk add python3 ENV OW_COMPILER=/proxy/bin/compile ENTRYPOINT [\"/bin/proxy\"] Next, let’s rename the launcher.py (a Python script) to one that indicates it is a Ruby script named launcher.rb.\nmv ruby2.6/lib/launcher.py ruby2.6/lib/launcher.rb Note that:\nYou changed the base Docker image to use a Ruby language image.\nYou changed the launcher script from Python to Ruby.\nWe had to add a python3 package to our Ruby image since our compile script will be written in Python for this tutorial. Of course, you may choose to rewrite the compile script in Ruby if you wish to as your own exercise.\nImplementing the ActionLoop protocol This section will take you through how to convert the contents of launcher.rb (formerly launcher.py) to the target Ruby programming language and implement the ActionLoop protocol.\nWhat the launcher needs to do Let’s recap the steps the launcher must accomplish to implement the ActionLoop protocol :\nimport the Action function’s main method for execution.\nNote: the compile script will make the function available to the launcher. open the system’s file descriptor 3 which will be used to output the functions response.\nread the system’s standard input, stdin, line-by-line. Each line is parsed as a JSON string and produces a JSON object (not an array nor a scalar) to be passed as the input arg to the function.\nNote: within the JSON object, the value key contains the user parameter data to be passed to your functions. All the other keys are made available as process environment variables to the function; these need to be uppercased and prefixed with \"__OW_\". invoke the main function with the JSON object payload.\nencode the result of the function in JSON (ensuring it is only one line and it is terminated with one newline) and write it to file descriptor 3.\nOnce the function returns the result, flush the contents of stdout, stderr and file descriptor 3 (FD 3).\nFinally, include the above steps in a loop so that it continually looks for Activations. That’s it.\nConverting launcher script to Ruby Now, let’s look at the protocol described above, codified within the launcher script launcher.rb, and work to convert its contents from Python to Ruby.\nImport the function code Skipping the first few library import statements within launcer.rb, which we will have to resolve later after we determine which ones Ruby may need, we see the first significant line of code importing the actual Action function.\n# now import the action as process input/output from main__ import main as main In Ruby, this can be rewritten as:\n# requiring user's action code require \"./main__\" Note that you are free to decide the path and filename for the function’s source code. In our examples, we chose a base filename that includes the word \"main\" (since it is OpenWhisk and Nuvolaris’s default function name) and append two underscores to better assure uniqueness.\nOpen File Descriptor (FD) 3 for function results output The ActionLoop proxy expects to read the results of invoking the Action function from File Descriptor (FD) 3.\nThe existing Python:\nout = fdopen(3, \"wb\") would be rewritten in Ruby as:\nout = IO.new(3) Process Action’s arguments from STDIN Each time the function is invoked via an HTTP request, the ActionLoop proxy passes the message contents to the launcher via STDIN. The launcher must read STDIN line-by-line and parse it as JSON.\nThe launcher’s existing Python code reads STDIN line-by-line as follows:\nwhile True: line = stdin.readline() if not line: break # ...continue... would be translated to Ruby as follows:\nwhile true # JSON arguments get passed via STDIN line = STDIN.gets() break unless line # ...continue... end Each line is parsed in JSON, where the payload is extracted from contents of the \"value\" key. Other keys and their values are as uppercased, \"__OW_\" prefixed environment variables:\nThe existing Python code for this is:\n# ... continuing ... args = json.loads(line) payload = {} for key in args: if key == \"value\": payload = args[\"value\"] else: os.environ[\"__OW_%s\" % key.upper()]= args[key] # ... continue ... would be translated to Ruby:\n# ... continuing ... args = JSON.parse(line) payload = {} args.each do |key, value| if key == \"value\" payload = value else # set environment variables for other keys ENV[\"__OW_#{key.upcase}\"] = value end end # ... continue ... Invoking the Action function We are now at the point of invoking the Action function and producing its result. Note we must also capture exceptions and produce an {\"error\": \u003cresult\u003e } if anything goes wrong during execution.\nThe existing Python code for this is:\n# ... continuing ... res = {} try: res = main(payload) except Exception as ex: print(traceback.format_exc(), file=stderr) res = {\"error\": str(ex)} # ... continue ... would be translated to Ruby:\n# ... continuing ... res = {} begin res = main(payload) rescue Exception =\u003e e puts \"exception: #{e}\" res [\"error\"] = \"#{e}\" end # ... continue ... Finalize File Descriptor (FD) 3, STDOUT and STDERR Finally, we need to write the function’s result to File Descriptor (FD) 3 and “flush” standard out (stdout), standard error (stderr) and FD 3.\nThe existing Python code for this is:\nout.write(json.dumps(res, ensure_ascii=False).encode('utf-8')) out.write(b'\\n') stdout.flush() stderr.flush() out.flush() would be translated to Ruby:\nSTDOUT.flush() STDERR.flush() out.puts(res.to_json) out.flush() Congratulations! You just completed your ActionLoop request handler.\nWriting the compilation script Now, we need to write the compilation script. It is basically a script that will prepare the uploaded sources for execution, adding the launcher code and generate the final executable.\nFor interpreted languages, the compilation script will only “prepare” the sources for execution. The executable is simply a shell script to invoke the interpreter.\nFor compiled languages, like Go it will actually invoke a compiler in order to produce the final executable. There are also cases like Java where we still need to execute the compilation step that produces intermediate code, but the executable is just a shell script that will launch the Java runtime.\nHow the ActionLoop proxy handles action uploads The OpenWhisk and Nuvolaris user can upload actions with the nuv Command Line Interface (CLI) tool as a single file.\nThis single file can be:\na source file\nan executable file\na ZIP file containing sources\na ZIP file containing an executable and other support files\nImportant: an executable for ActionLoop is either a Linux binary (an ELF executable) or a script. A script is, using Linux conventions, is anything starting with #!. The first line is interpreted as the command to use to launch the script: #!/bin/bash, #!/usr/bin/python etc.\nThe ActionLoop proxy accepts any file, prepares a work folder, with two folders in it named \"src\" and \"bin\". Then it detects the format of the uploaded file. For each case, the behavior is different.\nIf the uploaded file is an executable, it is stored as bin/exec and executed.\nIf the uploaded file is not an executable and not a zip file, it is stored as src/exec then the compilation script is invoked.\nIf the uploaded file is a zip file, it is unzipped in the src folder, then the src/exec file is checked.\nIf it exists and it is an executable, the folder src is renamed to bin and then again the bin/exec is executed.\nIf the src/exec is missing or is not an executable, then the compiler script is invoked.\nCompiling an action in source format The compilation script is invoked only when the upload contains sources. According to the description in the past paragraph, if the upload is a single file, we can expect the file is in src/exec, without any prefix. Otherwise, sources are spread the src folder and it is the task of the compiler script to find the sources. A runtime may impose that when a zip file is uploaded, then there should be a fixed file with the main function. For example, the Python runtime expects the file __main__.py. However, it is not a rule: the Go runtime does not require any specific file as it compiles everything. It only requires a function with the name specified.\nThe compiler script goal is ultimately to leave in bin/exec an executable (implementing the ActionLoop protocol) that the proxy can launch. Also, if the executable is not standalone, other files must be stored in this folder, since the proxy can also zip all of them and send to the user when using the pre-compilation feature.\nThe compilation script is a script pointed by the OW_COMPILER environment variable (you may have noticed it in the Dockerfile) that will be invoked with 3 parameters:\n\u003cmain\u003e is the name of the main function specified by the user on the nuv command line\n\u003csrc\u003e is the absolute directory with the sources already unzipped\nan empty \u003cbin\u003e directory where we are expected to place our final executables\nNote that both the \u003csrc\u003e and \u003cbin\u003e are disposable, so we can do things like removing the \u003cbin\u003e folder and rename the \u003csrc\u003e.\nSince the user generally only sends a function specified by the \u003cmain\u003e parameter, we have to add the launcher we wrote and adapt it to execute the function.\nImplementing the compile for Ruby This is the algorithm that the compile script in the kit follows for Python:\nif there is a \u003csrc\u003e/exec it must rename to the main file; I use the name main__.py\nif there is a \u003csrc\u003e/__main__.py it will rename to the main file main__.py\ncopy the launcher.py to exec__.py, replacing the main(arg) with \u003cmain\u003e(arg); this file imports the main__.py and invokes the function \u003cmain\u003e\nadd a launcher script \u003csrc\u003e/exec\nfinally it removes the \u003cbin\u003e folder and rename \u003csrc\u003e to \u003cbin\u003e\nWe can adapt this algorithm easily to Ruby with just a few changes.\nThe script defines the functions sources and build then starts the execution, at the end of the script.\nStart from the end of the script, where the script collect parameters from the command line. Instead of launcher.py, use launcher.rb:\n- launcher = \"%s/lib/launcher.py\" % dirname(dirname(sys.argv[0])) + launcher = \"%s/lib/launcher.rb\" % dirname(dirname(sys.argv[0])) Then the script invokes the source function. This function renames the exec file to main__.py, you will rename it instead to main__.rb:\n- copy_replace(src_file, \"%s/main__.py\" % src_dir) + copy_replace(src_file, \"%s/main__.rb\" % src_dir) If instead there is a __main__.py the function will rename to main__.py (the launcher invokes this file always). The Ruby runtime will use a main.rb as starting point. So the next change is:\n- # move __main__ in the right place if it exists - src_file = \"%s/__main__.py\" % src_dir + # move main.rb in the right place if it exists + src_file = \"%s/main.rb\" % src_dir Now, the source function copies the launcher as exec__.py, replacing the line from main__ import main as main (invoking the main function) with from main__ import \u003cmain\u003e as main. In Ruby you may want to replace the line res = main(payload) with res = \u003cmain\u003e(payload). In code it is:\n- copy_replace(launcher, \"%s/exec__.py\" % src_dir, - \"from main__ import main as main\", - \"from main__ import %s as main\" % main ) + copy_replace(launcher, \"%s/exec__.rb\" % src_dir, + \"res = main(payload)\", + \"res = %s(payload)\" % main ) We are almost done. We just need the startup script that instead of invoking python will invoke Ruby. So in the build function do this change:\nwrite_file(\"%s/exec\" % tgt_dir, \"\"\"#!/bin/sh cd \"$(dirname $0)\" -exec /usr/local/bin/python exec__.py +exec ruby exec__.rb \"\"\") For an interpreted language that is all. We move the src folder in the bin. For a compiled language instead, we may want to actually invoke the compiler to produce the executable.\nDebugging Now that we have completed both the launcher and compile scripts, it is time to test them.\nHere we will learn how to:\nenter in a test environment\nsimple smoke tests to check things work\nwriting the validation tests\ntesting the image in an actual OpenWhisk and Nuvolaris environment\nEntering in the test environment In the starter kit, there is a Makefile that can help with our development efforts.\nWe can build the Dockerfile using the provided Makefile. Since it has a reference to the image we are building, let’s change it:\nsed -i.bak -e 's/actionloop-demo-python-v3.7/actionloop-demo-ruby-v2.6/' ruby2.6/Makefile We should be now able to build the image and enter in it with make debug. It will rebuild the image for us and put us into a shell so we can enter access the image environment for testing and debugging:\n$ cd ruby2.6 $ make debug # results omitted for brevity ... Let’s start with a couple of notes about this test environment.\nFirst, use --entrypoint=/bin/sh when starting the image to have a shell available at our image entrypoint. Generally, this is true by default; however, in some stripped down base images a shell may not be available.\nSecond, the /proxy folder is mounted in our local directory, so that we can edit the bin/compile and the lib/launcher.rb using our editor outside the Docker image\nNOTE It is not necessary to rebuild the Docker image with every change when using make debug since directories and environment variables used by the proxy indicate where the code outside the Docker container is located.\nOnce at the shell prompt that we will use for development, we will have to start and stop the proxy. The shell will help us to inspect what happened inside the container.\nA simple smoke test It is time to test. Let’s write a very simple test first, converting the example\\hello.py in example\\hello.rb to appear as follows:\ndef hello(args) name = args[\"name\"] || \"stranger\" greeting = \"Hello #{name}!\" puts greeting { \"greeting\" =\u003e greeting } end Now change into the ruby2.6 subdirectory of our runtime project and in one terminal type:\n$ cd \u003cprojectdir\u003e/ruby2.6 $ make debug # results omitted for brevity ... # (you should see a shell prompt of your image) $ /bin/proxy -debug 2019/04/08 07:47:36 OpenWhisk and Nuvolaris ActionLoop Proxy 2: starting Now the runtime is started in debug mode, listening on port 8080, and ready to accept Action deployments.\nOpen another terminal (while leaving the first one running the proxy) and go into the top-level directory of our project to test the Action by executing an init and then a couple of run requests using the tools/invoke.py test script.\nThese steps should look something like this in the second terminal:\n$ cd \u003cprojectdir\u003e $ python tools/invoke.py init hello example/hello.rb {\"ok\":true} $ python tools/invoke.py run '{}' {\"greeting\":\"Hello stranger!\"} $ python tools/invoke.py run '{\"name\":\"Mike\"}' {\"greeting\":\"Hello Mike!\"} We should also see debug output from the first terminal running the proxy (with the debug flag) which should have successfully processed the init and run requests above.\nThe proxy’s debug output should appear something like:\n/proxy # /bin/proxy -debug 2019/04/08 07:54:57 OpenWhisk and Nuvolaris ActionLoop Proxy 2: starting 2019/04/08 07:58:00 compiler: /proxy/bin/compile 2019/04/08 07:58:00 it is source code 2019/04/08 07:58:00 compiling: ./action/16/src/exec main: hello 2019/04/08 07:58:00 compiling: /proxy/bin/compile hello action/16/src action/16/bin 2019/04/08 07:58:00 compiler out: , \u003cnil\u003e 2019/04/08 07:58:00 env: [__OW_API_HOST=] 2019/04/08 07:58:00 starting ./action/16/bin/exec 2019/04/08 07:58:00 Start: 2019/04/08 07:58:00 pid: 13 2019/04/08 07:58:24 done reading 13 bytes Hello stranger! XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX 2019/04/08 07:58:24 received::{\"greeting\":\"Hello stranger!\"} 2019/04/08 07:58:54 done reading 27 bytes Hello Mike! XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX 2019/04/08 07:58:54 received::{\"greeting\":\"Hello Mike!\"} Hints and tips for debugging Of course, it is very possible something went wrong. Here a few debugging suggestions:\nThe ActionLoop runtime (proxy) can only be initialized once using the init command from the invoke.py script. If we need to re-initialize the runtime, we need to stop the runtime (i.e., with Control-C) and restart it.\nWe can also check what is in the action folder. The proxy creates a numbered folder under action and then a src and bin folder.\nFor example, using a terminal window, we would would see a directory and file structure created by a single action:\n$ find action/ action/1 action/1/bin action/1/bin/exec__.rb action/1/bin/exec action/1/bin/main__.rb Note that the exec starter, exec__.rb launcher and main__.rb action code are have all been copied under a directory numbered`1`.\nIn addition, we can try to run the action directly and see if it behaves properly:\n$ cd action/1/bin $ ./exec 3\u003e\u00261 $ {\"value\":{\"name\":\"Mike\"}} Hello Mike! {\"greeting\":\"Hello Mike!\"} Note we redirected the file descriptor 3 in stdout to check what is happening, and note that logs appear in stdout too.\nAlso, we can test the compiler invoking it directly.\nFirst let’s prepare the environment as it appears when we just uploaded the action:\n$ cd /proxy $ mkdir -p action/2/src action/2/bin $ cp action/1/bin/main__.rb action/2/src/exec $ find action/2 action/2 action/2/bin action/2/src action/2/src/exec Now compile and examine the results again:\n$ /proxy/bin/compile main action/2/src action/2/bin $ find action/2 action/2/ action/2/bin action/2/bin/exec__.rb action/2/bin/exec action/2/bin/main__.rb Testing If we have reached this point in the tutorial, the runtime is able to run and execute a simple test action. Now we need to validate the runtime against a set of mandatory tests both locally and within an OpenWhisk and Nuvolaris staging environment. Additionally, we should author and automate additional tests for language specific features and styles.\nThe starter kit includes two handy makefiles that we can leverage for some additional tests. In the next sections, we will show how to update them for testing our Ruby runtime.\nTesting multi-file Actions So far we tested a only an Action comprised of a single file. We should also test multi-file Actions (i.e., those with relative imports) sent to the runtime in both source and binary formats.\nFirst, let’s try a multi-file Action by creating a Ruby Action script named example/main.rb that invokes our hello.rb as follows:\nrequire \"./hello\" def main(args) hello(args) end Within the example/Makefile makefile:\nupdate the name of the image to ruby-v2.6\" as well as the name of the main action.\nupdate the PREFIX with your DockerHub username.\n-IMG=actionloop-demo-python-v3.7:latest -ACT=hello-demo-python -PREFIX=docker.io/openwhisk +IMG=actionloop-demo-ruby-v2.6:latest +ACT=hello-demo-ruby +PREFIX=docker.io/\u003cdocker username\u003e Now, we are ready to test the various cases. Again, start the runtime proxy in debug mode:\ncd ruby2.6 make debug /bin/proxy -debug On another terminal, try to deploy a single file:\n$ make test-single python ../tools/invoke.py init hello ../example/hello.rb {\"ok\":true} python ../tools/invoke.py run '{}' {\"greeting\":\"Hello stranger!\"} python ../tools/invoke.py run '{\"name\":\"Mike\"}' {\"greeting\":\"Hello Mike!\"} Now, stop and restart the proxy and try to send a ZIP file with the sources:\n$ make test-src-zip zip src.zip main.rb hello.rb adding: main.rb (deflated 42%) adding: hello.rb (deflated 42%) python ../tools/invoke.py init ../example/src.zip {\"ok\":true} python ../tools/invoke.py run '{}' {\"greeting\":\"Hello stranger!\"} python ../tools/invoke.py run '{\"name\":\"Mike\"}' {\"greeting\":\"Hello Mike!\"} Finally, test the pre-compilation: the runtime builds a zip file with the sources ready to be deployed. Again, stop and restart the proxy then:\n$ make test-bin-zip docker run -i actionloop-demo-ruby-v2.6:latest -compile main \u003csrc.zip \u003ebin.zip python ../tools/invoke.py init ../example/bin.zip {\"ok\":true} python ../tools/invoke.py run '{}' {\"greeting\":\"Hello stranger!\"} python ../tools/invoke.py run '{\"name\":\"Mike\"}' {\"greeting\":\"Hello Mike!\"} Congratulations! The runtime works locally! Time to test it on the public cloud. So as the last step before moving forward, let’s push the image to Docker Hub with make push.\nTesting on OpenWhisk and Nuvolaris To run this test you need to configure access to OpenWhisk and Nuvolaris with nuv. A simple way is to get access is to register a free account in the IBM Cloud but this works also with our own deployment of OpenWhisk and Nuvolaris.\nEdit the Makefile as we did previously:\nIMG=actionloop-demo-ruby-v2.6:latest ACT=hello-demo-ruby PREFIX=docker.io/\u003cdocker username\u003e Also, change any reference to hello.py and main.py to hello.rb and main.rb.\nOnce this is done, we can re-run the tests we executed locally on “the real thing”.\nTest single:\n$ make test-single nuv action update hello-demo-ruby hello.rb --docker docker.io/linus/actionloop-demo-ruby-v2.6:latest --main hello ok: updated action hello-demo-ruby nuv action invoke hello-demo-ruby -r { \"greeting\": \"Hello stranger!\" } nuv action invoke hello-demo-ruby -p name Mike -r { \"greeting\": \"Hello Mike!\" } Test source zip:\n$ make test-src-zip zip src.zip main.rb hello.rb adding: main.rb (deflated 42%) adding: hello.rb (deflated 42%) nuv action update hello-demo-ruby src.zip --docker docker.io/linus/actionloop-demo-ruby-v2.6:latest ok: updated action hello-demo-ruby nuv action invoke hello-demo-ruby -r { \"greeting\": \"Hello stranger!\" } nuv action invoke hello-demo-ruby -p name Mike -r { \"greeting\": \"Hello Mike!\" } Test binary ZIP:\n$ make test-bin-zip docker run -i actionloop-demo-ruby-v2.6:latest -compile main \u003csrc.zip \u003ebin.zip nuv action update hello-demo-ruby bin.zip --docker docker.io/actionloop/actionloop-demo-ruby-v2.6:latest ok: updated action hello-demo-ruby nuv action invoke hello-demo-ruby -r { \"greeting\": \"Hello stranger!\" } nuv action invoke hello-demo-ruby -p name Mike -r { \"greeting\": \"Hello Mike!\" } Congratulations! Your runtime works also in the real world.\nWriting the validation tests Before you can submit your runtime you should ensure your runtime pass the validation tests.\nUnder tests/src/test/scala/runtime/actionContainers/ActionLoopPythonBasicTests.scala there is the template for the test.\nRename to tests/src/test/scala/runtime/actionContainers/ActionLoopRubyBasicTests.scala, change internally the class name to class ActionLoopRubyBasicTests and implement the following test cases:\ntestNotReturningJson\ntestUnicode\ntestEnv\ntestInitCannotBeCalledMoreThanOnce\ntestEntryPointOtherThanMain\ntestLargeInput\nYou should convert Python code to Ruby code. We do not do go into the details of each test, as they are pretty simple and obvious. You can check the source code for the real test here.\nYou can verify tests are running properly with:\n$ ./gradlew test Starting a Gradle Daemon, 1 busy Daemon could not be reused, use --status for details \u003e Task :tests:test runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should handle initialization with no code PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should handle initialization with no content PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should run and report an error for function not returning a json object PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should fail to initialize a second time PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should invoke non-standard entry point PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should echo arguments and print message to stdout/stderr PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should handle unicode in source, input params, logs, and result PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should confirm expected environment variables PASSED runtime.actionContainers.ActionLoopPythoRubyTests \u003e runtime proxy should echo a large input PASSED BUILD SUCCESSFUL in 55s Big congratulations are in order having reached this point successfully. At this point, our runtime should be ready to run on any OpenWhisk and Nuvolaris platform and also can be submitted for consideration to be included in the Apache OpenWhisk and Nuvolaris project.\n","categories":"","description":"","excerpt":"Developing a new Runtime with the ActionLoop proxy The OpenWhisk and …","ref":"/docs/reference/references/actions-actionloop/","tags":"","title":"Building your runtime"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":" ","categories":"","description":"","excerpt":" ","ref":"/community/","tags":"","title":"Community"},{"body":"The ops debug subcomand gives access to many useful debugging utilities as follow:\nYou need access to the Kubernetes cluster where OpenServerless is installed.\nops debug: available subcommands: * apihost: show current apihost * certs: show certificates * config: show deployed configuration * images: show current images * ingress: show ingresses * kube: kubernetes support subcommand prefix * lb: show ingress load balancer * log: show logs * route: show openshift route * runtimes: show runtimes * status: show deployment status * watch: watch nodes and pod deployment * operator:version: show operator versions The ops debug kube subcommand also gives detailed informations about the underlying Kubernetes cluster:\nops debug kube: available subcommands: * ctl: execute a kubectl command, specify with CMD=\u003ccommand\u003e * detect: detect the kind of kubernetes we are using * exec: exec bash in pod P=... * info: show info * nodes: show nodes * ns: show namespaces * operator: describe operator * pod: show pods and related * svc: show services, routes and ingresses * users: show openserverless users custom resources * wait: wait for a value matching the given jsonpath on the specific resources under the namespace openserverless ","categories":"","description":"Utilities to troubleshoot OpenServerless' cluster","excerpt":"Utilities to troubleshoot OpenServerless' cluster","ref":"/docs/cli/debug/","tags":"","title":"Debugging"},{"body":"Configuring DNS and SSL You can use OpenServerless as just as a serverless engine, and use the default IP or DNS provided when provisioned your server or cluster. If you do so, only http is avaialble, and it is not secure.\nIf you want your server or cluster is available with a well-known internet name, you can associate the IP address or the “ugly” default DNS name of serveres or clusters to a DNS name of your choice, to use it also to publish the static front-end of your server.\nFurthermore, once you decided for a DNS name for your server, you can enable the provisioning of an SSL certificate so you server will be accessible with https.\nIn order to configure the DNS and the SSL the steps are:\nretrieve the IP address or the the DNS name of your server or cluster\nregister a DNS name of your choice with your registration name provider\nconfigure OpenServerless so he knows of the DNS and SSL and can use it\nRetrieving the IP address or the DNS name If OpenServerless is installed in your local machine with Docker, cannot configure any DNS nor SSL, so you can proceed configuring the services.\nIf OpenServerless is installed in a single server, after you satisfied the server prerequisites you will know the IP address or DNS name of you server.\nIf OpenServerless is installed in a Kubernetes cluster, after you satisfied the server cluster prerequisites you know either the IP address or the DNS name of the load balancer.\nRegister a DNS name or wildcard Using the address of your server or cluster, you need either to configure a DNS name your already own or contact a domain name registrar to register a new DNS name dedicated to your server or cluster.\nYou need at least one DNS name in a domain you control, for example nuvolaris.example.com that points to you IP or address.\nNote that:\nIf you have an IP address to your load balancer you need to configure an A record mapping nuvolaris.example.com to the IP address of your server.\nIf you have a DNS name to your load balancer, you need to configure a CNAME record mapping nuvolaris.example.com to the DNS name of your server.\n💡 NOTE\nIf you are registering a dedicated domain name for your cluster, you are advised to register wildcard name (*) for every domain name in example.com will resolve to your server.\nRegistering a wildcard is required to get a different website for for multiple users.\nConfigure OpenServerless to use your DNS and and enable SSL Once you registrered a single DNS (for example openserverless.example.com) or a wildcard DNS name (for example *.example.com) you can communicate to the installer what is the main DNS name of your cluster or server, as it is not able to detect it automatically. We call this the \u003capihost\u003e\n💡 NOTE\nIf you have registered a single DNS name, like openserverless.example.com use this name as \u003capihost\u003e.\nIf you have registered a wildcard DNS name, you have to choose a DNS name to be used as \u003capihost\u003e.\nWe recommended you use a name starting with api since to avoid clashes, user and domain names starting with api are reserved. So if you have a *.example.com wildcard DNS available, use api.example.com as your \u003capihost\u003e\nOnce you decided what is your API host, you can configure this as follows:\nops config apihost \u003capihost\u003e This configuration will assign a well know DNS name as access point of your OpenServerless cluster. However note it does NOT enable SSL. Accessing to your cluster will happen using HTTP.\nSince requests contain sensitive information like security keys, this is highly insecure. You hence do this only for development or testing but never for production.\nOnce you have a DNS name, enabling https is pretty easy, since we can do it automatically using the free service Let's Encrypt. We have however to provide a valid email address \u003cemail\u003e.\nOnce you know your \u003capihost\u003e and the \u003cemail\u003e to receive communications from Let’s Encrypt (mostly, when a domain name is invalidated and needs to be renewed), you can configure your apihost and enable SSL as follows:\nops config apihost \u003capihost\u003e --tls=\u003cemail\u003e Of course, replace the \u003capihost\u003e with the actual DNS name you registered, and \u003cemail\u003e with your email address\n","categories":"","description":"Configuring DNS and SSL","excerpt":"Configuring DNS and SSL","ref":"/docs/installation/configure/dns/","tags":"","title":"DNS and SSL"},{"body":"You can find more informations about Nuvolaris and OpenWhisk entities here:\nActions\nParameters\nAnnotations\nScheduler\nWeb Actions\nPackages\nFeeds\n","categories":"","description":"","excerpt":"You can find more informations about Nuvolaris and OpenWhisk entities …","ref":"/docs/reference/entities/","tags":"","title":"Entities"},{"body":"Kubernetes Cluster requirements OpenServerless installs in any Kubernetes cluster which satisfies the following requirements:\ncluster-admin access\nat least 3 worker nodes with 4GB of memory each\nsupport for block storage configured as default storage class\nsupport for LoadBalancer services\nthe nginx ingress already installed\nthe cert manager already installed\nOnce you have such a cluster, you need to retrieve the IP address of the Load Balancer associated with the Nginx Ingress. In the default installation, it is installed in the namespace nginx-ingress and it is called ingress-nginx-controller.\nIn the default installation you can read the IP address with the following command:\nkubectl -n ingress-nginx get svc ingress-nginx-controller If you have installed it in some other namespace or with another name, change the command accordingly.\nThe result should be something like this:\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.0.9.99 20.62.156.19 80:30898/TCP,443:31451/TCP 4d1h Take note of the value under EXTERNAL-IP as you need it in the next step of installation, configuring DNS.\n","categories":"","description":"Prerequisites for all Kubernetes","excerpt":"Prerequisites for all Kubernetes","ref":"/docs/installation/prereq/kubernetes/cluster/","tags":"","title":"Generic Kubernetes"},{"body":"Prerequisites to install OpenServerless in a Google GKE Cluster Google GKE is a pre-built Kubernetes cluster offered by the cloud provider Google Cloud Platform (GCP).\nYou can create a GKE Cluster in GCP for installing using OpenServerless using ops as follows:\ninstall the GCloud CLI\nconfigure GKE\nprovision GKE\noptionally, retrieve the load balancer address to configure a DNS name\nOnce you have GKE up and running you can proceed configuring and installing OpenServerless.\nInstalling the GCloud CLI Our cli ops uses under the hood the GCloud CLI version 2, so you need to dowload and install it following those instructions.\nOnce installed, ensure it is available on the terminal executing the following command:\ngcloud version you should receive something like this:\nGoogle Cloud SDK 443.0.0 beta 2023.08.11 bq 2.0.96 bundled-python3-unix 3.9.16 core 2023.08.11 gcloud-crc32c 1.0.0 gke-gcloud-auth-plugin 0.5.5 gsutil 5.25 Configuring GKE Before starting, you need to create a project in Google Cloud. Then, to install GKE you need to configure ops for GKE with the command ops config gke answering to all the questions, as in the following example:\n$ ops config gke *** Please, specify GCloud Project Id and press enter. nuvolaris *** Please, specify GCloud Cluster Name and press enter. The cluster name must be unique. Just press enter for default [nuvolaris]: *** Please, specify GCloud Cluster Zone and press enter. To get a list of valid values use: gcloud compute zones list Just press enter for default [us-east1]: *** Please, specify GCloud number of worker nodes and press enter. Just press enter for default [3]: *** Please, specify GKE virtual machine type and press enter. To get a list of valid values, use: gcloud compute machine-types list Just press enter for default [e2-standard-2]: *** Please, specify GKE disk size in gigabyte and press enter. Just press enter for default [50]: Provisioning Google GKE Once you have configured it, you can create the EKS cluster with the command:\nops cloud gke create It will take around 10 minutes to be ready. Please be patient.\nAt the end of the process, you will have access directly to the created Kubernetes cluster for installation.\nRetrieving the Load Balancer DNS name Once the cluster is up and running, you need to retrieve the DNS name of the load balancer.\nYou can read this with the command:\nops cloud gke lb Take note of the result as it is required for configuring a dns name for your cluster.\nAdditional Commands You can delete the created cluster with: ops cloud gke delete\nYou can extract again the cluster configuration, if you lose it, reconfiguring the cluster and then using the command ops cloud gke kubeconfig.\n","categories":"","description":"Prerequisites for Google GKE","excerpt":"Prerequisites for Google GKE","ref":"/docs/installation/prereq/kubernetes/gke/","tags":"","title":"Google GKE"},{"body":"Install MicroK8S in a server You can install OpenServerless as described here and you do not need to install any Kubernetes in it, as it is installed as part of the procedure. In this case it installs K3S.\nBut you can install MicroK8S instead, if you prefer. Check here for informations about MicroK8S.\nIf you install MicroK8S in your server, you can then proceed configuring and then installing OpenServerless as in any other Kubernetes cluster.\nInstalling MicroK8S in a server Before installing ensure you have satisfied the prerequisites, most notably:\nyou know the IP address or DNS name\nyou have passwordless access with ssh\nyou have an user with passwordless sudo rights\nyou have opened the port 16443 in the firewall\nFurthermore, since MicroK8S is installed using snap, you also need to install snap.\n💡 NOTE\nWhile snap is available for many linux distributions, it is typically pre-installed and well supported in in Ubuntu and its derivatives. So we recommend MicroK8S only if you are actually using an Ubuntu-like Linux distribution.\nIf you system is suitable to run MicroK8S you can use the following subcommand to install in the server:\nops cloud mk8s create SERVER=\u003cserver\u003e USERNAME=\u003cusername\u003e where \u003cserver\u003e is IP address or DNS name to access the server, and \u003cusername\u003e is the user you use to access the server.\nThose informations should have been provided when provisioning the server.\n❗ IMPORTANT\nIf you installed a Kubernetes cluster in the server in this way, you should proceed installing OpenServerless as in a Kubernetes cluster, not as a server.\nThe installation retrieves also a kubernets configuration file so you can proceed to installing it without any other step involved.\nAdditional Commands In addition to create you have available also the following subcommands:\nops cloud mk8s delete SERVER=\u003cserver\u003e USERNAME=\u003cusername\u003e: uninstall K3S from the server\nops cloud mk8s kubeconfig SERVER=\u003cserver\u003e USERNAME=\u003cusername\u003e: retrieve the kubeconfig from the MicroK8S server\nops cloud mk8s info: informations about the server\nops cloud mk8s status: status of the server\n","categories":"","description":"Prerequisites to install OpenServerless in K8S","excerpt":"Prerequisites to install OpenServerless in K8S","ref":"/docs/installation/prereq/server/mk8s/","tags":"","title":"Install MicroK8S"},{"body":"System details The following sections provide more details about the OpenWhisk and Nuvolaris system.\nEntities Namespaces and packages OpenWhisk and Nuvolaris actions, triggers, and rules belong in a namespace, and optionally a package.\nPackages can contain actions and feeds. A package cannot contain another package, so package nesting is not allowed. Also, entities do not have to be contained in a package.\nIn Nuvolaris a namespace corresponds to an user. You can create users with the admin subcommand of the CLI.\nThe fully qualified name of an entity is /namespaceName[/packageName]/entityName. Notice that / is used to delimit namespaces, packages, and entities.\nIf the fully qualified name has three parts: /namespaceName/packageName/entityName, then the namespace can be entered without a prefixed /; otherwise, namespaces must be prefixed with a /.\nFor convenience, the namespace can be left off if it is the user’s default namespace.\nFor example, consider a user whose default namespace is /myOrg. Following are examples of the fully qualified names of a number of entities and their aliases.\nFully qualified name Alias Namespace Package Name /whisk.system/cloudant/read\n/whisk.system\ncloudant\nread\n/myOrg/video/transcode\nvideo/transcode\n/myOrg\nvideo\ntranscode\n/myOrg/filter\nfilter\n/myOrg\nfilter\nYou will be using this naming scheme when you use the OpenWhisk and Nuvolaris CLI, among other places.\nEntity names The names of all entities, including actions, triggers, rules, packages, and namespaces, are a sequence of characters that follow the following format:\nThe first character must be an alphanumeric character, or an underscore.\nThe subsequent characters can be alphanumeric, spaces, or any of the following: _, @, ., -.\nThe last character can’t be a space.\nMore precisely, a name must match the following regular expression (expressed with Java metacharacter syntax): \\A([\\w]|[\\w][\\w@ .-]*[\\w@.-]+)\\z.\nSystem limits Actions OpenWhisk and Nuvolaris has a few system limits, including how much memory an action can use and how many action invocations are allowed per minute.\nNote: On Openwhisk 2.0 with the scheduler service, concurrent in the table below really means the max containers that can be provisioned at once for a namespace. The api may be able to accept more activations than this number at once depending on a number of factors.\nThe following table lists the default limits for actions.\nlimit description configurable unit default timeout\na container is not allowed to run longer than N milliseconds\nper action\nmilliseconds\n60000\nmemory\na container is not allowed to allocate more than N MB of memory\nper action\nMB\n256\nlogs\na container is not allowed to write more than N MB to stdout\nper action\nMB\n10\ninstances\nan action is not allowed to have more containers than this value (new scheduler only)\nper action\nnumber\nnamespace concurrency limit\nconcurrent\nno more than N activations may be submitted per namespace either executing or queued for execution\nper namespace\nnumber\n100\nminuteRate\nno more than N activations may be submitted per namespace per minute\nper namespace\nnumber\n120\ncodeSize\nthe maximum size of the action code\nconfigurable, limit per action\nMB\n48\nparameters\nthe maximum size of the parameters that can be attached\nnot configurable, limit per action/package/trigger\nMB\n1\nresult\nthe maximum size of the action result\nnot configurable, limit per action\nMB\n1\nPer action timeout (ms) (Default: 60s) The timeout limit N is in the range [100ms..300000ms] and is set per action in milliseconds.\nA user can change the limit when creating the action.\nA container that runs longer than N milliseconds is terminated.\nPer action memory (MB) (Default: 256MB) The memory limit M is in the range from [128MB..512MB] and is set per action in MB.\nA user can change the limit when creating the action.\nA container cannot have more memory allocated than the limit.\nPer action max instance concurrency (Default: namespace limit for concurrent invocations) Only applicable using new scheduler The max containers that will be created for an action before throttling in the range from [1..concurrentInvocations limit for namespace]\nBy default the max allowed containers / server instances for an action is equal to the namespace limit.\nA user can change the limit when creating the action.\nDefining a lower limit than the namespace limit means your max container concurrency will be the action defined limit.\nIf using actionConcurrency \u003e 1 such that your action can handle multiple requests per instance, your true concurrency limit is actionContainerConcurrency * actionConcurrency.\nThe actions within a namespaces containerConcurrency total do not have to add up to the namespace limit though you can configure it that way to guarantee an action will get exactly the action container concurrency.\nFor example with a namespace limit of 30 with 2 actions each with a container limit of 20; if the first action is using 20, there will still be space for 10 for the other.\nPer action logs (MB) (Default: 10MB) The log limit N is in the range [0MB..10MB] and is set per action.\nA user can change the limit when creating or updating the action.\nLogs that exceed the set limit are truncated and a warning is added as the last output of the activation to indicate that the activation exceeded the set log limit.\nPer action artifact (MB) (Default: 48MB) The maximum code size for the action is 48MB.\nIt is recommended for a JavaScript action to use a tool to concatenate all source code including dependencies into a single bundled file.\nPer activation payload size (MB) (Fixed: 1MB) The maximum POST content size plus any curried parameters for an action invocation or trigger firing is 1MB. Per activation result size (MB) (Fixed: 1MB) The maximum size of a result returned from an action is 1MB. Per namespace concurrent invocation (Default: 100) The number of activations that are either executing or queued for execution for a namespace cannot exceed 100.\nA user is currently not able to change the limits.\nInvocations per minute (Fixed: 120) The rate limit N is set to 120 and limits the number of action invocations in one minute windows.\nA user cannot change this limit when creating the action.\nA CLI or API call that exceeds this limit receives an error code corresponding to HTTP status code 429: TOO MANY REQUESTS.\nSize of the parameters (Fixed: 1MB) The size limit for the parameters on creating or updating of an action/package/trigger is 1MB.\nThe limit cannot be changed by the user.\nAn entity with too big parameters will be rejected on trying to create or update it.\nPer Docker action open files ulimit (Fixed: 1024:1024) The maximum number of open files is 1024 (for both hard and soft limits).\nThe docker run command use the argument --ulimit nofile=1024:1024.\nFor more information about the ulimit for open files see the docker run documentation.\nPer Docker action processes ulimit (Fixed: 1024) The maximum number of processes available to the action container is 1024.\nThe docker run command use the argument --pids-limit 1024.\nFor more information about the ulimit for maximum number of processes see the docker run documentation.\nTriggers Triggers are subject to a firing rate per minute as documented in the table below.\nlimit description configurable unit default minuteRate\nno more than N triggers may be fired per namespace per minute\nper user\nnumber\n60\nTriggers per minute (Fixed: 60) The rate limit N is set to 60 and limits the number of triggers that may be fired in one minute windows.\nA user cannot change this limit when creating the trigger.\nA CLI or API call that exceeds this limit receives an error code corresponding to HTTP status code 429: TOO MANY REQUESTS.\n","categories":"","description":"","excerpt":"System details The following sections provide more details about the …","ref":"/docs/reference/references/naming-limits/","tags":"","title":"Naming And Limits"},{"body":"RedHat™ OpenShift is a Kubernetes distribution offered by RedHat™, a division of IBM™.\nOpenShift is available in a variety of cloud environment and provider, using its own installer\nYou can install OpenServerless in OpenShift, provided you have already installed OpenShift.\nThe procedure is the following:\nInstall OpenShift in any supported environment following this guide\nAt the end of the installation, the installer will leave a kubeconfig file in a folder. You need to import it with the command.\nops cloud osh import \u003ckubeconfig\u003e 💡 NOTE\nin the command above, \u003ckubeconfig\u003e is the path to the generated kubeconfig.\nNow, setup the required components (currently, acme-openshift) with: ops cloud config setup Once you have OpenShift up and running and you imported its kubeconfig you can proceed configuring and installing OpenServerless.\n","categories":"","description":"Prerequisites for RedHat™ OpenShift","excerpt":"Prerequisites for RedHat™ OpenShift","ref":"/docs/installation/prereq/kubernetes/openshift/","tags":"","title":"OpensShift"},{"body":"Project An OpenServerless Project ⚠️ WARNING\nThis document is still 🚧 work in progress 🚧\nA project represents a logical unit of functionality whose boundaries are up to you. Your app can contain one or more projects. The folder structure of a project determines how the deployer finds and labels packages and actions, how it deploys static web content, and what it ignores.\nYou can detect and load entire projects into OpenServerless with a single command using the ops CLI tool.\nProject Detection When deploying a project, ops checks in the given path for 2 special folders:\nThe packages folder: contains sub-folders that are treated as OpenServerless packages and are assumed to contain actions in the form of either files or folders, which we refer to as Single File Actions (SFA) and Multi File Actions (MFA).\nThe web folder: contains static web content.\nAnything else is ignored. This lets you store things in the root folder that are not meant to be deployed on OpenServerless (such as build folders and project documentation).\nSingle File Actions A single file action is simply a file with specific extension (the supported ones: .js .py .php .go .java), whici is directly deployed as an action.\nMulti File Actions A multi-file action is a folder containing a main file and dependencies. The folder is bundled into a zip file and deployed as an action.\n","categories":"","description":"How to deal with OpenServerless projects","excerpt":"How to deal with OpenServerless projects","ref":"/docs/cli/project/","tags":"","title":"Project"},{"body":"Advanced Reference Guides You can find advanced reference documentations here:\nNaming and Limits\nAdvanced CLI\nRest API\nRuntimes under the hood\nBuilding your runtime\n","categories":"","description":"","excerpt":"Advanced Reference Guides You can find advanced reference …","ref":"/docs/reference/references/","tags":"","title":"References"},{"body":"Using REST APIs with OpenWhisk and Nuvolaris After your OpenWhisk and Nuvolaris environment is enabled, you can use OpenWhisk and Nuvolaris with your web apps or mobile apps with REST API calls.\nFor more details about the APIs for actions, activations, packages, rules, and triggers, see the OpenWhisk and Nuvolaris API documentation.\nAll the capabilities in the system are available through a REST API. There are collection and entity endpoints for actions, triggers, rules, packages, activations, and namespaces.\nThese are the collection endpoints:\nhttps://$APIHOST/api/v1/namespaces https://$APIHOST/api/v1/namespaces/{namespace}/actions https://$APIHOST/api/v1/namespaces/{namespace}/triggers https://$APIHOST/api/v1/namespaces/{namespace}/rules https://$APIHOST/api/v1/namespaces/{namespace}/packages https://$APIHOST/api/v1/namespaces/{namespace}/activations https://$APIHOST/api/v1/namespaces/{namespace}/limits The $APIHOST is the OpenWhisk and Nuvolaris API hostname (for example, localhost, 172.17.0.1, and so on). For the {namespace}, the character _ can be used to specify the user’s default namespace.\nYou can perform a GET request on the collection endpoints to fetch a list of entities in the collection.\nThere are entity endpoints for each type of entity:\nhttps://$APIHOST/api/v1/namespaces/{namespace} https://$APIHOST/api/v1/namespaces/{namespace}/actions/[{packageName}/]{actionName} https://$APIHOST/api/v1/namespaces/{namespace}/triggers/{triggerName} https://$APIHOST/api/v1/namespaces/{namespace}/rules/{ruleName} https://$APIHOST/api/v1/namespaces/{namespace}/packages/{packageName} https://$APIHOST/api/v1/namespaces/{namespace}/activations/{activationName} The namespace and activation endpoints support only GET requests. The actions, triggers, rules, and packages endpoints support GET, PUT, and DELETE requests. The endpoints of actions, triggers, and rules also support POST requests, which are used to invoke actions and triggers and enable or disable rules.\nAll APIs are protected with HTTP Basic authentication. You can use the nuvadmin tool to generate a new namespace and authentication. The Basic authentication credentials are in the AUTH property in your ~/.nuvprops file, delimited by a colon. You can also retrieve these credentials using the CLI running nuv property get --auth.\nThe following is an example that uses the cURL command tool to get the list of all packages in the whisk.system namespace:\ncurl -u USERNAME:PASSWORD https://$APIHOST/api/v1/namespaces/whisk.system/packages [ { \"name\": \"slack\", \"binding\": false, \"publish\": true, \"annotations\": [ { \"key\": \"description\", \"value\": \"Package that contains actions to interact with the Slack messaging service\" } ], \"version\": \"0.0.1\", \"namespace\": \"whisk.system\" } ] In this example the authentication was passed using the -u flag, you can pass this value also as part of the URL as https://USERNAME:PASSWORD@$APIHOST.\nThe OpenWhisk API supports request-response calls from web clients. OpenWhisk responds to OPTIONS requests with Cross-Origin Resource Sharing headers. Currently, all origins are allowed (that is, Access-Control-Allow-Origin is “*”), the standard set of methods are allowed (that is, Access-Control-Allow-Methods is GET, DELETE, POST, PUT, HEAD), and Access-Control-Allow-Headers yields Authorization, Origin, X-Requested-With, Content-Type, Accept, User-Agent.\nAttention: Because OpenWhisk and Nuvolaris currently supports only one key per namespace, it is not recommended to use CORS beyond simple experiments. Use Web Actions to expose your actions to the public and not use the OpenWhisk and Nuvolaris authorization key for client applications that require CORS.\nUsing the CLI verbose mode The OpenWhisk and Nuvolaris CLI is an interface to the OpenWhisk and Nuvolaris REST API. You can run the CLI in verbose mode with the flag -v, this will print truncated information about the HTTP request and response. To print all information use the flag -d for debug.\nNote: HTTP request and response bodies will only be truncated if they exceed 1000 bytes.\nLet’s try getting the namespace value for the current user.\nnuv namespace list -v REQUEST: [GET] https://$APIHOST/api/v1/namespaces Req Headers { \"Authorization\": [ \"Basic XXXYYYY\" ], \"User-Agent\": [ \"OpenWhisk and Nuvolaris-CLI/1.0 (2017-08-10T20:09:30+00:00)\" ] } RESPONSE:Got response with code 200 Resp Headers { \"Content-Type\": [ \"application/json; charset=UTF-8\" ] } Response body size is 28 bytes Response body received: [\"john@example.com_dev\"] As you can see you the printed information provides the properties of the HTTP request, it performs a HTTP method GET on the URL https://$APIHOST/api/v1/namespaces using a User-Agent header OpenWhisk and Nuvolaris-CLI/1.0 (\u003cCLI-Build-version\u003e) and Basic Authorization header Basic XXXYYYY. Notice that the authorization value is your base64-encoded OpenWhisk and Nuvolaris authorization string. The response is of content type application/json.\nActions Note: In the examples that follow, $AUTH and $APIHOST represent environment variables set respectively to your OpenWhisk and Nuvolaris authorization key and API host.\nTo create or update an action send a HTTP request with method PUT on the the actions collection. For example, to create a nodejs:6 action with the name hello using a single file content use the following:\ncurl -u $AUTH -d '{\"namespace\":\"_\",\"name\":\"hello\",\"exec\":{\"kind\":\"nodejs:6\",\"code\":\"function main(params) { return {payload:\\\"Hello \\\"+params.name}}\"}}' -X PUT -H \"Content-Type: application/json\" https://$APIHOST/api/v1/namespaces/_/actions/hello?overwrite=true To perform a blocking invocation on an action, send a HTTP request with a method POST and body containing the input parameter name use the following:\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/actions/hello?blocking=true \\ -X POST -H \"Content-Type: application/json\" \\ -d '{\"name\":\"John\"}' You get the following response:\n{ \"duration\": 2, \"name\": \"hello\", \"subject\": \"john@example.com_dev\", \"activationId\": \"c7bb1339cb4f40e3a6ccead6c99f804e\", \"publish\": false, \"annotations\": [{ \"key\": \"limits\", \"value\": { \"timeout\": 60000, \"memory\": 256, \"logs\": 10 } }, { \"key\": \"path\", \"value\": \"john@example.com_dev/hello\" }], \"version\": \"0.0.1\", \"response\": { \"result\": { \"payload\": \"Hello John\" }, \"success\": true, \"status\": \"success\" }, \"end\": 1493327653769, \"logs\": [], \"start\": 1493327653767, \"namespace\": \"john@example.com_dev\" } If you just want to get the response.result, run the command again with the query parameter result=true\ncurl -u $AUTH \"https://$APIHOST/api/v1/namespaces/_/actions/hello?blocking=true\u0026result=true\" \\ -X POST -H \"Content-Type: application/json\" \\ -d '{\"name\":\"John\"}' You get the following response:\n{ \"payload\": \"hello John\" } Annotations and Web Actions To create an action as a web action, you need to add an annotation of web-export=true for web actions. Since web-actions are publicly accessible, you should protect pre-defined parameters (i.e., treat them as final) using the annotation final=true. If you create or update an action using the CLI flag --web true this command will add both annotations web-export=true and final=true.\nRun the curl command providing the complete list of annotations to set on the action\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/actions/hello?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"namespace\":\"_\",\"name\":\"hello\",\"exec\":{\"kind\":\"nodejs:6\",\"code\":\"function main(params) { return {payload:\\\"Hello \\\"+params.name}}\"},\"annotations\":[{\"key\":\"web-export\",\"value\":true},{\"key\":\"raw-http\",\"value\":false},{\"key\":\"final\",\"value\":true}]}' You can now invoke this action as a public URL with no OpenWhisk and Nuvolaris authorization. Try invoking using the web action public URL including an optional extension such as .json or .http for example at the end of the URL.\ncurl https://$APIHOST/api/v1/web/john@example.com_dev/default/hello.json?name=John { \"payload\": \"Hello John\" } Note that this example source code will not work with .http, see web actions documentation on how to modify.\nSequences To create an action sequence, you need to create it by providing the names of the actions that compose the sequence in the desired order, so the output from the first action is passed as input to the next action.\n$ nuv action create sequenceAction –sequence /whisk-system/utils/split,/whisk-system/utils/sort\nCreate a sequence with the actions /whisk-system/utils/split and /whisk-system/utils/sort.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/actions/sequenceAction?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"namespace\":\"_\",\"name\":\"sequenceAction\",\"exec\":{\"kind\":\"sequence\",\"components\":[\"/whisk.system/utils/split\",\"/whisk.system/utils/sort\"]},\"annotations\":[{\"key\":\"web-export\",\"value\":true},{\"key\":\"raw-http\",\"value\":false},{\"key\":\"final\",\"value\":true}]}' Take into account when specifying the names of the actions, they have to be full qualified.\nTriggers To create a trigger, the minimum information you need is a name for the trigger. You could also include default parameters that get passed to the action through a rule when the trigger gets fired.\nCreate a trigger with name events with a default parameter type with value webhook set.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/triggers/events?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"name\":\"events\",\"parameters\":[{\"key\":\"type\",\"value\":\"webhook\"}]}' Now whenever you have an event that needs to fire this trigger it just takes an HTTP request with a method POST using the OpenWhisk and Nuvolaris Authorization key.\nTo fire the trigger events with a parameter temperature, send the following HTTP request.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/triggers/events \\ -X POST -H \"Content-Type: application/json\" \\ -d '{\"temperature\":60}' Rules To create a rule that associates a trigger with an action, send a HTTP request with a PUT method providing the trigger and action in the body of the request.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/rules/t2a?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"name\":\"t2a\",\"status\":\"\",\"trigger\":\"/_/events\",\"action\":\"/_/hello\"}' Rules can be enabled or disabled, and you can change the status of the rule by updating its status property. For example, to disable the rule t2a send in the body of the request status: \"inactive\" with a POST method.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/rules/t2a?overwrite=true \\ -X POST -H \"Content-Type: application/json\" \\ -d '{\"status\":\"inactive\",\"trigger\":null,\"action\":null}' Packages To create an action in a package you have to create a package first, to create a package with name iot send an HTTP request with a PUT method\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/packages/iot?overwrite=true \\ -X PUT -H \"Content-Type: application/json\" \\ -d '{\"namespace\":\"_\",\"name\":\"iot\"}' To force delete a package that contains entities, set the force parameter to true. Failure will return an error either for failure to delete an action within the package or the package itself. The package will not be attempted to be deleted until all actions are successfully deleted.\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/packages/iot?force=true \\ -X DELETE Activations To get the list of the last 3 activations use a HTTP request with a GET method, passing the query parameter limit=3\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/activations?limit=3 To get all the details of an activation including results and logs, send a HTTP request with a GET method passing the activation identifier as a path parameter\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/activations/f81dfddd7156401a8a6497f2724fec7b Limits To get the limits set for a namespace (i.e. invocationsPerMinute, concurrentInvocations, firesPerMinute, actionMemoryMax, actionLogsMax…)\ncurl -u $AUTH https://$APIHOST/api/v1/namespaces/_/limits Note that the default system values are returned if no specific limits are set for the user corresponding to the authenticated identity.\n","categories":"","description":"","excerpt":"Using REST APIs with OpenWhisk and Nuvolaris After your OpenWhisk and …","ref":"/docs/reference/references/rest_api/","tags":"","title":"Rest API"},{"body":"This document is still 🚧 work in progress 🚧\nThe programming languages currently directly supported by Nuvolaris are:\n🚧 Node\n🚧 Python\n🚧 Go\n🚧 Java\n🚧 PHP\n","categories":"","description":"","excerpt":"This document is still 🚧 work in progress 🚧\nThe programming languages …","ref":"/docs/reference/runtimes/","tags":"","title":"Runtimes"},{"body":"Adding Action Language Runtimes OpenWhisk and Nuvolaris supports several languages and runtimes but there may be other languages or runtimes that are important for your organization, and for which you want tighter integration with the platform.\nThe platform is extensible and you can add new languages or runtimes (with custom packages and third-party dependencies)\nThis guide describes the contract a runtime must satisfy. However all the Nuvolaris runtimes are implemented the using the ActionLoop Proxy. This proxy is implemented in Go, already satifies the semantic of a runtime ands makes very easy to build a new runtime. You just need to provide “launcher code” in your favorite programming language and a compilation script (generally written in python) for the initialization of an action. You are advised to use it for your own runtimes and use the material of this document as reference for the behaviour of a runtime.\nRuntime general requirements The unit of execution for all functions is a Docker container which must implement a specific Action interface that, in general performs:\nInitialization - accepts an initialization payload (the code) and prepared for execution,\nActivation - accepts a runtime payload (the input parameters) and\nprepares the activation context,\nruns the function,\nreturns the function result,\nLogging - flushes all stdout and stderr logs and adds a frame marker at the end of the activation.\nThe specifics of the Action interface and its functions are shown below.\nThe runtimes manifest Actions when created specify the desired runtime for the function via a property called kind. When using the nuv CLI, this is specified as --kind \u003cruntime-kind\u003e. The value is typically a string describing the language (e.g., nodejs) followed by a colon and the version for the runtime as in nodejs:20 or php:8.1.\nThe manifest is a map of runtime family names to an array of specific kinds. As an example, the following entry add a new runtime family called nodejs with a single kind nodejs:20.\n{ \"nodejs\": [{ \"kind\": \"nodejs:20\", \"default\": true, \"image\": { \"prefix\": \"openwhisk\", \"name\": \"action-nodejs-v20\", \"tag\": \"latest\" } }] } The default property indicates if the corresponding kind should be treated as the default for the runtime family. The JSON image structure defines the Docker image name that is used for actions of this kind (e.g., openwhisk/nodejs10action:latest for the JSON example above).\nThe standard test action is shown below in JavaScript. It should be adapted for the new language and added to the test artifacts directory with the name \u003cruntime-kind\u003e.txt for plain text file or \u003cruntime-kind\u003e.bin for a a binary file. The \u003cruntime-kind\u003e must match the value used for kind in the corresponding runtime manifest entry, replacing : in the kind with a -. For example, a plain text function for nodejs:20 becomes nodejs-20.txt.\nfunction main(args) { var str = args.delimiter + \" ☃ \" + args.delimiter; console.log(str); return { \"winter\": str }; } An action consists of the user function (and its dependencies) along with a proxy that implements a canonical protocol to integrate with the OpenWhisk and Nuvolaris platform.\nThe proxy is a web server with two endpoints.\nIt listens on port 8080.\nIt implements /init to initialize the container.\nIt also implements /run to activate the function.\nThe proxy also prepares the execution context, and flushes the logs produced by the function to stdout and stderr.\nThe initialization route is /init. It must accept a POST request with a JSON object as follows:\n{ \"value\": { \"name\" : String, \"main\" : String, \"code\" : String, \"binary\": Boolean, \"env\": Map[String, String] } } name is the name of the action.\nmain is the name of the function to execute.\ncode is either plain text or a base64 encoded string for binary functions (i.e., a compiled executable).\nbinary is false if code is in plain text, and true if code is base64 encoded.\nenv is a map of key-value pairs of properties to export to the environment. And contains several properties starting with the __OW_ prefix that are specific to the running action.\n__OW_API_KEY the API key for the subject invoking the action, this key may be a restricted API key. This property is absent unless explicitly requested.\n__OW_NAMESPACE the namespace for the activation (this may not be the same as the namespace for the action).\n__OW_ACTION_NAME the fully qualified name of the running action.\n__OW_ACTION_VERSION the internal version number of the running action.\n__OW_ACTIVATION_ID the activation id for this running action instance.\n__OW_DEADLINE the approximate time when this initializer will have consumed its entire duration quota (measured in epoch milliseconds).\nThe initialization route is called exactly once by the OpenWhisk and Nuvolaris platform, before executing a function. The route should report an error if called more than once. It is possible however that a single initialization will be followed by many activations (via /run). If an env property is provided, the corresponding environment variables should be defined before the action code is initialized.\nSuccessful initialization: The route should respond with 200 OK if the initialization is successful and the function is ready to execute. Any content provided in the response is ignored.\nFailures to initialize: Any response other than 200 OK is treated as an error to initialize. The response from the handler if provided must be a JSON object with a single field called error describing the failure. The value of the error field may be any valid JSON value. The proxy should make sure to generate meaningful log message on failure to aid the end user in understanding the failure.\nTime limit: Every action in OpenWhisk and Nuvolaris has a defined time limit (e.g., 60 seconds). The initialization must complete within the allowed duration. Failure to complete initialization within the allowed time frame will destroy the container.\nLimitation: The proxy does not currently receive any of the activation context at initialization time. There are scenarios where the context is convenient if present during initialization. This will require a change in the OpenWhisk and Nuvolaris platform itself. Note that even if the context is available during initialization, it must be reset with every new activation since the information will change with every execution.\nThe proxy is ready to execute a function once it has successfully completed initialization. The OpenWhisk and Nuvolaris platform will invoke the function by posting an HTTP request to /run with a JSON object providing a new activation context and the input parameters for the function. There may be many activations of the same function against the same proxy (viz. container). Currently, the activations are guaranteed not to overlap — that is, at any given time, there is at most one request to /run from the OpenWhisk and Nuvolaris platform.\nThe route must accept a JSON object and respond with a JSON object, otherwise the OpenWhisk and Nuvolaris platform will treat the activation as a failure and proceed to destroy the container. The JSON object provided by the platform follows the following schema:\n{ \"value\": JSON, \"namespace\": String, \"action_name\": String, \"api_host\": String, \"api_key\": String, \"activation_id\": String, \"transaction_id\": String, \"deadline\": Number } value is a JSON object and contains all the parameters for the function activation.\nnamespace is the OpenWhisk and Nuvolaris namespace for the action (e.g., whisk-system).\naction_name is the fully qualified name of the action.\nactivation_id is a unique ID for this activation.\ntransaction_id is a unique ID for the request of which this activation is part of.\ndeadline is the deadline for the function.\napi_key is the API key used to invoke the action.\nThe value is the function parameters. The rest of the properties become part of the activation context which is a set of environment variables constructed by capitalizing each of the property names, and prefixing the result with __OW_. Additionally, the context must define __OW_API_HOST whose value is the OpenWhisk and Nuvolaris API host. This value is currently provided as an environment variable defined at container startup time and hence already available in the context.\nSuccessful activation: The route must respond with 200 OK if the activation is successful and the function has produced a JSON object as its result. The response body is recorded as the result of the activation.\nFailed activation: Any response other than 200 OK is treated as an activation error. The response from the handler must be a JSON object with a single field called error describing the failure. The value of the error field may be any valid JSON value. Should the proxy fail to respond with a JSON object, the OpenWhisk and Nuvolaris platform will treat the failure as an uncaught exception. These two failures modes are distinguished by the value of the response.status in the activation record which is application error if the proxy returned an error object, and action developer error otherwise.\nTime limit: Every action in OpenWhisk and Nuvolaris has a defined time limit (e.g., 60 seconds). The activation must complete within the allowed duration. Failure to complete activation within the allowed time frame will destroy the container.\nThe proxy must flush all the logs produced during initialization and execution and add a frame marker to denote the end of the log stream for an activation. This is done by emitting the token XXX_THE_END_OF_A_WHISK_ACTIVATION_XXX as the last log line for the stdout and stderr streams. Failure to emit this marker will cause delayed or truncated activation logs.\nThe Action interface is enforced via a canonical test suite which validates the initialization protocol, the runtime protocol, ensures the activation context is correctly prepared, and that the logs are properly framed. Your runtime should extend this test suite, and of course include additional tests as needed.\nRuntime proxy tests The tests verify that the proxy can handle the following scenarios:\nTest the proxy can handle the identity functions (initialize and run).\nTest the proxy can handle pre-defined environment variables as well as initialization parameters.\nTest the proxy properly constructs the activation context.\nTest the proxy can properly handle functions with Unicode characters.\nTest the proxy can handle large payloads (more than 1MB).\nTest the proxy can handle an entry point other than main.\nTest the proxy does not permit re-initialization.\nTest the error handling for an action returning an invalid response.\nTest the proxy when initialized with no content.\nThe canonical test suite should be extended by the new runtime tests. Additional tests will be required depending on the feature set provided by the runtime.\nSince the OpenWhisk and Nuvolaris platform is language and runtime agnostic, it is generally not necessary to add integration tests. That is the unit tests verifying the protocol are sufficient. However, it may be necessary in some cases to modify the nuv CLI or other OpenWhisk and Nuvolaris clients. In which case, appropriate tests should be added as necessary. The OpenWhisk and Nuvolaris platform will perform a generic integration test as part of its basic system tests. This integration test will require a test function to be available so that the test harness can create, invoke, and delete the action.\n","categories":"","description":"","excerpt":"Adding Action Language Runtimes OpenWhisk and Nuvolaris supports …","ref":"/docs/reference/references/actions-new/","tags":"","title":"Runtimes under the hood"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/reference/references/scheduler/","tags":"","title":"Scheduler"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"Configuring OpenServerless services After you satisfied the prerequisites and before you actually install OpenServerless, you have to select which services you want to install:\nStatic, publishing of static assets\nRedis, a storage service\nMinIO an object storage service\nPostgres a relational SQL database\nFerretDB A MongoDB-compatible adapter for Postgres\nYou can enable all the services with:\nops config enable --all or disable all of them with:\nops config disable --all Or select the services you want, as follows.\nStatic Asset Publishing The static service allows you to publish static asset.\n💡 NOTE\nyou need to setup a a wildcard DNS name to be able to access them from Internet.\nYou can enable the Static service with:\nops config enable --static and disable it with:\nops config disable --static Redis Redis, is a fast, in-memory key-value store, usually used as cache, but also in some cases as a (non-relational) database.\nEnable REDIS:\nops config enable --redis Disable REDIS:\nops config disable --redis MinIO MinIO is an object storage service\nEnable minio:\nops config enable --minio Disable minio:\nops config disable --minio Postgres Postgres is an SQL (relational) database.\nEnable postgres:\nops config enable --postgres Disable postgres:\nops config disable --postgres FerretDB FerretDB is a MongoDB-compatible adapter for Postgres. It created a document-oriented database service on top of Postgres.\n💡 NOTE\nSince FerretDB uses Postgres as its storage, if you enable it, also the service Postgresql will be enabled as it is required.\nEnable MongoDB api with FerretDB:\nops config enable --mongodb Disable MongoDB api with FerretDB:\nops config disable --mongodb ","categories":"","description":"Configure OpenServerless services","excerpt":"Configure OpenServerless services","ref":"/docs/installation/configure/services/","tags":"","title":"Services"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":"Debug This document gives you hints for diagnostics and solving issues, using the (hidden) subcommand debug.\nNote it is technical and assumes you have some knowledge of how Kubernetes operates.\nWatching While installing, you can watch the installation (opening another terminal) with the command:\nops debug watch Check that no pods will go in error while deploying.\nConfiguration You can inspect the configuration with the ops debug subcommand\nAPI host: ops debug apihost\nStatic Configuration: ops debug config.\nCurrent Status: ops debug status\nRuntimes: ops debug runtimes\nLoad Balancer: ops debug lb\nImages: ops debug images\nLogs You can inspect logs with ops debug log subcommand. Logs you can show:\noperator: ops debug log operator (continuously: ops debug log foperator)\ncontroller: ops debug log controller (continuously: ops debug log fcontroller)\ndatabase: ops debug log couchdb (continuously: ops debug log fcouchdb)\ncertificate manager: ops debug log certman (continuously: ops debug log fcertmap)\nKubernetes You can detect which Kubernetes are you using with:\nops debug detect\nYou can then inspect Kubernetes objects with:\nnamespaces: ops debug kube ns\nnodes: ops debug kube nodes\npod: ops debug kube pod\nservices: ops debug kube svc\nusers: ops debug kube users\nYou can enter a pod by name (use kube pod to find the name) with:\nops debug kube exec P=\u003cpod-name\u003e Kubeconfig Usually, ops uses a hidden kubeconfig so does not override your Kubernetes configuration.\nIf you want to go more in-depth and you are knowledgeable of Kubernetes, you can export the kubeconfig with ops debug export F=\u003cfile\u003e.\nYou can overwrite your kubeconfig (be aware there is no backup) with ops debug export F=-.\n","categories":"","description":"How to diagnose and solve issues","excerpt":"How to diagnose and solve issues","ref":"/docs/installation/debug/","tags":"","title":"Troubleshooting"},{"body":"Upload Web Assets The web folder in the root of a project is used to deploy static frontends. A static front-end is a collection of static asset under a given folder that will be published in a web server under a path.\nEvery uses has associated a web accessible static area where you can upload static assets.\nYou can upload a folder in this web area with\nops web upload \u003cfolder\u003e\nSynopsis: Subcommand: ops web Commands to upload and manage static content. Usage: web upload \u003cfolder\u003e [--quiet] [--clean] Commands: upload \u003cfolder\u003e Uploads a folder to the web bucket in OpenServerless. Options: --quiet Do not print anything to stdout. --clean Remove all files from the web bucket instead. ","categories":"","description":"How to handle frontend deployment","excerpt":"How to handle frontend deployment","ref":"/docs/cli/assets/","tags":"","title":"Web Assets"}]